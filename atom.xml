<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Riroaki</title>
  
  <subtitle>Riroaki&#39;s home</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://riroaki.github.io/"/>
  <updated>2019-07-08T03:25:59.676Z</updated>
  <id>http://riroaki.github.io/</id>
  
  <author>
    <name>Riroaki</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-08ï¼šKè¿‘é‚»</title>
    <link href="http://riroaki.github.io/Machine-Learning-08-K-Nearest-Neighbor/"/>
    <id>http://riroaki.github.io/Machine-Learning-08-K-Nearest-Neighbor/</id>
    <published>2019-07-07T16:00:00.000Z</published>
    <updated>2019-07-08T03:25:59.676Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å…«ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†Kè¿‘é‚»ç®—æ³•çš„ç†è®ºå’Œå®ç°ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>è¿™ä¸€æ¬¡æˆ‘ä»¬ä»‹ç»çš„æ˜¯Kè¿‘é‚»ï¼ˆK Nearest Neighborï¼‰ç®—æ³•ï¼Œå®ƒå±äºæœ‰ç›‘ç£å­¦ä¹ ä¸­æ¯”è¾ƒç®€å•å’Œç›´è§‰çš„åˆ†ç±»ç®—æ³•ã€‚</p><p>å¤äººäº‘ï¼Œâ€œè¿‘æœ±è€…èµ¤ï¼Œè¿‘å¢¨è€…é»‘â€ï¼Œåˆæœ‰äº‘ï¼Œâ€œç‰©ä»¥ç±»èšï¼Œäººä»¥ç¾¤åˆ†â€ï¼Œå¤§æ„å°±æ˜¯è¯´æ€§è´¨ç›¸ä¼¼çš„äººå’Œäº‹å®¹æ˜“èšåœ¨ä¸€å—ã€‚</p><p>æ­£æ˜¯å› ä¸ºæœ‰ç›¸ä¼¼çš„ç‰¹å¾ï¼Œæ‰€ä»¥è¢«å½’ä¸ºä¸€ç±»ï¼Œè¿™åŒæ ·å¯ä»¥åº”ç”¨åœ¨åˆ†ç±»çš„æ€æƒ³ã€‚</p><p>äºæ˜¯å°±æœ‰äº†æˆ‘ä»¬çš„Kè¿‘é‚»ç®—æ³•ï¼Œå®ƒèƒ½å¤ŸæŠŠæ–°çš„æ ·æœ¬è¿…é€Ÿå½’ç±»åˆ°å’Œå®ƒæœ€ç›¸ä¼¼çš„é‚£äº›æ ·æœ¬é‡Œé¢å»ã€‚</p><h2 id="Kè¿‘é‚»ç†è®º"><a href="#Kè¿‘é‚»ç†è®º" class="headerlink" title="Kè¿‘é‚»ç†è®º"></a>Kè¿‘é‚»ç†è®º</h2><p>æœ‰äº†åŸç†ï¼Œå…·ä½“æ“ä½œå°±æ˜¯é€‰å–Kä¸ªå’Œæ–°æ ·æœ¬æœ€è¿‘çš„æ ·æœ¬çš„ç±»åˆ«çš„ä¼—æ•°ä½œä¸ºæ–°æ ·æœ¬çš„ç±»ã€‚</p><p>æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ç»†åŒ–å®šä¹‰è¿™ä¸ªç®—æ³•ï¼š</p><ul><li>å¦‚ä½•å®šä¹‰æ ·æœ¬ä¹‹é—´çš„è·ç¦»è¿œè¿‘ï¼Ÿ</li><li>å¦‚ä½•é€‰å–Kï¼Ÿ</li></ul><p>é¦–å…ˆå¾ˆç›´è§‰åœ°ï¼Œæˆ‘ä»¬é€‰å–æ¬§å¼è·ç¦»ä½œä¸ºè·ç¦»çš„è¡¡é‡æŒ‡æ ‡ï¼š$d(x_i,x_j)=||x_i-x_j||^2$</p><p>å¯¹äºKçš„é€‰å–ï¼Œæˆ‘ä»¬æ—¢ä¸èƒ½é€‰å¤ªå°‘ï¼Œä¹Ÿä¸èƒ½é€‰å¤ªå¤šï¼š</p><ul><li><p>å°‘äº†ï¼Œä¸è¶³ä»¥ä½œä¸ºå‚è€ƒï¼Œå¯èƒ½è¢«å¶ç„¶çš„å™ªå£°å½±å“ï¼Œæ ·æœ¬åˆ†ç±»å—æ‰°åŠ¨å½±å“å¤§ã€‚</p></li><li><p>å¤šäº†ï¼Œå¾’åŠ³å¢å¤§è®¡ç®—é‡ï¼Œè¿˜å®¹æ˜“æ”¶åˆ°å æ¯”æ¯”è¾ƒå¤šçš„æ ·æœ¬æ•°é‡å½±å“ã€‚</p><ul><li>å½“ç„¶æ ·æœ¬ä¸å‡è¡¡çš„å½±å“åœ¨å“ªé‡Œéƒ½æœ‰ï¼Œåªæ˜¯è¿™é‡Œé—®é¢˜æ¯”è¾ƒæ˜æ˜¾</li></ul></li></ul><p>å¦å¤–ï¼Œåº”å½“é€‰å–Kä¸ºå¥‡æ•°ã€‚è¿™æ ·ä¸€æ¥å°±æœç»äº†æ¨¡æ£±ä¸¤å¯çš„å¯èƒ½æ€§â€”â€”å› ä¸ºä¸€å®šæœ‰ä¸€ä¸ªç±»æ ‡ç­¾æ˜¯å‡ºç°äº†æœ€å¤šæ¬¡çš„ã€‚</p><p>è‡³äºå…·ä½“é€‰æ‹©å°±è§ä»è§æ™ºï¼Œä¸€èˆ¬å¯ä»¥å¤šæ¬¡é€‰å–Kï¼Œæ‰¾åˆ°åˆ†ç±»é¢æ¯”è¾ƒå…‰æ»‘ï¼ˆå¯¹æ‰°åŠ¨å½±å“ä¸å¤§ï¼‰è€Œåˆ†ç±»å‡†ç¡®ç‡è¾ƒé«˜çš„é‚£ä¸ªå€¼ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>stats<span class="token keyword">from</span> <span class="token punctuation">.</span>_base <span class="token keyword">import</span> SupervisedModel<span class="token keyword">class</span> <span class="token class-name">KNearest</span><span class="token punctuation">(</span>SupervisedModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""K-Nearest-Neighbor model, multi-class classifier."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>__data <span class="token operator">=</span> None        self<span class="token punctuation">.</span>__label <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>int<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Lazy training for knn, no computations</span>        self<span class="token punctuation">.</span>__data <span class="token operator">=</span> x        self<span class="token punctuation">.</span>__label <span class="token operator">=</span> label        class_count <span class="token operator">=</span> len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> class_count    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>__data <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> self<span class="token punctuation">.</span>__label <span class="token keyword">is</span> <span class="token operator">not</span> None        <span class="token keyword">assert</span> <span class="token string">'k'</span> <span class="token keyword">in</span> kwargs <span class="token operator">and</span> kwargs<span class="token punctuation">[</span><span class="token string">'k'</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>__data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        k <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'k'</span><span class="token punctuation">]</span>        pred_label <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> xi <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>            dist <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>self<span class="token punctuation">.</span>__data <span class="token operator">-</span> xi<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            top_idx <span class="token operator">=</span> np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>dist<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> k<span class="token punctuation">]</span>            top_label <span class="token operator">=</span> self<span class="token punctuation">.</span>__label<span class="token punctuation">[</span>top_idx<span class="token punctuation">]</span>            pred_label<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> scipy<span class="token punctuation">.</span>stats<span class="token punctuation">.</span>mode<span class="token punctuation">(</span>top_label<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> pred_label    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Use 0-1 loss</span>        loss <span class="token operator">=</span> np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred_label <span class="token operator">!=</span> label<span class="token punctuation">)</span>        precision <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> loss <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="æœ‰æ•ˆå‚æ•°"><a href="#æœ‰æ•ˆå‚æ•°" class="headerlink" title="æœ‰æ•ˆå‚æ•°"></a>æœ‰æ•ˆå‚æ•°</h2><p>è¿™ä¸ªç®—æ³•å¾ˆç‰¹åˆ«ï¼Œå®ƒå®é™…ä¸Šä¸å­˜åœ¨â€œè®­ç»ƒâ€çš„è¿‡ç¨‹ï¼Œåªæ˜¯æŠŠæ‰€æœ‰çš„æ ·æœ¬ï¼Œä»¥åŠKä½œä¸ºå‚æ•°ã€‚</p><p>é‚£ä¹ˆç®—æ³•çš„å‚æ•°é‡å°±æ˜¯$N+1$å—ï¼Ÿå¥½åƒä¹Ÿä¸æ˜¯ã€‚</p><p>å¯¹äºæ¯”è¾ƒå°çš„Kï¼Œåˆ†ç±»é¢å¯ä»¥æå…¶å¤æ‚ï¼š</p><p><img src="/Machine-Learning-08-K-Nearest-Neighbor/k=1.png" alt></p><p>è€Œæ¯”è¾ƒå¤§çš„Kä¼šä½¿å¾—åˆ†ç±»é¢æ¯”è¾ƒå…‰æ»‘ï¼š</p><p><img src="/Machine-Learning-08-K-Nearest-Neighbor/k=15.png" alt></p><p>æˆ‘ä»¬çŸ¥é“ï¼Œåˆ†ç±»é¢è¶Šå¤æ‚éœ€è¦æè¿°å®ƒçš„å‚æ•°é‡è¶Šå¤§ã€‚</p><p>å¯ä»¥çœ‹å‡ºKçš„å¤§å°å’Œæ¨¡å‹å‚æ•°çš„å…³ç³»ï¼šKè¶Šå°ï¼Œå‚æ•°é‡è¶Šå¤šã€‚</p><p>äºæ˜¯ï¼Œåˆæ­¥åˆ¤æ–­æ¨¡å‹çš„å‚æ•°é‡ï¼ˆè¿™é‡Œï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªæ¨¡ç³Šçš„è¯´æ³•ï¼Œå®é™…ä¸Šåº”è¯¥å«åšâ€œæœ‰æ•ˆå‚æ•°é‡â€ï¼‰$p=\frac{N}{K}$</p><p>æœ‰æ•ˆå‚æ•°é‡ï¼ˆEffective number of parametersï¼‰çš„è¯æ˜åœ¨æ­¤çœç•¥ã€‚</p><p>äºæ˜¯æœ¬ä¸“æ æœ€çŸ­çš„ä¸€ç¯‡æ–‡ç« å°±å®Œæˆäº†ï¼šï¼‰</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å…«ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†Kè¿‘é‚»ç®—æ³•çš„ç†è®ºå’Œå®ç°ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-06ï¼šæ ¸æ–¹æ³•â€”â€”éçº¿æ€§SVM</title>
    <link href="http://riroaki.github.io/Machine-Learning-06-Kernel-Method/"/>
    <id>http://riroaki.github.io/Machine-Learning-06-Kernel-Method/</id>
    <published>2019-06-30T16:00:00.000Z</published>
    <updated>2019-07-07T07:35:01.702Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å…­ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ ¸æ–¹æ³•çš„åŸºæœ¬ç†è®ºã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>ä¸Šä¸€ç¯‡æ–‡ç« ä»‹ç»SVMï¼Œå¹¶æ€»ç»“äº†çº¿æ€§åˆ†ç±»å™¨çš„ç‰¹å¾ã€‚</p><p>ç°åœ¨æˆ‘ä»¬è¦æ¢ç©¶SVMçš„æé™â€”â€”æ˜¯å¦å¯ä»¥å¯¹éçº¿æ€§ä½†å¯åˆ†çš„æ•°æ®è¿›è¡Œåˆ†ç±»ï¼Ÿ</p><p>ï¼ˆè¯´åˆ°æé™â€¦â€¦<s>æˆ‘ä¸åšäººç±»äº†ï¼ŒJoJoï¼</s>ï¼‰</p><p>æˆ‘ä»¬çœ‹ä¸€ä¸ªäºŒæ¬¡å¯åˆ†çš„é—®é¢˜ï¼š</p><p><img src="/Machine-Learning-06-Kernel-Method/2.png" alt></p><p>å¯¹ä¸Šé¢è¿™ä¸ªå›¾ï¼Œå½¢ä¼¼åœ†ç¯çš„ä¸¤ä¸ªç±»åˆ«çš„æ•°æ®åˆ†å¸ƒï¼Œæ˜¾ç„¶ä¸æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚é‚£ä¹ˆæ‰€æœ‰çš„çº¿æ€§åˆ†ç±»å™¨ï¼ˆé€»è¾‘å›å½’ã€SVMï¼Œä»¥åŠä¹‹åä»‹ç»çš„Perceptronï¼‰éƒ½ä¼šå¤±æ•ˆã€‚</p><p>å¦‚æœæ‰‹åŠ¨åšçš„è¯ï¼Œæˆ‘ä»¬ä»¥å†…åœ†çš„åœ†å¿ƒä¸ºåŸç‚¹ï¼Œè§†æ¨ªåæ ‡ï¼Œçºµåæ ‡çš„è¡¨ç¤ºä¸º$[x_1,x_2]$ï¼Œæ‰¾åˆ°ä»‹äºä¸¤ä¸ªåœ†åŠå¾„ä¹‹é—´çš„é•¿åº¦$r$ï¼Œé‚£ä¹ˆæ»¡è¶³$x_1^2+x_2^2-r^2\le0$ä¸º1ç±»ï¼Œåä¹‹åˆ™ä¸º2ç±»ï¼Œå¦‚æ­¤ä¾¿å¯å®ç°åŒºåˆ†ã€‚</p><p>å¯¹äºä¸€ä¸ªäºŒç»´çš„å¹³é¢ï¼Œæˆ‘ä»¬å£ç®—å°šå¯ä¸€æˆ˜ï¼›ç„¶è€Œå¯¹é—®é¢˜ç¨åšå˜æ¢ï¼Œæƒ…å†µåˆå¦‚ä½•å‘¢ï¼Ÿ</p><p>è®¾æƒ³ä¸€ä¸ªæ˜ å°„å°†åŸå›¾æ”¾å…¥ä¸‰ç»´ç©ºé—´ï¼š</p><p><img src="/Machine-Learning-06-Kernel-Method/3d.png" alt></p><p>è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•æå®šå‘¢ï¼Ÿæˆ–è€…æƒ…å†µä¸æ˜¯åœ†â€¦â€¦</p><p>è¿™æ—¶å€™æˆ‘ä»¬éœ€è¦å›è¿‡å¤´æŠŠæˆ‘ä»¬åœ¨äºŒç»´åšçš„äº‹æƒ…è¿›è¡Œæ³›åŒ–â€”â€”<strong>æ‰¾åˆ°æ›´ä¸ºä¸€èˆ¬å’Œé€šç”¨çš„å½¢å¼</strong>ï¼Œä»¥ä¸å˜åº”ä¸‡å˜å˜›ã€‚</p><p>æ³¨æ„åˆšæ‰çš„ä¸ç­‰å¼$x_1^2+x_2^2 - r^2$çš„å½¢å¼ï¼Œæœ¬è´¨è¿˜æ˜¯å¯ä»¥çœ‹ä½œä¸€ä¸ªçº¿æ€§ç»„åˆâ€”â€”å¦‚æœä»¤$z_0=1,z_1=x_1^2,z_2=x_2^2$é‚£ä¹ˆæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥ç”¨çº¿æ€§å¯åˆ†çš„åˆ†ç±»å™¨å»åˆ’åˆ†ï¼Œå­¦ä¹ å¾—åˆ°$w=[-r^2,1,1]^T$çš„å‚æ•°ä½¿å¾—æ•°æ®å¯ä»¥è¢«$w^Tz=$åˆ’åˆ†ã€‚</p><p>æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬åˆšæ‰åšäº†ä¸€æ¬¡åæ ‡å˜æ¢ï¼Œä»è€ŒæŠŠåŸæ¥ç±»çš„æ•°æ®è½¬æ¢åˆ°ä¸€ä¸ªç©ºé—´ï¼Œåœ¨é‚£ä¸ªç©ºé—´é‡Œå„ä¸ªç±»çš„åˆ†å¸ƒæ˜¯çº¿æ€§å¯åˆ†çš„ã€‚</p><p>æ›´ä¸ºä¸€èˆ¬çš„å½¢å¼æ˜¯åŒ…å«ä¸€æ¬¡é¡¹å’Œå…¶ä»–äºŒæ¬¡é¡¹çš„ï¼ˆæ¯•ç«Ÿä½ ä¸ä¼šæ€»æ˜¯å¯¹è¿™ç§åœ†è¿›è¡Œåˆ†ç±»ï¼Œåœ†å¿ƒä¹Ÿæœªå¿…åœ¨åŸç‚¹ï¼‰ï¼š</p><ul><li>å˜æ¢å‰ï¼š$x=[1,x_1,x_2,â€¦,x_n]$</li><li>å˜æ¢åï¼š$z=\begin{bmatrix} 1&amp;x_1&amp;x_2&amp;â€¦&amp;x_n\x_1&amp;x_1x_1&amp;x_1x_2&amp;â€¦&amp;x_1x_n\â€¦\x_n&amp;x_nx_1&amp;x_nx_2&amp;â€¦&amp;x_nx_n\end{bmatrix}$</li></ul><p>å°±è·å¾—äº†è¿™æ ·çš„æ–°åæ ‡ï¼Œè¿™ä¸ªæ–°åæ ‡çš„ç»´åº¦ä¸º$x_ix_j,i&amp;j\in[0,n]$ï¼Œæ‰€ä»¥æ–°çš„åæ ‡æœ‰$((n+1)^2-(n+1))/2=\frac{n(n+1)}{2}$ä¸ªä¸åŒçš„ç»´åº¦ã€‚</p><p>ç„¶åæˆ‘ä»¬å°†å˜æ¢åçš„åæ ‡å˜ä¸ºæ–°çš„$x$ï¼Œè¿™æ ·ä¸€æ¥è®­ç»ƒä¸€ä¸ª$w\in \R^{n(n+1)/2\times1}$æ¥é¢„æµ‹ï¼Œå°±æŠŠé—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§çš„åˆ†ç±»å·¥ä½œã€‚</p><blockquote><p>å…¶å®åœ¨ä¹‹å‰<a href="/Machine-Learning-03-Linear-Regression">çº¿æ€§å›å½’</a>è®²æ­£åˆ™åŒ–çš„æ—¶å€™å°±å·²ç»åšè¿‡ç±»ä¼¼çš„å·¥ä½œäº†ï¼Œåªä¸è¿‡é‚£ä¸ªæ—¶å€™çš„åæ ‡å˜æ¢æ˜¯ä¸€ä¸ªé¢„å¤„ç†çš„å·¥ä½œï¼Œå³æ”¹å˜æ•°æ®é›†çš„ç»´åº¦ï¼Œè€Œä¸æ˜¯æ¨¡å‹çš„å·¥ä½œã€‚</p></blockquote><p>é‚£ä¹ˆç°åœ¨ï¼Œæˆ‘ä»¬å¦‚ä½•æŠŠè¿™ç§å˜æ¢åŠ å…¥çº¿æ€§çš„åˆ†ç±»å™¨ï¼Œè®©å®ƒèƒ½å¤Ÿè‡ªåŠ¨å¸®æˆ‘ä»¬æå®šéçº¿æ€§çš„æƒ…å†µå‘¢ï¼Ÿ</p><h2 id="æ ¸å‡½æ•°"><a href="#æ ¸å‡½æ•°" class="headerlink" title="æ ¸å‡½æ•°"></a>æ ¸å‡½æ•°</h2><p>æˆ‘ä»¬æŠŠä¸Šé¢è¿™ç§ä»åŸfeatureåˆ°æ–°featureçš„æ˜ å°„å«åšæ ¸å‡½æ•°$\kappa$ã€‚</p><p>å¯¹ä¸Šé¢çš„å˜æ¢ï¼Œæˆ‘ä»¬æœ‰$\hat f(x)=w^Tx=\Sigma_{i=1}^n\alpha_ix_i^Tx=\Sigma_{i=1}^n\alpha_i\kappa(x_i, x)$</p><p>ä»è€Œ$\kappa(x_i,x)=x_i^Tx$</p><p>æŠŠå®ƒåº”ç”¨åœ¨SVMä¸­ï¼Œå¾—åˆ°æ–°çš„å…¬å¼ï¼š</p><p>$y=sgn(w^Tx+b)=sgn(\Sigma_{i=1}^n\alpha_iy_i&lt;x_i,x&gt;+b), w=\Sigma_{i=1}^n\alpha_iy_ix_i$</p><p>åœ¨SVMä¸­ï¼Œå¯¹éæ”¯æŒå‘é‡çš„ç‚¹ï¼Œ$\alpha_i$çš„å€¼ä¸º0ã€‚</p><p>æ ¸å‡½æ•°æ›´ä¸ºä¸€èˆ¬çš„å®šä¹‰æ˜¯ï¼š</p><blockquote><p>æ ¸å‡½æ•°æ˜¯ç”¨äºè¡¡é‡ä¸¤ä¸ªå¯¹è±¡$x,xâ€™$çš„<strong>ç›¸ä¼¼æ€§</strong>å…³ç³»çš„å‡½æ•°ï¼Œé€šå¸¸å®ƒæ˜¯ï¼š</p><ul><li>éè´Ÿçš„ï¼Œå³$\kappa(x,xâ€™)\ge0$</li><li>å¯¹ç§°çš„ï¼Œå³$\kappa(x,xâ€™)=\kappa(xâ€™,x)$</li></ul></blockquote><p>é€šå¸¸çš„æ ¸å‡½æ•°æœ‰å¦‚ä¸‹å‡ ç§ï¼š</p><ul><li><code>Linear kernel</code>:$\kappa(x,xâ€™)=x^Txâ€™$</li><li><code>Polynomial kernel</code>:$\kappa(x,xâ€™)=(x^Txâ€™+1)^d$</li><li><code>RBF kernel</code>:$\kappa(x,xâ€™)=exp(-\frac{||x-xâ€™||^2}{2\sigma^2})$</li></ul><p>é€šè¿‡å¼•å…¥æ ¸å‡½æ•°ï¼Œæˆ‘ä»¬å°†åŸæ¥çš„çº¿æ€§SVMåˆ†ç±»å™¨æ¨å¹¿åˆ°äº†éçº¿æ€§çš„åˆ†ç±»ã€‚</p><p>æ­¤å¤–ï¼Œè¿˜æœ‰<code>string kernel</code>å’Œ<code>graph kernel</code>ï¼Œè¿™ä¸¤ä¸ªæ ¸å‡½æ•°çš„ä½œç”¨ä¸æ˜¯æŠŠè¾“å…¥æŠ•å½±åˆ°æ–°çš„ç»´åº¦ä¸Šï¼Œè€Œæ˜¯å•çº¯è·å–ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚</p><h2 id="ç¼ºé™·"><a href="#ç¼ºé™·" class="headerlink" title="ç¼ºé™·"></a>ç¼ºé™·</h2><p>ä½¿ç”¨æ ¸æ–¹æ³•æ„å‘³ç€ä½ å·²ç»çŸ¥é“äº†æ•°æ®åˆ†å¸ƒçš„å¤§è‡´æƒ…å†µï¼ˆæ¯”å¦‚äºŒæ¬¡å‹ï¼‰ï¼Œä»è€Œèƒ½å¤Ÿé€‰å–æ ¸çš„å½¢å¼ã€‚</p><p>å¹¶ä¸æ˜¯ä¸€åŠ³æ°¸é€¸çš„æ–¹æ³•ã€‚å“ˆå“ˆï¼Œç…§è¿™ä¸ªç»“è®ºï¼Œæˆ‘å¯ä»¥è¯´â€œæœºå™¨å­¦ä¹ æ²¡æœ‰é“¶å¼¹â€å’¯ï¼Ÿ</p><h2 id="è¯´æ˜"><a href="#è¯´æ˜" class="headerlink" title="è¯´æ˜"></a>è¯´æ˜</h2><p>è¿™ä¸€ç« å†…å®¹å…¶å®æˆ‘ä¹Ÿä¸€çŸ¥åŠè§£ï¼Œå¯ä»¥çœ‹ä½œæ˜¯å¯¹SVMçš„ä¸€ç§è¡¥å……å§ï¼ˆç„¶è€Œå¹¶æ²¡æœ‰ä»£ç å®ç°ï¼‰ã€‚</p><p>ç­‰åˆ°æœ‰æ›´æ¸…æ¥šçš„è¯´æ³•æˆ‘ä¼šè¡¥å……ï¼Œæœ‰é—®é¢˜æˆ–è€…æ„è§å¯ä»¥åœ¨è¯„è®ºåŒºç•™è¨€ï¼Œå…±åŒè®¨è®ºã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å…­ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ ¸æ–¹æ³•çš„åŸºæœ¬ç†è®ºã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-07ï¼šæ„ŸçŸ¥æœºä¸ç¥ç»ç½‘ç»œ</title>
    <link href="http://riroaki.github.io/Machine-Learning-07-Perceptron-and-Neural-Network/"/>
    <id>http://riroaki.github.io/Machine-Learning-07-Perceptron-and-Neural-Network/</id>
    <published>2019-06-30T16:00:00.000Z</published>
    <updated>2019-07-08T02:54:57.233Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸ƒç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ„ŸçŸ¥æœºçš„è¯¦ç»†ç†è®ºå’Œå®ç°ï¼Œä»¥åŠæ„ŸçŸ¥æœºå‘æ·±åº¦å­¦ä¹ çš„æ¨å¹¿ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>è¿™åº”è¯¥æ˜¯æˆ‘ä»¬è¦ä»‹ç»çš„æœ€åä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨äº†ã€‚</p><p>è¿™ç©æ„æ˜¯60å¹´å‰æå‡ºçš„ï¼ˆFrank Rosenblattï¼Œ1957ï¼‰ï¼Œä¸€åº¦é£é¡è®¡ç®—æœºç§‘å­¦ç•Œã€‚</p><p>å½“æ—¶äººå·¥æ™ºèƒ½çš„æ¦‚å¿µå°±å¼€å§‹ğŸ”¥äº†ã€‚<s>ä¸è¿‡è¿™è‚¡çƒ­æƒ…è¿…é€Ÿè¢«1969å¹´çš„ä¸€ç¯‡è®ºæ–‡æµ‡ç­</s>ã€‚</p><p>é—®é¢˜åœ¨äºï¼Œè¿™ç©æ„æ ¹æœ¬å°±æ˜¯ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œæ²¡åŠæ³•æ‹Ÿåˆéçº¿æ€§çš„å‡½æ•°ï¼ˆè®ºæ–‡é‡Œç”¨å¼‚æˆ–è¿ç®—æ‰“è„¸ï¼Œä¹Ÿå°±æ˜¯è¯´å®ƒè¿å¼‚æˆ–éƒ½ä¸èƒ½æ‹Ÿåˆï¼‰ã€‚å¦å¤–ï¼Œç›¸å¯¹å½“æ—¶çš„è®¡ç®—èƒ½åŠ›ï¼Œè¿™ä¸ªç®—æ³•è¿˜æ˜¯å¤ªå¤æ‚ã€‚</p><p>äºæ˜¯è¿æ¥æ•°åå¹´çš„AIå¯’å†¬ï¼Œç›´åˆ°SVMçš„å‡ºç°å¸¦æ¥AIçš„å¤å…´â€”â€”åªä¸è¿‡Rosenblattæœ¬äººåœ¨1971å¹´æ„å¤–ç¦»ä¸–ï¼Œçœ‹ä¸åˆ°åæ¥çš„æ•…äº‹äº†ã€‚</p><p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ1970å¹´backpropagationçš„ç®—æ³•å°±å·²ç»æå‡ºäº†ï¼Œåªä¸è¿‡å½“æ—¶æ²¡æœ‰å¾—åˆ°æ³¨æ„ï¼Œç›´åˆ°1984å¹´è¢«é‡æ–°å‘æ˜ã€‚è¿™ä¸ªå¯æ˜¯ç°ä»£ç¥ç»ç½‘ç»œçš„åŸºçŸ³å•Šã€‚åªèƒ½è¯´ï¼Œå†å²æ€»æ˜¯èºæ—‹å¼ä¸Šå‡ã€æ›²æŠ˜å‘å±•çš„å§ã€‚</p><h2 id="æ„ŸçŸ¥æœºç†è®º"><a href="#æ„ŸçŸ¥æœºç†è®º" class="headerlink" title="æ„ŸçŸ¥æœºç†è®º"></a>æ„ŸçŸ¥æœºç†è®º</h2><p>æ„ŸçŸ¥æœºæ˜¯ä¸€ä¸ªçº¿æ€§äºŒåˆ†ç±»å™¨ã€‚å®ƒçš„ç®—æ³•å’Œä¹‹å‰çš„é€»è¾‘å›å½’ã€SVMç±»ä¼¼ï¼š</p><p>$f(x)=w^Tx+b$ï¼Œ$f(x)\ge0$è¡¨ç¤ºæ­£ç±»ï¼Œåä¹‹è¡¨ç¤ºè´Ÿç±»ã€‚</p><p>è€Œå®ƒçš„å­¦ä¹ è¿‡ç¨‹ï¼Œäº‹å®ä¸Šæœ‰ç‚¹åƒæ˜¯ä¸ªæ‹è„‘è¢‹çš„ç®—æ³•ï¼š</p><ul><li>å¯¹äº$x_i$å¦‚æœé¢„æµ‹æ­£ç¡®ï¼Œé‚£å°±ä¸åšå¤„ç†ï¼›</li><li>å¦‚æœé¢„æµ‹é”™è¯¯ï¼Œé‚£å°±æ‰§è¡Œ$w_t=w_{t-1}+x_iy_i$çš„æ“ä½œã€‚</li></ul><p>æˆ‘ä»¬å…ˆä»ç›´è§‚è§’åº¦ç†è§£ä¸€ä¸‹è¿™ä¸€æ“ä½œçš„åˆç†æ€§ï¼š</p><ol><li>$y_i=\pm1$ï¼Œå¦‚æœé¢„æµ‹é”™è¯¯ï¼Œé‚£ä¹ˆ$w_{t-1}x_iy_i&lt;0$ï¼ˆé¢„æµ‹å’ŒçœŸå®å€¼å¼‚å·ï¼‰</li><li>å‡å¦‚æˆ‘ä»¬é‡æ–°é¢„æµ‹è¿™ä¸ªå€¼ï¼Œä¼šå‘ç°$w_t^Tx_i=(w_{t-1}^Tx_i+(x_iy_i)^Tx_i)=w_{t-1}^T+y_ix_i^Tx_i$</li><li>ç”±äº$x_i^Tx_i&gt;0$ï¼Œè¿™æ ·æ“ä½œç›¸å½“äºå¼•å…¥çœŸå®æ ‡ç­¾ä¿¡æ¯ï¼Œä½¿å¾—é¢„æµ‹ç»“æœå‘çœŸå®æƒ…å†µ$y_i$é è¿‘ã€‚</li></ol><p>é‚£ä¹ˆæŒ‰ç…§ä¹‹å‰çš„æƒ¯ä¾‹ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªå½¢å¼åŒ–çš„æŸå¤±å‡½æ•°ï¼š</p><h2 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h2><p>è¿™å°±æœ‰ç‚¹å…ˆå°„ç®­ï¼Œåç”»é¶å­çš„æ„Ÿè§‰ğŸ¯ã€‚</p><p>å®šä¹‰æŸå¤±å‡½æ•°ï¼š$J(w)=-\Sigma_{i\in I_M}w^Tx_iy_i$</p><p>ç»“åˆæ¢¯åº¦ä¸‹é™ç†è®ºï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºæ¢¯åº¦$\nabla J=\Sigma_{i\in I_M}-x_iy_i$</p><p>æ‰€ä»¥$w_t=w_{t-1}+\alpha(t)\Sigma_{i\in I_M}x_iy_i$ï¼Œä¸è¿‡ä¸€èˆ¬å°±è®©$\alpha(t)=1$ã€‚</p><p>å¯¹äº$b$çš„æ¢¯åº¦å°±ä½¿ç”¨$b_t=b_{t-1}+\Sigma_{i\in I_M}y_i$ã€‚</p><p>è¿™æ ·æˆ‘ä»¬å°±å¾—åˆ°äº†æ„ŸçŸ¥æœºçš„æŸå¤±å‡½æ•°å’Œå‚æ•°ä¼°è®¡æ–¹æ³•ã€‚</p><h2 id="å‚æ•°ä¼°è®¡"><a href="#å‚æ•°ä¼°è®¡" class="headerlink" title="å‚æ•°ä¼°è®¡"></a>å‚æ•°ä¼°è®¡</h2><p>æ„ŸçŸ¥æœºçš„å‚æ•°ä¼°è®¡å°±å¦‚ä¸Šæ–‡æ‰€è¿°ï¼š</p><ul><li><p>$w_t=w_{t-1}+\Sigma_{i\in I_M}x_iy_i$</p></li><li><p>$b_t=b_{t-1}+\Sigma_{i\in I_M}y_i$</p></li></ul><p>è¿™æ ·ä¸€æ¥ï¼Œå²‚ä¸æ˜¯å¾ˆå®¹æ˜“ä¸æ”¶æ•›ï¼Ÿä¼šä¸ä¼šå› ä¸ºæ ·æœ¬çš„å€¼æ¯”è¾ƒå¤§ï¼Œåœ¨æ”¶æ•›çš„è¾¹ç¼˜<s>åå¤æ¨ªè·³</s>æŒ¯è¡ä¹‹ç±»çš„â€¦â€¦</p><p>ä¸è¿‡å·²ç»æœ‰å·¥ä½œè¯æ˜äº†å®ƒçš„æ”¶æ•›æ€§â€”â€”æˆ–è€…è¯´ï¼Œæ„ŸçŸ¥æœºå¯¹åˆ†ç±»å­˜åœ¨è¯¯å·®çš„ä¸Šç•Œã€‚è¿™é‡Œå°±ç›´æ¥è´´å›¾äº†ï¼š</p><p><img src="/Machine-Learning-07-Perceptron-and-Neural-Network/proof1.png" alt></p><p><img src="/Machine-Learning-07-Perceptron-and-Neural-Network/proof2.png" alt></p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>ç»ˆäºåˆ°äº†ä¸‡ä¼—ç©ç›®çš„ä»£ç å®ç°ç¯èŠ‚ã€‚</p><p>æœ¬æ¬¡ä»£ç ä¸å¤šè¯´ï¼Œå’Œçº¿æ€§å›å½’ç±»ä¼¼ã€‚æœ‰é—®é¢˜è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Perceptron</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Perceptron model, binary classifier."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token keyword">assert</span> np<span class="token punctuation">.</span>array_equal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token keyword">if</span> kwargs <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Update parameters of training</span>            self<span class="token punctuation">.</span>_update_params<span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span>        iters<span class="token punctuation">,</span> loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true"># Iterates till converge or iterating times exceed bound</span>        <span class="token keyword">while</span> iters <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_iter_bound<span class="token punctuation">:</span>            iters <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment" spellcheck="true"># Update weights using mini-batch gradient desent</span>            <span class="token keyword">for</span> batch_x<span class="token punctuation">,</span> batch_label <span class="token keyword">in</span> batch<span class="token punctuation">(</span>x<span class="token punctuation">,</span> label<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>                pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>                loss <span class="token operator">+=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> batch_label<span class="token punctuation">)</span> <span class="token operator">*</span> batch_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>                grad_w<span class="token punctuation">,</span> grad_b <span class="token operator">=</span> self<span class="token punctuation">.</span>_grad<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> pred_label<span class="token punctuation">,</span> batch_label<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>_w <span class="token operator">-=</span> grad_w                self<span class="token punctuation">.</span>_b <span class="token operator">-=</span> grad_b            loss <span class="token operator">/=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># Break if model converges.</span>            <span class="token keyword">if</span> loss <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>_loss_tol<span class="token punctuation">:</span>                <span class="token keyword">break</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_label    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        precision <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred_label <span class="token operator">-</span> label<span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_value</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> w<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>                       b<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_val <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b        <span class="token keyword">return</span> pred_val    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_label</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_label <span class="token operator">=</span> np<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        pred_label<span class="token punctuation">[</span>pred_label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>        <span class="token keyword">return</span> pred_label    @staticmethod    <span class="token keyword">def</span> <span class="token function">_loss</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> true_label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        loss <span class="token operator">=</span> <span class="token operator">-</span>np<span class="token punctuation">.</span>float<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>pred_val <span class="token operator">*</span> true_label<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> true_label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> pred_label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>              true_label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        grad_w <span class="token operator">=</span> <span class="token operator">-</span><span class="token punctuation">(</span>true_label<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> x<span class="token punctuation">)</span><span class="token punctuation">[</span>pred_label <span class="token operator">!=</span> true_label<span class="token punctuation">]</span>        grad_b <span class="token operator">=</span> <span class="token operator">-</span>true_label<span class="token punctuation">[</span>pred_label <span class="token operator">!=</span> true_label<span class="token punctuation">]</span>        grad_w <span class="token operator">=</span> grad_w<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        grad_b <span class="token operator">=</span> grad_b<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> grad_w<span class="token punctuation">,</span> grad_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="ç¥ç»ç½‘ç»œ"><a href="#ç¥ç»ç½‘ç»œ" class="headerlink" title="ç¥ç»ç½‘ç»œ"></a>ç¥ç»ç½‘ç»œ</h2><p>å…¶å®ä¸Šæ–‡æåˆ°çš„å¼‚æˆ–è¿ç®—å¯ä»¥ç”¨å¤šå±‚çš„æ„ŸçŸ¥æœºç»„åˆè§£å†³ï¼Œå¦‚ä¸‹æ˜¯ä¸€ç§å¼‚æˆ–æ¨¡å‹ï¼š</p><p><img src="/Machine-Learning-07-Perceptron-and-Neural-Network/xor.png" alt></p><p>åœ¨è¿™ä¸ªå›¾ä¸­ï¼Œæ¯ä¸€ä¸ªåœ†éƒ½æ˜¯ä¸€ä¸ªç¥ç»å…ƒï¼Œè¿™é‡Œæœ‰è¾“å…¥ç¥ç»å…ƒå’Œæ„ŸçŸ¥æœºç¥ç»å…ƒä¹‹åˆ†ã€‚</p><p>åˆä»£çš„ç¥ç»ç½‘ç»œå°±æ˜¯é€šè¿‡æ„ŸçŸ¥æœºç»„åˆå¾—åˆ°çš„ã€‚</p><p>ç„¶è€Œâ€¦â€¦æ€ä¹ˆå¾—åˆ°è¿™ä¹ˆä¸€ä¸ªæ¨¡å‹å‘¢ï¼Ÿæ€»ä¸èƒ½å¯¹æ¯ä¸€ä¸ªé—®é¢˜ï¼Œéƒ½äººå·¥å»å‡‘å‡ºä¸€ä¸ªæ¨¡å‹å§ï¼Ÿ</p><p>ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ç®—æ³•ã€‚</p><h3 id="åå‘ä¼ æ’­"><a href="#åå‘ä¼ æ’­" class="headerlink" title="åå‘ä¼ æ’­"></a>åå‘ä¼ æ’­</h3><p>åå‘ä¼ æ’­ï¼Œå…¶å®å°±æ˜¯æ¢¯åº¦ä¸‹é™ç»“åˆæ±‚å¯¼çš„é“¾å¼æ³•åˆ™ï¼Œå¯¹ç½‘ç»œçš„æ¯ä¸€å±‚è¿›è¡Œæ¢¯åº¦ä¸‹é™çš„å‚æ•°ä¼°è®¡ã€‚</p><p>æ¯”å¦‚è¯´ï¼Œä¸€ä¸ªç¥ç»ç½‘ç»œçš„ç»“æ„æ˜¯$p_1(in)=out_1,p_2(out_1)=out_2,p_3(out_2)-&gt;out_3$ï¼ˆè™½ç„¶ä¸å¯èƒ½æ˜¯å•é“¾æ¡è¿™ä¹ˆç®€å•ï¼Œä½†æ˜¯è¶³å¤Ÿè¯´æ˜é—®é¢˜ï¼‰ï¼Œå¦‚æœè¯´æŸå¤±å‡½æ•°æ˜¯$J(out_3)$ï¼Œé‚£ä¹ˆå¯¹ä¸‰ä¸ªç¥ç»å…ƒï¼ˆæ„ŸçŸ¥æœºï¼‰çš„æ¢¯åº¦åˆ†åˆ«æ˜¯ï¼š</p><ul><li>å¯¹3å·æ„ŸçŸ¥æœºï¼š$\frac{\partial J}{\partial w_3}=\frac{\partial J}{\partial out_3}\frac{\partial out_3}{\partial w_3}$</li><li>2å·ï¼š$\frac{\partial J}{\partial w_2}=\frac{\partial J}{\partial out_3}\frac{\partial out_3}{\partial w_2}=\frac{\partial J}{\partial out_3}w_3\frac{\partial out_2}{\partial w_2}$</li><li>1å·ï¼š$\frac{\partial J}{\partial w_1}=\frac{\partial J}{\partial out_3}\frac{\partial out_3}{\partial out_2}\frac{\partial out_2}{\partial out_1}\frac{\partial out_1}{\partial w_1}=\frac{\partial J}{\partial out_3}w_3w_2\frac{\partial out_1}{\partial w_1}$</li></ul><p>ç»“æœä¸ä¸€å®šå‡†ç¡®ï¼Œä½†æ˜¯è¿‡ç¨‹å°±æ˜¯è¿™ä¸ªæ ·å­ã€‚</p><p>å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ˜¯ç›¸å¯¹çš„æ¦‚å¿µï¼Œå‰å‘è¡¨ç¤ºä»è¾“å…¥å±‚å±‚æ¨è¿›åˆ°è¾“å‡ºç»“æœçš„è¿‡ç¨‹ï¼Œåå‘å°±æ˜¯å‚æ•°ä¼°è®¡çš„è¿‡ç¨‹ã€‚</p><p>ç„¶åï¼Œä¸ºäº†æ‘†è„±æ„ŸçŸ¥æœºçš„çº¿æ€§æ€§ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªéçº¿æ€§çš„æ¿€æ´»å‡½æ•°ï¼Œæ¯”å¦‚$sigmoid$ï¼Œ$ReLU$ç­‰ç­‰ã€‚äºæ˜¯å°±å˜æˆäº†æ·±åº¦å­¦ä¹ çš„æ¨¡å‹ï¼š</p><h3 id="æ·±åº¦å­¦ä¹ "><a href="#æ·±åº¦å­¦ä¹ " class="headerlink" title="æ·±åº¦å­¦ä¹ "></a>æ·±åº¦å­¦ä¹ </h3><p>ç”¨ä¸€ä¸ªå›¾æ¥è¯´æ˜æ·±åº¦å­¦ä¹ çš„ç½‘ç»œç»“æ„ä¸å®ƒçš„åå‘ä¼ æ’­ç®—æ³•ï¼š</p><p><img src="/Machine-Learning-07-Perceptron-and-Neural-Network/net.png" alt></p><p>æ¯”èµ·æœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ çš„ä¸€å¤§ä¼˜åŠ¿åœ¨äºä¸å¤ªéœ€è¦å‰æœŸçš„ç‰¹å¾å·¥ç¨‹ã€‚</p><p>åœ¨æœºå™¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è§‚å¯Ÿæ•°æ®ï¼Œé€‰å–åˆé€‚çš„åˆ†ç±»å™¨ï¼ˆé€»è¾‘å›å½’ã€SVMã€è´å¶æ–¯ç­‰ç­‰ï¼‰ï¼Œå¹¶ä¸”æœ€é‡è¦çš„æ˜¯ï¼šæå–å‡ºä¸€äº›æœ‰æ•ˆåˆ†ç±»çš„featureï¼Œå¹¶è¿›è¡Œéçº¿æ€§çš„å˜æ¢ã€é™ç»´ã€å‡ç»´ç­‰ç­‰æ“ä½œã€‚è¿™ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹å°±æ˜¯ç‰¹å¾å·¥ç¨‹ï¼Œæ˜¯ä¸€ä¸ªéå¸¸ä¾èµ–ç»éªŒå’ŒäººåŠ›çš„æ´»ã€‚</p><blockquote><p>åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œæƒ³è¦è·å¾—ä¸€ä¸ªå¥½çš„ç»“æœï¼Œå¥½çš„ç‰¹å¾æ¯”æ¨¡å‹è®¾è®¡ã€è®­ç»ƒè¿‡ç¨‹ç­‰ç­‰éƒ½è¦é‡è¦ã€‚</p></blockquote><p>è€Œæ·±åº¦å­¦ä¹ ï¼Œä½ åªéœ€è¦æŠŠæ•°æ®å–‚è¿›å»ï¼Œé€‰å¥½ç½‘ç»œç»“æ„ï¼Œå‰©ä¸‹æ¥çš„äº‹æƒ…äº¤ç»™æ¨¡å‹è‡ªå·±å»å­¦å§â€”â€”è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå®ƒçš„è§£é‡Šæ€§å·®ï¼Œæ¨¡å‹é åå‘ä¼ æ’­å­¦å‡ºæ¥çš„ä¸œè¥¿èƒ½ç”¨ä»€ä¹ˆé€»è¾‘è§£é‡Šå—ï¼Ÿ</p><h3 id="å‡è®¾ç©ºé—´"><a href="#å‡è®¾ç©ºé—´" class="headerlink" title="å‡è®¾ç©ºé—´"></a>å‡è®¾ç©ºé—´</h3><p>å›åˆ°ä¸€å¼€å§‹çš„æ¦‚å¿µï¼Œæ·±åº¦å­¦ä¹ æœ€å¤§çš„ä¼˜åŠ¿åœ¨äºå®ƒå¹¿é˜”çš„å‡è®¾ç©ºé—´ã€‚</p><p>æœ‰è¯æ˜æŒ‡å‡ºï¼Œä»…éœ€è¦åƒä¸Šå›¾ä¸€æ ·çš„ä¸‰å±‚ç½‘ç»œï¼ˆè¾“å…¥ã€éšå«å±‚ã€è¾“å‡ºï¼‰ï¼Œå°±å¯ä»¥æ‹Ÿåˆ<strong>ä»»æ„</strong>ï¼ˆarbitraryï¼‰çš„å‡½æ•°ã€‚</p><p>è¿™è¿˜æ˜¯åœ¨å‡è®¾ä½¿ç”¨åŒä¸€ä¸ªæ¿€æ´»å‡½æ•°çš„å‰æä¸‹ï¼š</p><p><img src="/Machine-Learning-07-Perceptron-and-Neural-Network/proof3.png" alt></p><p>ç”¨å½¢å¼åŒ–çš„è¯­è¨€æè¿°ï¼Œå°±æ˜¯è¯´ï¼š</p><blockquote><p>Any continuous function from input to output can be implemented in a threeâ€layer net, given sufficient number of hidden units $n_H$, proper nonlinearities, and weights.</p></blockquote><p>è¿™æ˜¯ç”±A. Kolmogorovè¯æ˜çš„ï¼Œæœ‰å…´è¶£å¯ä»¥è‡ªè¡Œäº†è§£ï½</p><h3 id="è¦ç´ "><a href="#è¦ç´ " class="headerlink" title="è¦ç´ "></a>è¦ç´ </h3><p>ç¥ç»ç½‘ç»œçš„ä¸‰è¦ç´ æœ‰ï¼š</p><ul><li>ç½‘ç»œç»“æ„ï¼ˆnet topologyï¼‰ï¼ˆå…¨è¿æ¥å±‚ã€æ± åŒ–å±‚ç­‰ç­‰ç»„æˆçš„å±‚æ¬¡ç»“æ„ï¼‰</li><li>èŠ‚ç‚¹æ€§è´¨ï¼ˆprocessor characteristicsï¼‰ï¼ˆä¸€èˆ¬èŠ‚ç‚¹éƒ½æ˜¯çº¿æ€§å•å…ƒï¼Œè¿™é‡Œçš„æ€§è´¨ä¸»è¦æ˜¯æ¿€æ´»å‡½æ•°çš„é€‰å–ï¼‰</li><li>è®­ç»ƒæ³•åˆ™ï¼ˆtraining rulesï¼‰ï¼ˆä¸€èˆ¬ç‰¹æŒ‡åå‘ä¼ æ’­çš„è®¡ç®—æ³•åˆ™ï¼‰</li></ul><p>å¸¸è§çš„ç¥ç»ç½‘ç»œæœ‰CNNã€RNNã€LSTMç­‰ã€‚</p><p>å…³äºç¥ç»ç½‘ç»œçš„å†…å®¹ï¼Œåœ¨ç»“æŸæœºå™¨å­¦ä¹ éƒ¨åˆ†åä¼šæ›´æ–°ï¼Œè¯·æ‹­ç›®ä»¥å¾…ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸ƒç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ„ŸçŸ¥æœºçš„è¯¦ç»†ç†è®ºå’Œå®ç°ï¼Œä»¥åŠæ„ŸçŸ¥æœºå‘æ·±åº¦å­¦ä¹ çš„æ¨å¹¿ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-05ï¼šæ”¯æŒå‘é‡æœº</title>
    <link href="http://riroaki.github.io/Machine-Learning-05-Support-Vector-Machine/"/>
    <id>http://riroaki.github.io/Machine-Learning-05-Support-Vector-Machine/</id>
    <published>2019-06-25T04:00:00.000Z</published>
    <updated>2019-07-02T16:44:31.425Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬äº”ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ”¯æŒå‘é‡æœºçš„è¯¦ç»†ç†è®ºå’Œå®ç°ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>ä¸Šä¸€ç¯‡å†…å®¹ä¸­ä»‹ç»äº†é€»è¾‘å›å½’çš„å†…å®¹ï¼Œå¹¶ä»¥æ­¤å±•ç¤ºäº†çº¿æ€§åˆ†ç±»å™¨æœ€åŸºæœ¬çš„å½¢å¼ã€‚</p><p>æœ¬æ–‡ä»‹ç»çš„æ”¯æŒå‘é‡æœºä¹Ÿæ˜¯ä¸€ç§çº¿æ€§åˆ†ç±»å™¨ï¼Œåªä¸è¿‡è·å¾—æ¨¡å‹çš„æ–¹å¼æœ‰æ‰€ä¸åŒã€‚</p><p>ä½œä¸ºå¤ä¹ ï¼Œæˆ‘ä»¬é‡æ–°å›é¡¾ä¸€ä¸‹é€»è¾‘å›å½’çš„åˆ†ç±»æ–¹å¼ï¼š</p><p>$y=a^Tx$ï¼Œåœ¨$y&gt;0$çš„æ—¶å€™è¢«æŠ•å½±åˆ°åŒºé—´$(0.5,1)$ï¼Œæ‰€ä»¥åˆ†ç±»ä¸ºæ­£ç±»ï¼›</p><p>åœ¨$y&lt;0$çš„æ—¶å€™è¢«æŠ•å½±åˆ°åŒºé—´$(0,0.5)$æ‰€ä»¥åˆ†ç±»ä¸ºè´Ÿç±»ã€‚</p><p>$a$è¢«ç§°ä¸ºåˆ†å‰²å‘é‡ï¼Œæˆ–è€…è§£å‘é‡ï¼Œè€Œæ¯ä¸€ä¸ªåˆ†ç±»å‘é‡éƒ½å¯¹åº”ç€ä¸€ä¸ªåˆ†ç±»å¹³é¢ï¼ŒæŠŠæŠ•å½±åˆ°ç©ºé—´ä¸­çš„æ‰€æœ‰ç‚¹$X_i$åˆ†ä¸ºä¸¤ç±»ã€‚</p><p>ä¸‹å›¾ç”¨äºè§£é‡Šåˆ†ç±»å¹³é¢ä¸å‚æ•°$a$ï¼ˆ$a=[w,b]$ï¼‰çš„å…³ç³»ï¼š</p><p><img src="/Machine-Learning-05-Support-Vector-Machine/wb.png" alt></p><p>é‚£ä¹ˆï¼Œè¿™ä¸ªå‘é‡æ˜¯å”¯ä¸€çš„å—ï¼Ÿ</p><p>ç­”æ¡ˆæ˜¯ï¼Œåœ¨æœ‰é™ä¸”çº¿æ€§å¯åˆ†çš„æ•°æ®é›†ä¸Šï¼Œä¸€èˆ¬æ˜¯å­˜åœ¨æ— æ•°å¯è¡Œçš„åˆ†ç±»é¢/åˆ†ç±»å‘é‡çš„ï¼Œå¦‚ä¸‹å›¾ï¼š</p><p><img src="/Machine-Learning-05-Support-Vector-Machine/hyperplane.png" alt></p><p>é‚£ä¹ˆå¾ˆè‡ªç„¶çš„æˆ‘ä»¬å°±ä¼šæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæ€æ ·åˆ†ç±»æ‰æ˜¯æœ€ä¼˜çš„å‘¢ï¼Ÿ</p><p>è¿™ä¸ªæœ€ä¼˜çš„å¹³é¢ï¼Œç†åº”æ˜¯èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬åœ¨æµ‹è¯•æ•°æ®ä¸Šæœ‰æœ€å¥½çš„åˆ†ç±»æ•ˆæœçš„ï¼š</p><p>ç›´è§‰ä¸Šæ¥çœ‹ï¼Œè¿™ä¸ªåˆ†ç±»é¢ä¸åº”è¯¥è¿‡äºé è¿‘æŸä¸€ç±»ç‚¹ï¼ˆæˆ–è€…ç”šè‡³æ’å…¥äº†åŒä¸€ç±»ç‚¹ä¹‹é—´ï¼‰ï¼Œè€Œæ˜¯è®©ä¸¤ç±»ç‚¹å°½é‡ç¦»åˆ†ç±»å¹³é¢è¾ƒè¿œã€‚å› ä¸ºè·ç¦»è¿‘è¡¨ç¤ºæ¥è¿‘è¾¹ç•Œï¼Œé‚£ä¹ˆè¿™äº›ç‚¹æ˜¯æœ€å®¹æ˜“è¢«è¯¯åˆ†ç±»çš„ï¼Œæˆ‘ä»¬å¸Œæœ›è¿™æ ·çš„ç‚¹è¶Šå°‘è¶Šå¥½â€”â€”ä¹Ÿå°±æ˜¯ï¼Œå¸Œæœ›æˆ‘ä»¬çš„åˆ†ç±»å™¨çš„åˆ†ç±»ç»“æœéƒ½æ˜¯<strong>æç«¯ä¸€ç‚¹</strong>ï¼Œ<strong>æ¨¡æ£±ä¸¤å¯çš„ç»“æœå°½é‡å°‘ä¸€äº›</strong>ã€‚</p><p>æ¢å¥è¯è¯´ï¼Œæ¯ä¸€ä¸ªç‚¹åˆ°è¶…å¹³é¢çš„è·ç¦»éƒ½åº”å½“å°½é‡çš„å¤§ï¼Œåº”å¯¹æ–°æ•°æ®ç†åº”æœ‰å¥½çš„è¡¨ç°ã€‚</p><p>è€Œäº‹å®ä¸Šè¶…å¹³é¢ç¨å¾®æ”¹å˜ï¼Œå½±å“çš„ä¸»è¦æ˜¯å’Œå¹³é¢è¿‘é‚»çš„ç‚¹ï¼Œæ‰€ä»¥æˆ‘ä»¬å®šä¹‰æ¦‚å¿µï¼š</p><blockquote><p>Marginï¼šåˆ†ç±»å¹³é¢åˆ°ç‚¹é›†çš„<strong>æœ€å°</strong>è·ç¦»ã€‚</p></blockquote><p>ç”¨æ•°å­¦åŒ–çš„è¯­è¨€æè¿°ï¼Œæˆ‘ä»¬æ‰€è¿½æ±‚çš„ç›®æ ‡å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆ†ç±»é¢å¯ä»¥æœ€å¤§åŒ–marginã€‚</p><p>ç­”æ¡ˆå·²ç»å‘¼ä¹‹æ¬²å‡ºäº†ï¼Œé‚£å°±æ˜¯ä»Šå¤©çš„ä¸»è§’â€”â€”æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machineï¼‰ã€‚</p><h2 id="æ”¯æŒå‘é‡æœºç†è®º"><a href="#æ”¯æŒå‘é‡æœºç†è®º" class="headerlink" title="æ”¯æŒå‘é‡æœºç†è®º"></a>æ”¯æŒå‘é‡æœºç†è®º</h2><p>é¦–å…ˆå¤ä¹ ä¸€ä¸‹ç‚¹åˆ°å¹³é¢è·ç¦»å…¬å¼ï¼š</p><p>å¯¹å¹³é¢$C:y=a_0+a_1x_1+a_2x_2+â€¦+a_nx_n$ï¼Œä»»æ„ä¸€ä¸ªç‚¹$x=[x_1,x_2,â€¦,x_n]$åˆ°å¹³é¢çš„è·ç¦»ä¸ºï¼š</p><p>$d=\frac{|a_0+a_1x_1+a_2x_2+â€¦+a_nx_n|}{\sqrt{a_0^2+a_1^2+a_2^2+â€¦+a_n^2}}=\frac{|y(x)|}{||a||_2-a_0^2}$</p><p>å› è€Œï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°çš„ç”±$a$å†³å®šçš„åˆ†ç±»å¹³é¢åº”å½“æ˜¯ï¼š</p><p>$w,b=\arg \max \min \frac{|w^Tx+b|}{||w||_2}$</p><p>åŒæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒæ˜¯åˆ†ç±»æ­£ç¡®çš„ã€‚è™½ç„¶è·ç¦»è¶³å¤Ÿå¤§ï¼Œä½†æ˜¯ä¸ä¿è¯åˆ†ç±»æ­£ç¡®é‚£ä¸å°±æœ¬æœ«å€’ç½®äº†å—ï¼</p><p>æ‰€ä»¥åœ¨è¿™ä¸ªè¡¨è¾¾å¼ä¸­åŠ å…¥åˆ†ç±»çš„ä¿¡æ¯ï¼š</p><p>$w,b=\arg \max \min \frac{y_i(w^Tx_i+b)}{||w||_2}$</p><p>è¿™é‡Œçš„$y_i\in {-1,1}$ï¼Œè¡¨ç¤ºæ­£ç±»å’Œè´Ÿç±»ã€‚ç”±æ­¤å¯è§SVMä¹Ÿæ˜¯ä¸€ç§äºŒåˆ†ç±»ç®—æ³•ã€‚</p><p>è§‚å¯Ÿè¿™ä¸ªè¡¨è¾¾å¼ï¼Œå¦‚æœåˆ†ç±»æ­£ç¡®ï¼Œé‚£ä¹ˆ$w^Tx_i+b$å’Œ$y_i$åº”è¯¥æ˜¯åŒå·çš„ï¼Œåä¹‹æ˜¯å¼‚å·ã€‚</p><p>å› è€Œè¿™ä¸ªè¡¨è¾¾å¼æ˜¯åˆç†çš„ï¼Œå®ƒåŒæ—¶åŒ…å«äº†â€œåˆ†ç±»æ­£ç¡®â€å’Œâ€œç‚¹åˆ°å¹³é¢è·ç¦»æœ€å¤§â€çš„ç›®æ ‡ã€‚</p><h3 id="å˜æ¢"><a href="#å˜æ¢" class="headerlink" title="å˜æ¢"></a>å˜æ¢</h3><p>å¦‚æœè¯´åˆ°æ­¤ä¸ºæ­¢ï¼Œé‚£å°±å¤ªç®€å•äº†ï¼Œç„¶è€Œæ”¯æŒå‘é‡æœºè¿™åå­—è¿˜æ²¡å‡ºæ¥å‘¢ï¼</p><p><img src="/Machine-Learning-05-Support-Vector-Machine/%E5%A4%A9%E5%BA%95%E4%B8%8B%E5%93%AA%E6%9C%89%E8%BF%99%E6%A0%B7%E7%9A%84%E5%A5%BD%E4%BA%8B.jpg" alt></p><p>æ¥ç€æ¨å‘—ã€‚</p><p>å›åˆ°ä¸Šé¢è¿™ä¸ªå¼å­ï¼šæœ€å¤§åŒ–$\frac{y_i(w^Tx_i+b)}{||w||_2}$ï¼Œæ˜¯ä¸æ˜¯å•çº¯æœ€å¤§åŒ–åˆ†å­&amp;æœ€å°åŒ–åˆ†æ¯å°±å¯ä»¥äº†ï¼Ÿ</p><p>å½“ç„¶ä¸æ˜¯ã€‚å› ä¸ºä¸Šä¸‹éƒ½æœ‰$w$è¿™ä¸€é¡¹ã€‚</p><p>ä½†æ˜¯æ³¨æ„åˆ°$a$å†³å®šäº†å¹³é¢ä¹‹åï¼Œç­‰æ¯”ä¾‹åœ°ç¼©æ”¾$a$ä¸ä¼šæ”¹å˜å¹³é¢ï¼Œä½†æ˜¯å´æ”¹å˜äº†åˆ†å­åˆ†æ¯çš„å€¼ï¼Œå¯¹æˆ‘ä»¬çš„è®¡ç®—å¸¦æ¥å›°æ‰°ã€‚æˆ‘ä»¬å½“ç„¶å¸Œæœ›æ§åˆ¶çš„å˜é‡è¶Šå°‘è¶Šå¥½ï¼Œå¸Œæœ›åˆ†å­å’Œåˆ†æ¯ä¸è¦å­˜åœ¨å…³è”ï¼Œè¿™æ ·æˆ‘ä»¬åªéœ€è¦è€ƒè™‘ä¸€è¾¹å°±å¯ä»¥ã€‚</p><p>æ‰€ä»¥æˆ‘ä»¬ä»¤$y_i(w^Tx_i+b)=1$ï¼Œè¿™æ ·é—®é¢˜å°±è½¬å˜ä¸ºæ±‚$\frac{1}{||w||_2}$çš„æœ€å¤§å€¼ï¼Œä¹Ÿå°±æ˜¯æ±‚$||w||_2$çš„æœ€å°å€¼ã€‚</p><p>ç¨å¾®ä¿®æ•´è¡¨è¾¾ï¼Œé—®é¢˜è¢«æ”¹å†™ä¸ºï¼š</p><p>$\min\frac{1}{2}||w||_2^2$</p><p>$s.t. y_i(w^Tx_i+b)\ge1$</p><p>å¹³æ–¹å’Œç³»æ•°$\frac{1}{2}$æ˜¯ä¸ºäº†æ±‚å¯¼æ–¹ä¾¿å’Œå¯¼æ•°å½¢å¼æ‰€ç¡®å®šçš„ï¼Œä¸ä¼šå¯¹ç»“æœæœ‰å½±å“ã€‚</p><h3 id="æ”¯æŒå‘é‡"><a href="#æ”¯æŒå‘é‡" class="headerlink" title="æ”¯æŒå‘é‡"></a>æ”¯æŒå‘é‡</h3><p>è¯´äº†è¿™ä¹ˆå¤šï¼Œæ”¯æŒå‘é‡åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ</p><p>ç¨å¾®æŠ½è±¡åŒ–åœ°æƒ³ä¸€æƒ³ï¼šæˆ‘ä»¬çš„å¹³é¢æ˜¯è¢«ç©ºé—´ä¸­çš„ç‚¹â€œæ”¯æ’‘â€èµ·æ¥çš„ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ä¿æŒä¸€å®šçš„è·ç¦»ã€‚å°±åƒç£é“çš„ä¸¤æç›¸æ–¥ä¸€æ ·ï¼Œå¹³é¢å—åˆ°äº†ç‚¹çš„æ–¥åŠ›è€Œæ ‘ç«‹èµ·æ¥ã€‚</p><p>æ‰€ä»¥ï¼Œè¿™äº›ç‚¹å°±å«åšâ€œæ”¯æŒå‘é‡â€</p><p>è€Œå› ä¸ºæˆ‘ä»¬åªè€ƒè™‘æœ€è¿‘çš„ç‚¹æ¥è®¡ç®—ç‚¹åˆ°å¹³é¢çš„è·ç¦»æœ€å°å€¼ï¼Œæ‰€ä»¥æ”¯æŒå‘é‡æŒ‡çš„æ˜¯é è¿‘å¹³é¢çš„é‚£äº›ç‚¹ã€‚</p><p>æ‰€ä»¥é€‰å–ç‚¹çš„ä¸ªæ•°ä¹Ÿæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå®ƒå‡å°‘äº†è®¡ç®—é‡ï¼ˆåŸæœ¬æ˜¯å¯¹æ¯ä¸€ä¸ªç‚¹éƒ½è¿›è¡Œè®¡ç®—ï¼‰ã€‚</p><h2 id="è½¯é—´éš”"><a href="#è½¯é—´éš”" class="headerlink" title="è½¯é—´éš”"></a>è½¯é—´éš”</h2><p>è¯´å®Œäº†åŸºæœ¬çš„ç†è®ºéƒ¨åˆ†ï¼Œæ¥ä¸‹æ¥è¦å¯¹ç®—æ³•è¿›è¡Œæ‰¹åˆ¤äº†ã€‚</p><p>è®¾æƒ³ä¸€ä¸‹ï¼Œç›®å‰çš„æ”¯æŒå‘é‡æœºç®—æ³•æ˜¯å»ºç«‹åœ¨â€œæ•°æ®çº¿æ€§å¯åˆ†â€çš„åŸºç¡€ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰çš„ç‚¹éƒ½èƒ½å¤Ÿåˆ†ç±»åœ¨å¹³é¢ä¸¤ä¾§ã€‚</p><p>å‡å¦‚å› ä¸ºæ ‡æ³¨é”™è¯¯æˆ–è€…åˆ«çš„ç‰¹æ®Šæƒ…å†µï¼Œæ•°æ®ä¸­æœ‰é‚£ä¹ˆå‡ ä¸ªç‚¹ä¸å°å¿ƒåˆ†é”™äº†ï¼Œè·‘åˆ°å¹³é¢çš„å¦ä¸€ä¾§å»äº†å‘¢ï¼Ÿ</p><p>å¯¹è¿™äº›ç‚¹ï¼Œæˆ‘ä»¬çš„ç®—æ³•ç¼ºå°‘ä¸€å®šçš„å®¹å¿æ€§ï¼ˆé²æ£’æ€§ï¼‰ï¼Œä¼šè¢«è¿™äº›ç‚¹ï¼ˆå¦‚æœå®ƒä»¬åˆåˆšå¥½è¶³å¤Ÿè¿‘ï¼Œä¼šè¢«é€‰æ‹©æˆä¸ºæ”¯æŒå‘é‡ï¼‰ï¼Œé‚£ä¹ˆå°±ä¼šè¢«å®ƒä»¬å¸¦åâ€”â€”æ‰€ä»¥è¯´ï¼Œä¸€é¢—è€é¼ å±åäº†ä¸€é”…ç²¥å•Šã€‚</p><p>ä¸‹é¢å°±ä»‹ç»ä¸€ä¸ªè¡¥æ•‘æªæ–½ï¼š</p><h3 id="æ¾å¼›å˜é‡"><a href="#æ¾å¼›å˜é‡" class="headerlink" title="æ¾å¼›å˜é‡"></a>æ¾å¼›å˜é‡</h3><p>åœ¨åº”å¯¹è¿‘ä¼¼çº¿æ€§å¯åˆ†çš„é—®é¢˜çš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦ç¨å¾®æ”¾æ¾è¦æ±‚ï¼Œå…è®¸æ”¯æŒå‘é‡çš„ç‚¹åˆ°å¹³é¢çš„è·ç¦»ç¨å¾®è¿‘ä¸€ç‚¹ã€‚</p><p>åœ¨å…¬å¼ä¸Šæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå˜é‡ï¼Œå«åšæ¾å¼›å˜é‡ï¼ˆSlack variableï¼‰ï¼š</p><p>$min\frac{1}{2}||w||<em>2^2+C\Sigma</em>{i=1}^n\epsilon_i$$</p><p>$s.t.y(w^Tx_i+b)\ge 1-\epsilon_i,$$</p><p>$\epsilon_i\ge0$</p><p>è¿™é‡Œï¼Œ$C$æ˜¯ç”¨æ¥æ§åˆ¶åŸç›®æ ‡ï¼ˆæœ€å°åŒ–$w$ï¼‰å’Œæ–°ç›®æ ‡ä¹‹é—´ï¼ˆä¿è¯å°½é‡å¤šçš„marginå¤§äºç­‰äº1ï¼‰çš„æƒé‡çš„ï¼Œ</p><p>ä¸è¿™ä¸ªåšæ³•ç›¸å¯¹çš„ï¼Œæˆ‘ä»¬åŸæ¥çš„åšæ³•å°±å«åšç¡¬é—´éš”ï¼ˆHard marginï¼‰ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>æ”¯æŒå‘é‡æœºçš„ç†è®ºè¿˜ä¸æ­¢è¿™äº›å†…å®¹ï¼Œä½†æ˜¯ç›®å‰æŒæ¡çš„çŸ¥è¯†è¶³å¤Ÿæˆ‘ä»¬å®ç°ä¸€ä¸ªç®€æ˜“çš„æ”¯æŒå‘é‡æœºäº†ã€‚</p><p>æœ¬æ¬¡å®ç°äº†ç®€åŒ–çš„SVMç®—æ³•ï¼Œç”¨åˆ°scipyåº“çš„ä¼˜åŒ–å‡½æ•°å–æœ€å°ç‚¹æ¥å®ŒæˆäºŒæ¬¡è§„åˆ’çš„éƒ¨åˆ†ã€‚</p><p>ä»£ç ä¸­å·²ç»ç»™å‡ºéƒ¨åˆ†æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚å…¶ä»–è¯¦æƒ…è¯·è§æˆ‘çš„<a href="https://github.com/Riroaki/LemonML/">repo</a>ã€‚</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> supervised<span class="token punctuation">.</span>_base <span class="token keyword">import</span> LinearModel<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> minimize<span class="token keyword">class</span> <span class="token class-name">SVM</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Support vector machine model, binary classifier."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Target and constraint functions</span>        <span class="token keyword">def</span> <span class="token function">target</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">get_func</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token keyword">lambda</span> w<span class="token punctuation">:</span> w<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x_ext<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> label<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment" spellcheck="true"># Target and constraint functions with slack variables</span>        <span class="token keyword">def</span> <span class="token function">target_slack</span><span class="token punctuation">(</span>w_e<span class="token punctuation">)</span><span class="token punctuation">:</span>            w <span class="token operator">=</span> w_e<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>p <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>            eps <span class="token operator">=</span> w_e<span class="token punctuation">[</span><span class="token punctuation">(</span>p <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span>            <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> c <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>eps<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">get_func_slack_w</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token keyword">lambda</span> w_e<span class="token punctuation">:</span> w_e<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>p <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x_ext<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span> \                               <span class="token operator">*</span> label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">+</span> w_e<span class="token punctuation">[</span>p <span class="token operator">+</span> i<span class="token punctuation">]</span>        <span class="token keyword">def</span> <span class="token function">get_func_slack_e</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token keyword">lambda</span> w_e<span class="token punctuation">:</span> w_e<span class="token punctuation">[</span>p <span class="token operator">+</span> i<span class="token punctuation">]</span>        <span class="token keyword">assert</span> np<span class="token punctuation">.</span>array_equal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># No slack parameters unless explicitly stated</span>        slack <span class="token operator">=</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> kwargs <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Update parameters of training</span>            self<span class="token punctuation">.</span>_update_params<span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># Whether to use slack variables</span>            <span class="token keyword">if</span> <span class="token string">'slack'</span> <span class="token keyword">in</span> kwargs<span class="token punctuation">:</span>                <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>kwargs<span class="token punctuation">[</span><span class="token string">'slack'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bool<span class="token punctuation">)</span>                slack <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'slack'</span><span class="token punctuation">]</span>        w_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span><span class="token punctuation">)</span>        x_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Find optimum w and b for both condition</span>        <span class="token keyword">if</span> <span class="token operator">not</span> slack<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># SVM without slack</span>            <span class="token comment" spellcheck="true"># Optimize 1/2 w^T * w</span>            <span class="token comment" spellcheck="true"># s.t. yi * (w^T * xi + b) - 1 >= 0</span>            cons <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'type'</span><span class="token punctuation">:</span> <span class="token string">'ineq'</span><span class="token punctuation">,</span> <span class="token string">'fun'</span><span class="token punctuation">:</span> get_func<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># Find optimized w</span>            w_ext <span class="token operator">=</span> minimize<span class="token punctuation">(</span>target<span class="token punctuation">,</span> w_ext<span class="token punctuation">,</span> constraints<span class="token operator">=</span>cons<span class="token punctuation">)</span><span class="token punctuation">.</span>x        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># SVM with slack</span>            <span class="token comment" spellcheck="true"># Optimize 1/2 w^T * w + C * sum(eps_i)</span>            <span class="token comment" spellcheck="true"># s.t. yi * (w^T * xi + b) - 1 + eps_i >= 0, eps_i >= 0</span>            c<span class="token punctuation">,</span> w_and_eps <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>w_ext<span class="token punctuation">,</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            cons <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> idx <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>                cons<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'type'</span><span class="token punctuation">:</span> <span class="token string">'ineq'</span><span class="token punctuation">,</span> <span class="token string">'fun'</span><span class="token punctuation">:</span> get_func_slack_w<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>                cons<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'type'</span><span class="token punctuation">:</span> <span class="token string">'ineq'</span><span class="token punctuation">,</span> <span class="token string">'fun'</span><span class="token punctuation">:</span> get_func_slack_e<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>            cons <span class="token operator">=</span> tuple<span class="token punctuation">(</span>cons<span class="token punctuation">)</span>            w_and_eps <span class="token operator">=</span> minimize<span class="token punctuation">(</span>target_slack<span class="token punctuation">,</span> w_and_eps<span class="token punctuation">,</span> constraints<span class="token operator">=</span>cons<span class="token punctuation">)</span><span class="token punctuation">.</span>x            w_ext <span class="token operator">=</span> w_and_eps<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>p <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Update and save optimal weights &amp; bias</span>        self<span class="token punctuation">.</span>_w <span class="token operator">=</span> w_ext<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>_b <span class="token operator">=</span> w_ext<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Calculate loss</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_label    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        precision <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred_label <span class="token operator">-</span> label<span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_value</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> w<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>                       b<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_val <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b        <span class="token keyword">return</span> pred_val    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_label</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_label <span class="token operator">=</span> np<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        pred_label<span class="token punctuation">[</span>pred_label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>        <span class="token keyword">return</span> pred_label    @staticmethod    <span class="token keyword">def</span> <span class="token function">_loss</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> true_label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Hinge loss</span>        loss <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> pred_val <span class="token operator">*</span> true_label        loss<span class="token punctuation">[</span>loss <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>        loss <span class="token operator">=</span> loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>              true_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Use scipy.optmize to find best w and b</span>        <span class="token comment" spellcheck="true"># Not grad-base method</span>        <span class="token keyword">return</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Go-beyond-SVM"><a href="#Go-beyond-SVM" class="headerlink" title="Go beyond SVM"></a>Go beyond SVM</h2><p>ä¸ºäº†è¯´æ˜é—®é¢˜çš„æœ¬è´¨ï¼Œæˆ‘ä»¬éœ€è¦æŠŠSVMè½¬æ¢ä¸ºæ›´ä¸€èˆ¬çš„å½¢å¼ã€‚</p><p>ä¼˜åŒ–é—®é¢˜å¾€å¾€éœ€è¦æŠŠé—®é¢˜çš„é™åˆ¶å»é™¤æˆ–è€…è½¬åŒ–ä¸ºå¯è®¡ç®—çš„å½¢å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¹ä¸Šé¢çš„é—®é¢˜è¡¨è¿°å†åšè½¬åŒ–ï¼š</p><p>$\epsilon_i\ge1-y_i(w^Tx_i+b)\\epsilon_i=max[1-y_i(w^Tx_i+b),0]$</p><p>æ‰€ä»¥ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºï¼š$\min{\Sigma_{i=1}^n\max[1-y_i(w^Tx_i+b),0]+\frac{1}{2C}||w||_2^2}$</p><p>è¿™ä¸ªå½¢å¼ï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹åƒæ­£åˆ™åŒ–çš„çº¿æ€§å›å½’ï¼Ÿ</p><p>å·¦ä¾§çœ‹ä½œç›®æ ‡å‡½æ•°ï¼Œå³ä¾§çœ‹ä½œRidgeæ­£åˆ™é¡¹ï¼Œåˆ™ç›®æ ‡å‡½æ•°$l(f)=\max[1-yf,0]$</p><ul><li><p>çº¿æ€§å›å½’çš„ç›®æ ‡ï¼š$l(f)=(y-f)^2=(1-yf)^2$</p></li><li><p>é€»è¾‘å›å½’çš„ç›®æ ‡ï¼š$l(f)=log(1+e^{-yf})$</p></li></ul><h3 id="çº¿æ€§åˆ†ç±»å™¨çš„ä¸€èˆ¬å½¢å¼"><a href="#çº¿æ€§åˆ†ç±»å™¨çš„ä¸€èˆ¬å½¢å¼" class="headerlink" title="çº¿æ€§åˆ†ç±»å™¨çš„ä¸€èˆ¬å½¢å¼"></a>çº¿æ€§åˆ†ç±»å™¨çš„ä¸€èˆ¬å½¢å¼</h3><p>ç”±ä¸Šè¿°è¡¨ç¤ºæˆ‘ä»¬å¯ä»¥å½’çº³å‡ºçº¿æ€§åˆ†ç±»å™¨çš„é—®é¢˜ä¸€èˆ¬å½¢å¼ï¼š</p><p>$\min{\Sigma_{i=1}^nl(f)+\lambda R(f)}$</p><p>å…¶ä¸­$l(f)$ä¸ºæŸå¤±å‡½æ•°ï¼Œ$R(f)$ä¸ºæ­£åˆ™é¡¹ã€‚</p><p>ä¸Šè¿°æ¨¡å‹åˆ†åˆ«å¯¹åº”ä»¥ä¸‹ï¼š</p><ul><li>æŸå¤±å‡½æ•°<ul><li>çº¿æ€§å›å½’ï¼šSquare loss</li><li>é€»è¾‘å›å½’ï¼šLogistic loss</li><li>SVMï¼šHinge loss</li></ul></li><li>æ­£åˆ™é¡¹<ul><li>Ridgeï¼šL2-regularizer</li><li>Lassoï¼šL1-regularizer</li></ul></li></ul><p>ä¸åŒæŸå¤±å‡½æ•°å…³äº$yf$çš„å›¾åƒï¼š</p><p>BTWï¼ŒHinge losså«åšåˆå¶å‡½æ•°ï¼Œæ­£æ˜¯å› ä¸ºå®ƒçš„å½¢çŠ¶å°±åƒæ‰“å¼€çš„åˆå¶ã€‚</p><p><img src="/Machine-Learning-05-Support-Vector-Machine/loss.png" alt></p><h2 id="éçº¿æ€§SVMï¼šæ ¸å‡½æ•°"><a href="#éçº¿æ€§SVMï¼šæ ¸å‡½æ•°" class="headerlink" title="éçº¿æ€§SVMï¼šæ ¸å‡½æ•°"></a>éçº¿æ€§SVMï¼šæ ¸å‡½æ•°</h2><p>åˆšæ‰æˆ‘ä»¬è§£å†³çº¿æ€§é—®é¢˜ï¼Œé‚£ä¹ˆSVMçš„èƒ½åŠ›å°±ä»…æ­¤è€Œå·²äº†å˜›ï¼Ÿ</p><p>èƒ½ä¸èƒ½å¯¹éçº¿æ€§æ•°æ®ä¹Ÿåšæ‹Ÿåˆï¼Ÿ</p><blockquote><p><strong>To be continuedâ€¦</strong></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬äº”ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ”¯æŒå‘é‡æœºçš„è¯¦ç»†ç†è®ºå’Œå®ç°ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-04ï¼šé€»è¾‘å›å½’</title>
    <link href="http://riroaki.github.io/Machine-Learning-04-Logistic-Regression/"/>
    <id>http://riroaki.github.io/Machine-Learning-04-Logistic-Regression/</id>
    <published>2019-06-24T16:00:00.000Z</published>
    <updated>2019-07-02T16:46:30.795Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å››ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†é€»è¾‘åˆ†ç±»çš„è¯¦ç»†ç†è®ºå’Œå®ç°ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>ä¸Šå›è¯´åˆ°çº¿æ€§å›å½’ç›¸å…³çš„ç†è®ºï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥å°±é¡ºç€çº¿æ€§å›å½’è®²è§£çº¿æ€§åˆ†ç±»å™¨ã€‚</p><p>çº¿æ€§åˆ†ç±»å™¨æ˜¯æŒ‡åˆ†ç±»å‡½æ•°ç¬¦åˆ$y=w^Tx+b$å½¢å¼çš„ä¸€ç³»åˆ—åˆ¤åˆ«æ¨¡å‹ï¼Œä¸»è¦åŒ…æ‹¬é€»è¾‘å›å½’ã€æ”¯æŒå‘é‡æœºã€æ„ŸçŸ¥æœºç­‰ï¼Œæ¥ä¸‹æ¥ä¼šé¦–å…ˆä»‹ç»ä¸‰ä¸ªçº¿æ€§åˆ†ç±»å™¨æœ¬èº«ï¼Œå†ä¼šä»‹ç»çº¿æ€§åˆ†ç±»å™¨æ›´ä¸ºä¸€èˆ¬çš„å½¢å¼å’Œå¹¿æ³›çš„è”ç³»ã€‚</p><h2 id="é€»è¾‘å›å½’ç†è®º"><a href="#é€»è¾‘å›å½’ç†è®º" class="headerlink" title="é€»è¾‘å›å½’ç†è®º"></a>é€»è¾‘å›å½’ç†è®º</h2><p>é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰è™½ç„¶æ˜¯å«å›å½’ï¼Œä½†æ˜¯å®é™…ä¸Šæ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ã€‚</p><p>é€»è¾‘å›å½’å¾—åäºé€»è¾‘å‡½æ•°ï¼ˆLogistic Funtionï¼‰ï¼Œä¹Ÿå«åšSå‡½æ•°ï¼ˆSigmoid Functionï¼‰ã€‚</p><h3 id="é€»è¾‘å‡½æ•°"><a href="#é€»è¾‘å‡½æ•°" class="headerlink" title="é€»è¾‘å‡½æ•°"></a>é€»è¾‘å‡½æ•°</h3><p>$\sigma(t)=\frac{e^t}{1+e^t}=\frac{1}{1+e^{-t}}$</p><p>è¿™ä¸ªå‡½æ•°å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š</p><ul><li>å¯ä»¥å°†$(-\infty,+\infty)$ä¹‹é—´çš„è¾“å…¥å€¼æ˜ å°„åˆ°$(0,1)$åŒºé—´</li><li>å‘ˆç°Så½¢ï¼Œå•è°ƒé€’å¢ï¼šè¾“å…¥å€¼ä¸ºè´Ÿæ—¶è¾“å‡ºåœ¨$(0,0.5)$ä¹‹é—´ï¼Œéè´Ÿè¾“å‡ºä¸º$[0.5,1)$ã€‚</li></ul><p>ä¸€å›¾èƒœåƒè¨€ï¼š</p><p><img src="/Machine-Learning-04-Logistic-Regression/logistic.png" alt></p><p>è¿™ä¸ªå‡½æ•°ä¹Ÿæ˜¯<a href="https://en.wikipedia.org/wiki/Logistic_distribution">é€»è¾‘åˆ†å¸ƒ</a>çš„ç´¯è®¡åˆ†å¸ƒå‡½æ•°ã€‚</p><p>é€»è¾‘å›å½’ä½¿ç”¨é€»è¾‘å‡½æ•°ä¼°è®¡è¾“å…¥å‚æ•°ä¸ç±»å˜é‡çš„æ¦‚ç‡ï¼Œæœ€ä¸€èˆ¬çš„å½¢å¼ä¸ºäºŒåˆ†ç±»ï¼š</p><ul><li>$P(y_i=1|x_i,a)=\sigma(a^Tx_i)=\frac{1}{1+e^{-a^Tx_i}}$</li><li>$P(y_i=-1|x_i,a)=1-\sigma(a^Tx_i)=\frac{1}{1+e^{a^Tx_i}}$</li></ul><p>åˆå¹¶äºŒå¼ï¼Œæœ‰ï¼š$P(y_i|x_i,a)=\sigma(y_ia^Tx_i)=\frac{1}{1+e^{-y_ia^Tx_i}}$</p><p>æˆ–è€…ï¼š$P(y_i|x_i,a)=y_i\sigma(a^Tx_i)+(1-y_i)(1-\sigma(a^Tx_i))=y_i\frac{1}{1+e^{-a^Tx_i}}+(1-y_i)(1-\frac{1}{1+e^{-a^Tx_i}})$ï¼Œ</p><p>æˆ–è€…ï¼š$P(y_i|x_i,a)=\sigma(a^Tx_i)^{y_i}(1-\sigma(a^Tx_i))^{1-y_i}=â€¦$</p><blockquote><p>P.S.å…¶å®åˆå¹¶å¾—åˆ°çš„å¼å­æˆ‘æ„Ÿè§‰æ˜¯å‡‘å‡ºæ¥çš„â€¦â€¦</p></blockquote><p>è¿™å°±æ˜¯æœ€åŸºæœ¬çš„é€»è¾‘å›å½’çš„å½¢å¼ã€‚</p><p>è¿™ä¸ªå¼å­ä¹Ÿéšå«ç€ï¼šåˆ¤æ–­æ˜¯ç±»1çš„æ¦‚ç‡å’Œç±»2çš„æ¦‚ç‡ä¹‹å’Œä¸º1ã€‚</p><p>å¦å¤–ï¼Œè¿™ä¸¤ä¸ªå¼å­è¿˜å…·æœ‰ä¸€ä¸ªè§„å¾‹ï¼š</p><p>$\frac{P(y_i=1|x_i,a)}{P(y_i=-1|x_i,a)}\ln\frac{\sigma(a^Tx_i)}{1-\sigma(a^Tx_i)}=a^Tx_i$ï¼Œæ‰€ä»¥é€»è¾‘å›å½’ä¹Ÿå«åšå¯¹æ•°å‡ ç‡å›å½’ã€‚</p><p>å®é™…åˆ¤æ–­çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šæŠŠè¾“å‡ºå¤§äº0.5çš„åˆ†ç±»ä½œä¸ºæ­£ç±»ï¼Œè¾“å‡ºå°äº0.5çš„å€¼çš„åˆ†ç±»ä½œä¸ºè´Ÿç±»ï¼Œä»è€Œå­¦ä¹ åˆ°ä¸€ä¸ªå‚æ•°ä¸º$w,b$çš„æ¨¡å‹ã€‚</p><h2 id="ç›®æ ‡å‡½æ•°"><a href="#ç›®æ ‡å‡½æ•°" class="headerlink" title="ç›®æ ‡å‡½æ•°"></a>ç›®æ ‡å‡½æ•°</h2><p>å¦‚ä½•è¯„ä»·æ¨¡å‹ï¼Œå†³å®šäº†æˆ‘ä»¬è·å–å‚æ•°çš„æ–¹å¼ã€‚</p><p>åœ¨è¿™é‡Œï¼Œå¯¹äºé€»è¾‘å›å½’è¿™ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ä½œä¸ºç›®æ ‡å‡½æ•°ï¼š</p><p>æˆ‘ä»¬æœ‰å¯¹å•ä¸ªè¾“å…¥çš„æ¦‚ç‡ä¼°è®¡$P(y_i=\pm1|x_i,a)$ï¼ˆè¿™é‡Œä½¿ç”¨ä¸Šé¢çš„<strong>ç¬¬ä¸‰ä¸ª</strong>å¼å­ï¼‰ï¼Œé‚£ä¹ˆå¯¹å…¨ä½“çš„æ•°æ®é›†$D$ï¼Œæ€»çš„æ¦‚ç‡ä¼°è®¡ä¸ºï¼š</p><p>$P(D)=\prod_{i\in I}P(y_i|x_i,a)=\prod_{i\in I}(\sigma(a^Tx_i)^{y_i}(1-\sigma(a^Tx_i))^{1-y_i})$</p><p>è¿™æ˜¯ä¸€ä¸ªå…³äº$a$çš„å‡½æ•°,æˆ‘ä»¬å¸Œæœ›$P(D)$å–æå¤§ï¼Œä¹Ÿå°±æ˜¯ä¼°è®¡æ­£ç¡®çš„æ¦‚ç‡è¾¾åˆ°æœ€å¤§ã€‚</p><p>å› è€Œï¼Œéœ€è¦å¯¹$P(D)$å…³äº$a$æ±‚å¯¼ã€‚ä½†æ˜¯ï¼Œè¿ä¹˜çš„å½¢å¼éš¾ä»¥æ±‚å¯¼ï¼Œæ‰€ä»¥æˆ‘ä»¬é€šè¿‡å–å¯¹æ•°æŠŠå‡½æ•°å½¢å¼è½¬åŒ–ä¸ºè¿åŠ â€”â€”è¿™åœ¨ä¹‹å‰çš„å†…å®¹ä¹ŸæåŠäº†ã€‚</p><p>$l(P(D))=\Sigma_{i\in I}y_ilog(\sigma(a^Tx_i))+(1-y_i)log(1-\sigma(a^Tx_i))$</p><p>å› ä¸ºè¿™ä¸ªå‡½æ•°æ˜¯å‡¹çš„ï¼Œæˆ–è€…è¯´æ˜¯ä¸Šå‡¸çš„ï¼Œæˆ‘ä»¬å†è¿›è¡Œä¸€æ¬¡è½¬æ¢ï¼š$E(a)=-\frac{1}{m}l(P(D))$ï¼Œå¯ä»¥è¯æ˜ï¼Œ$E(a)$æ˜¯ä¸€ä¸ªå¯å¯¼çš„å‡¸å‡½æ•°ã€‚</p><p>é‚£ä¹ˆç›®æ ‡å‡½æ•°å°±å˜ä¸º$E(a)$ï¼Œæˆ‘ä»¬è¦æ±‚å…¶æœ€å°å€¼ã€‚</p><blockquote><p>æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åœ¨ä¹‹å‰çš„å†…å®¹å·²ç»å‡ºç°è¿‡ï¼Œä¸è¿‡è¿™é‡Œçš„å½¢å¼ä¸è´å¶æ–¯åˆ†ç±»å™¨ä¸­çš„æå¤§ä¼¼ç„¶ä¼°è®¡ç¨æœ‰ä¸åŒï¼Œå› ä¸ºè¿™é‡Œçš„ä¼°è®¡ä¸­ï¼Œ<strong>æ¦‚ç‡å°±æ˜¯ä¼¼ç„¶</strong>ï¼Œæå¤§ä¼¼ç„¶ä¼°è®¡æ˜¯å¯¹æ¦‚ç‡ä¸å®é™…åˆ†å¸ƒå…³ç³»ä½œåˆ†æï¼›è€Œè´å¶æ–¯åˆ†ç±»å™¨ä¸­ï¼Œæå¤§ä¼¼ç„¶ä¼°è®¡å°±æ˜¯å¯¹ä¼¼ç„¶ä¸å®é™…åˆ†å¸ƒçš„å…³ç³»ä½œåˆ†æï¼ˆå½“ç„¶ï¼Œä»å¦ä¸€ä¸ªè§’åº¦ï¼Œä¼¼ç„¶å°±æ˜¯åéªŒæ¦‚ç‡ï¼‰ã€‚</p></blockquote><h2 id="å‚æ•°ä¼°è®¡"><a href="#å‚æ•°ä¼°è®¡" class="headerlink" title="å‚æ•°ä¼°è®¡"></a>å‚æ•°ä¼°è®¡</h2><p>é¦–å…ˆå¯¹$E(a)$è¿›è¡Œå˜æ¢ï¼š</p><p>$E(a)=-\frac{1}{m}\sum_{i=1}^{m}[y_ilog(\frac{e^{a^Tx_i}}{1+e^{^{a^Tx_i}}})+(1-y_i)log(\frac{1}{1+e^{a^Tx_i}})]$</p><p>$=-\frac{1}{m}\Sigma_{i=1}^m[y_ia^Tx_i+log(1+e^{a^Tx_i})]$</p><p>æ¥ä¸‹æ¥æ±‚æ¢¯åº¦ï¼š</p><p>$\frac{\partial E(a)}{\partial a}=-\frac{1}{m}\Sigma_{i=1}^m[y_ix_i-\frac{e^{a^Tx_i}}{1+e^{a^Tx_i}}x_i]$</p><p>$=-\frac{1}{m}\Sigma_{i=1}^m[y_ix_i-\sigma(a^Tx_i)x_i]$</p><p>è®°$\sigma(a^Tx_i)$ä¸º$h_a(x_i)$ï¼Œé‚£ä¹ˆä¸Šå¼åˆå¯ä»¥è¡¨ç¤ºä¸ºï¼š$-\frac{1}{m}\Sigma_{i=1}^m[(y_i-h_a(x_i))x_i]$</p><blockquote><p>è”æƒ³ä¸€ä¸‹çº¿æ€§å›å½’çš„æ¢¯åº¦ï¼š$\frac{\partial E(a)}{\partial a}=-\frac{1}{m}\Sigma_{i=1}^m[(y_i-wx_i+b)x_i]$ï¼Œ</p><p>å¯ä»¥è¯´å½¢å¼éå¸¸ç›¸ä¼¼äº†ã€‚</p></blockquote><p>é‚£ä¹ˆå’Œçº¿æ€§å›å½’ç›¸ä¼¼çš„ï¼Œæˆ‘ä»¬è¯•ç€ç”¨ä¸¤ç§æ–¹å¼æ±‚è§£ï¼š</p><h3 id="æ­£è§„æ–¹ç¨‹"><a href="#æ­£è§„æ–¹ç¨‹" class="headerlink" title="æ­£è§„æ–¹ç¨‹"></a>æ­£è§„æ–¹ç¨‹</h3><p>è®©æ¢¯åº¦ä¸º0ï¼Œæˆ‘ä»¬æœ‰ï¼š$y_i=\frac{1}{1+e^{-a^Tx_i}}$</p><p>é¦–å…ˆä»¤$z_i=a^Tx_i$ï¼Œæˆ‘ä»¬æœ‰ï¼š$y_i=\frac{1}{1+e^{-z_i}}$</p><p>æ‰€ä»¥$z_i=-log(\frac{1}{y_i}-1)=log(y_i)-log(1-y_i)$</p><p>é‚£ä¹ˆæˆ‘ä»¬æœ‰$a^Tx_i=log(y_i)-log(1-y_i)$</p><p>çœ‹èµ·æ¥æ˜¯æ²¡é”™ï¼Œé‚£ä¹ˆèƒ½ä¸èƒ½ä»£å…¥ï¼Œé€šè¿‡æ±‚è§£æ–¹ç¨‹ç»„å¾—åˆ°$a$å‘¢ï¼Ÿ</p><p><strong>å¾ˆé—æ†¾ï¼Œä¸èƒ½ã€‚</strong></p><p>æˆ‘ä»¬å¾ˆå¿«å°±ä¼šæ³¨æ„åˆ°ï¼Œå¯¹äº$y_i=0,1$ï¼Œä¸Šé¢è¿™ä¸ªå¼å­æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚</p><p>é‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½ç”¨è¿™ä¸ªæ–¹å¼æ±‚è§£å‘¢ï¼Ÿ<strong>å› ä¸ºæ¢¯åº¦æ˜¯ä¸ä¼šç­‰äº0çš„</strong>ï¼š$\sigma(z_i)$æ˜¯ä¸å¯èƒ½è¾¾åˆ°$0,1$çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è‡³å¤šæ˜¯æŠŠæ¢¯åº¦é™ä½ï¼Œæ°¸è¿œä¸ä¼šå‡ºç°$y_i=\frac{1}{1+e^{-a^Tx_i}}$çš„ç»“æœã€‚</p><p>æ‰€ä»¥ï¼Œæ­£è§„æ–¹ç¨‹è§£æ˜¯ä¸å­˜åœ¨çš„ã€‚</p><h3 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h3><p>é‚£ä¹ˆå¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£ã€‚</p><p>æ¢¯åº¦ä»£å…¥å³å¯ï¼Œç±»ä¼¼çº¿æ€§å›å½’çš„è§£ï¼š</p><p>$grad = \alpha * -\frac{1}{m}\Sigma_{i=1}^m[(y_i-wx_i+b)x_i]$</p><p>$a-=grad$</p><h2 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h2><p>å†…å®¹ç›¸ä¼¼ï¼Œå‚è§ä¸Šä¸€ç¯‡æ–‡ç« ï¼ˆ<a href="/Machine-Learning-03-Linear-Regression">çº¿æ€§å›å½’</a>ï¼‰çš„æœ‰å…³å†…å®¹ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>åˆåˆ°äº†ä»£ç å®ç°ç¯èŠ‚ã€‚</p><p>è¿™é‡Œå®ç°äº†æœ€åŸºæœ¬çš„é€»è¾‘å›å½’<code>LogisticRegression</code>ç±»ï¼ˆä¸åŒ…å«æ­£åˆ™åŒ–éƒ¨åˆ†ï¼‰ã€‚</p><p>ä»£ç ä¸­åŒ…å«éƒ¨åˆ†æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚å…¶ä»–è¯¦æƒ…è§æˆ‘çš„<a href="https://github.com/Riroaki/LemonML">repo</a>ã€‚</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> supervised<span class="token punctuation">.</span>_base <span class="token keyword">import</span> LinearModel<span class="token keyword">from</span> utils <span class="token keyword">import</span> batch<span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Logistic regression model, binary classifier."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Check labels: only containing 1 and 0</span>        <span class="token keyword">assert</span> np<span class="token punctuation">.</span>array_equal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token keyword">if</span> kwargs <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Update parameters of training</span>            self<span class="token punctuation">.</span>_update_params<span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span>        iters<span class="token punctuation">,</span> loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true"># Iterates till converge or iterating times exceed bound</span>        <span class="token keyword">while</span> iters <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_iter_bound<span class="token punctuation">:</span>            iters <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment" spellcheck="true"># Update weights using mini-batch gradient desent</span>            <span class="token keyword">for</span> batch_x<span class="token punctuation">,</span> batch_label <span class="token keyword">in</span> batch<span class="token punctuation">(</span>x<span class="token punctuation">,</span> label<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>                pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>                loss <span class="token operator">+=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> batch_label<span class="token punctuation">)</span> <span class="token operator">*</span> batch_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                grad_w<span class="token punctuation">,</span> grad_b <span class="token operator">=</span> self<span class="token punctuation">.</span>_grad<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> pred_val<span class="token punctuation">,</span> batch_label<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>_w <span class="token operator">-=</span> grad_w                self<span class="token punctuation">.</span>_b <span class="token operator">-=</span> grad_b            loss <span class="token operator">/=</span> n            <span class="token comment" spellcheck="true"># Break if model converges.</span>            <span class="token keyword">if</span> loss <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>_loss_tol<span class="token punctuation">:</span>                <span class="token keyword">break</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_label    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_label<span class="token punctuation">(</span>pred_val<span class="token punctuation">)</span>        precision <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred_label <span class="token operator">-</span> label<span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_value</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> w<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>                       b<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__sigmoid</span><span class="token punctuation">(</span>raw<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>            res <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>raw<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> res        prob <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b        pred_val <span class="token operator">=</span> __sigmoid<span class="token punctuation">(</span>prob<span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_val    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_label</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_label <span class="token operator">=</span> np<span class="token punctuation">.</span>sign<span class="token punctuation">(</span>pred_val <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span>        pred_label<span class="token punctuation">[</span>pred_label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>        pred_label<span class="token punctuation">[</span>pred_label <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">return</span> pred_label    @staticmethod    <span class="token keyword">def</span> <span class="token function">_loss</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> true_label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Use maximum likelihood (log-likelihood loss)</span>        <span class="token comment" spellcheck="true"># loss = 1 / n * (-y * log(wx + b) - (1 - y) * log(wx + b))</span>        <span class="token comment" spellcheck="true"># Here we need to care about the log zero and overflow warning...</span>        mask_val <span class="token operator">=</span> pred_val<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>        mask_val<span class="token punctuation">[</span>mask_val <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span>        mask_val<span class="token punctuation">[</span>mask_val <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span>        class1_loss <span class="token operator">=</span> <span class="token operator">-</span>true_label <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>mask_val<span class="token punctuation">)</span>        class0_loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> true_label<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> mask_val<span class="token punctuation">)</span>        loss <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>class0_loss <span class="token operator">+</span> class1_loss<span class="token punctuation">)</span> <span class="token operator">/</span> true_label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>              true_label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#  dc / dw = x * (pred_val - true_label)</span>        grad_w <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">*</span> <span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_label<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        grad_b <span class="token operator">=</span> <span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_label<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Use simple gradient by multiplying learning rate and grad.</span>        grad_w <span class="token operator">*=</span> self<span class="token punctuation">.</span>_learn_rate        grad_b <span class="token operator">*=</span> self<span class="token punctuation">.</span>_learn_rate        <span class="token keyword">return</span> grad_w<span class="token punctuation">,</span> grad_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="æ¨å¹¿ï¼šä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»"><a href="#æ¨å¹¿ï¼šä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»" class="headerlink" title="æ¨å¹¿ï¼šä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»"></a>æ¨å¹¿ï¼šä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»</h2><p>è§æœ¬ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« ï¼ˆ<a href="/Machine-Learning-01-Overview-2">æœºå™¨å­¦ä¹ æ¦‚å¿µ</a>ï¼‰</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å››ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†é€»è¾‘åˆ†ç±»çš„è¯¦ç»†ç†è®ºå’Œå®ç°ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-03ï¼šçº¿æ€§å›å½’</title>
    <link href="http://riroaki.github.io/Machine-Learning-03-Linear-Regression/"/>
    <id>http://riroaki.github.io/Machine-Learning-03-Linear-Regression/</id>
    <published>2019-06-22T04:00:00.000Z</published>
    <updated>2019-07-07T17:11:04.877Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸‰ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†çº¿æ€§å›å½’çš„è¯¦ç»†ç†è®ºå’Œç®€å•çº¿æ€§å›å½’çš„å®ç°ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>ä¸Šå›è®¨è®ºäº†è´å¶æ–¯æ¨¡å‹ï¼Œè¿™ä¸€æ¨¡å‹å±äºç”Ÿæˆæ¨¡å‹ï¼ˆGenerative Modelï¼‰ï¼ŒåŸºäºä¸€å®šçš„å‡è®¾ï¼Œè®¤ä¸ºæ ·æœ¬æ˜¯ç”±ç±»æŒ‰ç…§ä¸€å®šæ¦‚ç‡æ¨¡å‹äº§ç”Ÿçš„ï¼Œç„¶åæ ¹æ®æ ·æœ¬å­¦ä¹ æ•°æ®ã€‚</p><p>åŒæ—¶æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œåœ¨é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨ä¸­ï¼Œå¦‚æœæ‰€æœ‰ç±»åˆ«å…±äº«æƒé‡ï¼Œé‚£ä¹ˆæ¨¡å‹å°±è½¬åŒ–ä¸ºçº¿æ€§çš„è¡¨è¾¾å¼ï¼Œä»è€Œå¯ä»¥ä½¿ç”¨å½¢å¦‚$y=w^Tx+b$çš„ç®€æ´å½¢å¼å»ºæ¨¡ï¼Œç›´æ¥æ±‚å‡ºæè¿°åˆ†ç±»é¢çš„è¡¨è¾¾å¼ï¼ˆè¯¦è§ä¸Šæ¬¡é™„å½•çš„è¯æ˜ï¼‰ï¼Œè¿™å°±æ˜¯åˆ¤åˆ«æ¨¡å‹ï¼ˆDiscriminant Modelï¼‰çš„æ€è·¯ã€‚</p><p>é‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å°†æ·±å…¥è®¨è®ºåˆ¤åˆ«æ¨¡å‹ï¼Œè¿™æ˜¯ç›´æ¥æ ¹æ®æ•°æ®å­¦ä¹ å¾—åˆ°çš„æ›´åŠ ç›´æ¥çš„è§„å¾‹ã€‚</p><p>çº¿æ€§æ¨¡å‹å°±æ˜¯ä¸€ç§åˆ¤åˆ«æ¨¡å‹ï¼Œè¿™ä¸€æ¬¡æˆ‘ä»¬è®¨è®ºå®ƒåœ¨å›å½’ä»»åŠ¡ä¸Šçš„åº”ç”¨ï¼Œä¹Ÿå°±æ˜¯çº¿æ€§å›å½’ã€‚</p><h2 id="çº¿æ€§å›å½’ç†è®º"><a href="#çº¿æ€§å›å½’ç†è®º" class="headerlink" title="çº¿æ€§å›å½’ç†è®º"></a>çº¿æ€§å›å½’ç†è®º</h2><p>å¯¹$x=[x_1,x_2,x_3,â€¦,x_d]^T\in R^d$ï¼Œçº¿æ€§å‡½æ•°çš„å½¢å¼ä¸º$y=w^Tx+b$ï¼Œå…¶ä¸­$w=[w_1, w_2,â€¦, w_d]\in R^d$ï¼Œ$b\in R$ã€‚</p><p>è¿™ä¸€è¡¨è¾¾å¼è¿˜æœ‰ä¸€ç§è¡¨è¿°ï¼Œé‚£å°±æ˜¯å°†$b$è¿™ä¸€é¡¹åŠ å…¥$w$ä¸­ï¼Œå˜æˆï¼š</p><p>$x=[x_1,x_2,â€¦,x_d,1]^T\in R^{d+1},w=[w_1,w_2,â€¦,w_d,b]^T\in R^{d+1}$</p><p>ç®€å•çš„æ¨¡å‹è•´å«ç€ä¸å¯å°è§†çš„åŠ›é‡ã€‚<strong>ä»»æ„æ¨¡å‹çš„è¡¨è¾¾å¼éƒ½å¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§ç»„åˆï¼Œæ•…ä¹Ÿå¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§æ¨¡å‹ã€‚</strong></p><p>æ¯”å¦‚ï¼Œå¤šé¡¹å¼å¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§ç»„åˆçš„å½¢å¼ï¼š</p><p>$f(x,a)=a_0+a_1x+a_2x^2+â€¦+a_Mx^M=\Sigma_{i=0}^Ma_ix^i$</p><p>å¯ä»¥è½¬åŒ–ä¸ºï¼š$f(x,a)=A^TX$ï¼Œå…¶ä¸­ï¼š</p><p>$X=[1,x,x^2,x^3,â€¦,x^M]^T,a=[a_0,a_1,a_2,â€¦,a_M]^T$</p><p>åŸºæœ¬ç†è®ºéƒ¨åˆ†ååˆ†ç®€æ´æ˜äº†ã€‚</p><h2 id="ç›®æ ‡å‡½æ•°"><a href="#ç›®æ ‡å‡½æ•°" class="headerlink" title="ç›®æ ‡å‡½æ•°"></a>ç›®æ ‡å‡½æ•°</h2><p>è¿™é‡Œç›®æ ‡å‡½æ•°é€šå¸¸ä½¿ç”¨æœ€å°äºŒä¹˜è¯¯å·®ï¼ˆMean Square Errorï¼‰ï¼š</p><p>$J_n(a)=\frac{1}{N}\Sigma_{i=1}^N(y_i-a^Tx_i)^2=(y-X^Ta)^T(y-X^Ta)$</p><p>å½“ç„¶ï¼Œä½¿ç”¨å¹³æ–¹æ®‹å·®ï¼ˆResidual Sum of Squaresï¼‰ä¹Ÿæ˜¯å¯ä»¥çš„ï¼ŒåŒºåˆ«åœ¨äºæ¯”æœ€å°äºŒä¹˜è¯¯å·®å°‘äº†ç³»æ•°$\frac{1}{N}$ã€‚</p><p>ä½ å¯èƒ½ä¼šé—®ï¼Œä¸ºä»€ä¹ˆä¸ä½¿ç”¨å¹³å‡ç»å¯¹å€¼è¯¯å·®ï¼ˆMean Absolute Errorï¼‰ï¼š$J_n(a)=\frac{1}{N}\Sigma_{i=1}^N|y_i-a^Tx_i|$ï¼Œä½†æ˜¯å®ƒå­˜åœ¨ä¸€äº›ç¼ºé™·ï¼š</p><ol><li>åœ¨é›¶ç‚¹å¤„ä¸å¯å¯¼ã€‚</li><li>å…¶å¯¼å‡ºçš„æ¢¯åº¦æ˜¯å¸¸æ•°ï¼ˆ+1æˆ–è€…-1ï¼‰ï¼Œæ¢¯åº¦æ±‚è§£å®¹æ˜“å¯¼è‡´ä¸æ”¶æ•›ã€‚</li></ol><p>æ¥ä¸‹æ¥æˆ‘ä»¬æŠ±ç€è®©ç›®æ ‡å‡½æ•°æœ€å°åŒ–çš„ç›®æ ‡ï¼Œå¯¹å®ƒæ±‚æ¢¯åº¦ï¼š</p><p>$\nabla J_n=-\frac{2}{N}X(y-X^Ta)$</p><p>äº‹å®ä¸Šï¼Œå…³äºæœ€å°äºŒä¹˜è¯¯å·®ä¹Ÿå¯ä»¥ç”¨ç”Ÿæˆå¼çš„æ€è·¯å¾—åˆ°ï¼ˆå¯¹ç†è®ºä¸æ„Ÿå†’çš„å¯ä»¥è·³è¿‡è¿™ä¸€éƒ¨åˆ†ï¼‰ï¼š</p><p>ç„¶åå°±å¯ä»¥å¼€å§‹æ„‰å¿«åœ°å‚æ•°ä¼°è®¡å•¦ï¼ˆï¼¾âˆ‡ï¼¾ï¼‰</p><h2 id="å‚æ•°ä¼°è®¡"><a href="#å‚æ•°ä¼°è®¡" class="headerlink" title="å‚æ•°ä¼°è®¡"></a>å‚æ•°ä¼°è®¡</h2><p>è¿™é‡Œæˆ‘ä»¬æœ‰ä¸¤ç§ä¼°è®¡æ–¹æ³•ï¼šåŸºäºæ­£è§„çŸ©é˜µï¼ˆNormal Equationï¼‰çš„ç›´æ¥æ±‚è§£ï¼Œæˆ–è€…ç»™äºˆæ¢¯åº¦ä¸‹é™çš„è¿­ä»£æ³•ã€‚</p><h3 id="æ­£è§„çŸ©é˜µ"><a href="#æ­£è§„çŸ©é˜µ" class="headerlink" title="æ­£è§„çŸ©é˜µ"></a>æ­£è§„çŸ©é˜µ</h3><p>ç”±ä¸Šé¢çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬ç›´æ¥ä»¤æ¢¯åº¦ä¸º0ï¼š</p><p>$a=(XX^T)^{-1}Xy$ï¼Œè¿™å°±æ˜¯ç†è®ºæœ€ä¼˜è§£â€”â€”å› ä¸ºæ¢¯åº¦ä¸º0ï¼Œç›®æ ‡å‡½æ•°æ˜¯å®Œå…¨å‡¸çš„ï¼Œæ‰€ä»¥å¯ä»¥è®¤ä¸ºè®­ç»ƒæ•°æ®çš„ç›®æ ‡å‡½æ•°è¾¾åˆ°äº†æœ€å°å€¼ã€‚</p><ul><li><p>å¦‚æœ$XX^T$éå¥‡å¼‚ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è·å¾—<strong>å”¯ä¸€è§£</strong>ï¼ˆå¥‡å¼‚æƒ…å†µä¸‹ä½¿ç”¨ä¼ªé€†ï¼Œç†è®ºä¸Šåº”è¯¥æ˜¯æœ‰æ— æ•°ç»„è§£ï¼‰ã€‚</p></li><li><p>ç‰¹åˆ«åœ°ï¼Œå¦‚æœ$X$æ˜¯æ–¹é˜µï¼ˆä¸€èˆ¬ä¸æ˜¯ï¼‰ï¼Œé‚£ä¹ˆ$a=X^{-T}X^{-1}Xy=X^{-T}y$ã€‚</p></li></ul><p>å¥½ï¼Œç„¶åæˆ‘ä»¬çœ‹ä¸€ä¸‹æ¢¯åº¦æ±‚è§£çš„åšæ³•ï¼š</p><h3 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h3><p>å¦‚æœä½ è¿˜ä¸çŸ¥é“æ¢¯åº¦ä¸‹é™æ˜¯ä»€ä¹ˆçš„è¯ï¼Œæˆ‘åœ¨<a href="/Machine-Learning-01-Overview-2/">ç¬¬ä¸€ç¯‡æ–‡ç« </a>é‡Œå·²ç»å†™è¿‡æ¢¯åº¦ä¸‹é™ã€æ‰¹é‡æ¢¯åº¦ä¸‹é™/éšæœºæ¢¯åº¦ä¸‹é™è¿™äº›æ¦‚å¿µã€‚</p><p>é€šè¿‡è¿­ä»£çš„æ–¹å¼æ›´æ–°å‚æ•°ï¼Œåªéœ€è¦æŠŠæ¢¯åº¦ä¹˜ä¸Šä¸€ä¸ªå­¦ä¹ ç‡$\alpha$å°±å¯ä»¥ï¼š</p><p>$grad=\alpha * -\frac{2}{N}X(y-X^Ta)$</p><p>$a-=grad$</p><p>é€šå¸¸ï¼Œå¸¸æ•°é¡¹$\frac{2}{N}$ä¼šçœå»ï¼Œå› ä¸ºå­¦ä¹ ç‡æ˜¯ä¸€ä¸ªå¯ä»¥ç¼©æ”¾çš„å€¼ã€‚</p><p>å¥½äº†ï¼Œè¿™é‡Œå†æ¬¡æå‡ºç¬¬ä¸€ç¯‡æ–‡ç« çš„é—®é¢˜ï¼Œä¸ºä»€ä¹ˆç¬¬ä¸€ç§æ–¹æ³•çœ‹èµ·æ¥ç®€å•ç›´æ¥ï¼Œè€Œä¸”èƒ½å¤Ÿå¾—åˆ°ç¡®å®šçš„â€œç²¾ç¡®è§£â€ï¼Œè€Œå®é™…æ“ä½œå¾€å¾€ä½¿ç”¨åŸºäºæ¢¯åº¦çš„åšæ³•å‘¢ï¼Ÿçœ‹èµ·æ¥ç¬¬äºŒç§åšæ³•å¾ˆä¸ç²¾ç¡®ï¼Œè€Œä¸”ä¼¼ä¹æœªå¿…æ”¶æ•›åˆ°æ­£ç¡®çš„è§£ã€‚</p><blockquote><p>ç†ç”±å°±æ˜¯ï¼Œç¬¬ä¸€ä¸ªæ–¹æ³•çš„å®è´¨æ˜¯è®¡ç®—æ–¹ç¨‹ç»„çš„è§£ï¼Œæ¶‰åŠæ±‚é€†çŸ©é˜µçš„è¿‡ç¨‹ï¼Œä½†æ˜¯ä¸€æ¥è®¡ç®—é‡å¤§ï¼ŒäºŒæ¥éš¾ä»¥ä¿è¯çŸ©é˜µéå¥‡å¼‚æˆ–è€…éç—…æ€çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—è¿‡ç¨‹å¯¹æ–¹ç¨‹ç»„å€¼çš„æ‰°åŠ¨éå¸¸æ•æ„Ÿï¼Œå™ªå£°å¸¦æ¥çš„è¯¯å·®è¾ƒå¤§å¯¼è‡´ç»“æœåç¦»ç†è®ºè§£ã€‚</p></blockquote><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>åˆåˆ°äº†åŠ¨æ‰‹å®è·µçš„æ—¶é—´äº†ã€‚è¿™ä¸€æ¬¡å®ç°äº†<code>LinearRegression</code>ç±»åŸºäº<code>LinearModel</code>åŸºç±»ï¼Œå¹¶å®ç°äº†å…¶æŠ½è±¡æ–¹æ³•ã€‚åœ¨è¿™ä¸€ä»½ä»£ç ä¸­ä¸ä½†å®ç°äº†åŸºäºæ¢¯åº¦ä¸‹é™çš„è¿­ä»£æ–¹æ³•ï¼Œä¹Ÿå®ç°äº†åŸºäº<code>normal equation</code>çš„ç›´æ¥æ±‚è§£æ³•ã€‚</p><p>æš‚æ—¶æ²¡æœ‰å®ç°Ridgeå’ŒLassoçš„æ­£åˆ™éƒ¨åˆ†ï¼Œä¸»è¦æ˜¯å¸Œæœ›å’Œå…¶ä»–çº¿æ€§åˆ†ç±»å™¨ä¸€åŒæ„æ€å®ç°ï¼ŒæŠŠæ­£åˆ™åŒ–åšä¸€ä¸ªæ›´ä½³æ³›ç”¨å‹çš„æ¨¡å—ã€‚</p><p>ä»£ç ä¸­å·²ç»ç»™å‡ºéƒ¨åˆ†æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚å…¶ä»–è¯¦æƒ…è¯·è§æˆ‘çš„<a href="https://github.com/Riroaki/LemonML/">repo</a>ã€‚</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> supervised<span class="token punctuation">.</span>_base <span class="token keyword">import</span> LinearModel<span class="token keyword">from</span> utils <span class="token keyword">import</span> batch<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Linear regression model."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token keyword">if</span> kwargs <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Update parameters of training</span>            self<span class="token punctuation">.</span>_update_params<span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span>        iters<span class="token punctuation">,</span> loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true"># Iterates till converge or iterating times exceed bound</span>        <span class="token keyword">while</span> iters <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_iter_bound<span class="token punctuation">:</span>            iters <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment" spellcheck="true"># Update weights using mini-batch gradient desent</span>            <span class="token keyword">for</span> batch_x<span class="token punctuation">,</span> batch_y <span class="token keyword">in</span> batch<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>                pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>                loss <span class="token operator">+=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span> <span class="token operator">*</span> batch_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                grad_w<span class="token punctuation">,</span> grad_b <span class="token operator">=</span> self<span class="token punctuation">.</span>_grad<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> pred_val<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>_w <span class="token operator">-=</span> grad_w                self<span class="token punctuation">.</span>_b <span class="token operator">-=</span> grad_b            loss <span class="token operator">/=</span> n            <span class="token comment" spellcheck="true"># Break if model converges.</span>            <span class="token keyword">if</span> loss <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>_loss_tol<span class="token punctuation">:</span>                <span class="token keyword">break</span>        <span class="token comment" spellcheck="true"># Update model with current weight and bias</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">fit_norm_eq</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Fit x using normal equation</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        x_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">)</span>        w_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>pinv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_ext<span class="token punctuation">.</span>T<span class="token punctuation">,</span> x_ext<span class="token punctuation">)</span><span class="token punctuation">)</span>        w_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>w_ext<span class="token punctuation">,</span> x_ext<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b <span class="token operator">=</span> w_ext<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> w_ext<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Calculate training loss</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_val    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># The precision part of regression is None</span>        precision <span class="token operator">=</span> None        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_value</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> w<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>                       b<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_val <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b        <span class="token keyword">return</span> pred_val    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_label</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># NO labeling in regression.</span>        <span class="token keyword">pass</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">_loss</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> true_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Use MSE loss</span>        loss <span class="token operator">=</span> float<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_val<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        loss <span class="token operator">/=</span> <span class="token number">2</span> <span class="token operator">*</span> true_val<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>              true_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Use MSE loss</span>        grad_w <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">*</span> <span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_val<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        grad_b <span class="token operator">=</span> <span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_val<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Use simple gradient by multiplying learning rate and grad.</span>        grad_w <span class="token operator">*=</span> self<span class="token punctuation">.</span>_learn_rate        grad_b <span class="token operator">*=</span> self<span class="token punctuation">.</span>_learn_rate        <span class="token keyword">return</span> grad_w<span class="token punctuation">,</span> grad_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="æ­£åˆ™åŒ–"><a href="#æ­£åˆ™åŒ–" class="headerlink" title="æ­£åˆ™åŒ–"></a>æ­£åˆ™åŒ–</h2><p>å¥½äº†ï¼Œæˆ‘ä»¬çš„æ¨¡å‹çœ‹èµ·æ¥å¾ˆå®Œç¾ä¸æ˜¯å—ï¼Ÿ</p><p>ç°åœ¨æˆ‘ä»¬è¯•ç€ç”¨çº¿æ€§æ¨¡å‹å»æ‹Ÿåˆå¼€å¤´æåˆ°çš„å¤šé¡¹å¼æ›²çº¿$f(x,a)=a_0+a_1x+a_2x^2+â€¦+a_Mx^M=\Sigma_{i=0}^Ma_ix^i$</p><p>å‡å¦‚å›¾çº¿é•¿è¿™æ ·ï¼Œ$y=sin(x)$ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/polynomial.png" alt></p><p>è¿™ç§å›¾çº¿ï¼Œ0é˜¶ã€1é˜¶éƒ½æ˜¯å•è°ƒï¼Œ2é˜¶åˆä¸èƒ½å…ˆå‡¹åå‡¸ï¼Œçœ‹èµ·æ¥éƒ½æ‹Ÿåˆä¸äº†å•Šã€‚</p><p>ç›´æ¥ä¸Šä¸‰é˜¶è¯•è¯•ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/3.png" alt></p><p>çœ‹èµ·æ¥è¿˜è¡Œï¼Œä½†æ˜¯æ²¡åŠæ³•åšåˆ°å®Œç¾è´´åˆã€‚</p><p>æˆ‘ä»¬è¯•è¯•æ›´å‰å®³çš„ï¼Œè®©M=9ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/9.png" alt></p><p>åš¯ï¼Œå‰å®³äº†ï¼Œè¦ä¸æ˜¯èƒŒæ™¯æŠŠçœŸå®æ›²çº¿ç”»å‡ºæ¥æˆ‘è¿˜çœŸå°±ä¿¡äº†ã€‚</p><p>è™½ç„¶åšåˆ°è®­ç»ƒè¯¯å·®ä¸º0ï¼Œä½†æ˜¯æˆ‘ä»¬æœ‰ç†ç”±ç›¸ä¿¡ï¼Œåœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•ç»“æœä¸€å®šæƒ¨ä¸å¿ç¹ã€‚</p><p>ç»“æœå¦‚ä¸‹ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/results.png" alt></p><p>å¾ˆæ˜æ˜¾ï¼Œæ¨¡å‹è¿‡æ‹Ÿåˆäº†ã€‚äºæ˜¯å¯ä»¥å¤ä¹ ä¸€ä¸‹ç¬¬ä¸€ç¯‡æ–‡ç« å…³äºåå·®ä¸æ–¹å·®çš„ç†è§£ï¼š</p><blockquote><p>æ¨¡å‹è¶Šå¤æ‚ï¼ˆç»„æˆæ¨¡å‹çš„å‚æ•°è¶Šå¤šï¼‰ï¼Œæ–¹å·®è¶Šå¤§ï¼Œåå·®è¶Šå°ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹çš„æè¿°èƒ½åŠ›è¶Šå¼ºï¼›æ¨¡å‹è¶Šç®€å•ï¼Œåå·®ä¹Ÿå®¹æ˜“å¤§ï¼Œå¾ˆå¯èƒ½æ— æ³•æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚</p></blockquote><p>æˆ‘ä»¬è¿˜å‘ç°ä¸€ä¸ªç‰¹å¾ï¼Œé‚£å°±æ˜¯è¶Šé«˜é˜¶çš„é‚£ä¸ªç³»æ•°ç»å¯¹å€¼è¶Šå¤§ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/coef.png" alt></p><p>ä¸ºäº†é¿å…è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ç§å«åšæ­£è§„åŒ–ï¼ˆRegularizationï¼‰çš„æŠ€å·§ã€‚</p><p>ä¸‹é¢ä»‹ç»ä¸¤ç§æ­£è§„åŒ–æŠ€å·§ï¼ŒRidgeä¸Lassoã€‚</p><h3 id="Ridge"><a href="#Ridge" class="headerlink" title="Ridge"></a>Ridge</h3><p>æˆ‘ä»¬ä½¿ç”¨äºŒé˜¶æ®‹å·®ä½œä¸ºç›®æ ‡å‡½æ•°ï¼Œå¹¶å¼•å…¥ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œå˜ä¸ºï¼š</p><p>$a^*=argmin\Sigma_{i=1}^N(y_i-x_i^Ta)^2+\lambda\Sigma_{j=1}^pa_j^2=(y-X^Ta)^T(y-X^Ta)+\lambda a^Ta$</p><p>è®¡ç®—æ¢¯åº¦å¾—åˆ°ï¼š$\nabla a=-2X(y-X^Ta)+2\lambda a$</p><p>ç”¨æ­£è§„æ–¹ç¨‹çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š$a^*=(XX^T+\lambda I)^{-1}Xy$ï¼Œå…¶ä¸­$\lambda$æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚</p><p>å†æ¬¡æ±‚è§£ï¼Œæˆ‘ä»¬æƒŠå¥‡çš„å‘ç°ï¼Œé«˜é˜¶çš„ç³»æ•°å˜å°äº†ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/coef1.png" alt></p><p>è¿™å°±æ¯”è¾ƒè€äººå¯»å‘³äº†ã€‚ä»ç†è®ºè§’åº¦åˆ†æä¸€ä¸‹è¿™ä¸ªäº‹å®ï¼š</p><p>å²­å›å½’ä»¥å¢å¤§åå·®ä¸ºä»£ä»·ï¼Œæ¢å–æ›´å°çš„æ–¹å·®â€”â€”è¿™æ˜¯éšç€$\lambda$å¢å¤§ï¼Œæ¨¡å‹å‘ç”Ÿçš„å˜åŒ–ã€‚</p><p>åœ¨è¿™ä¸ªå¤šé¡¹å¼ä¸­ï¼Œå› ä¸ºå¾ˆæ˜æ˜¾åœ°çœ‹åˆ°éšç€æ¨¡å‹å˜å¾—å¤æ‚ï¼Œæ¨¡å‹çš„æ–¹å·®è¶Šæ¥è¶Šå¤§ï¼Œå²­å›å½’æ­£æ˜¯é™ä½æ–¹å·®çš„æ‰‹æ®µã€‚</p><p><strong>ä¸ä»…å¦‚æ­¤ï¼Œå²­å›å½’æ›´å¤§çš„ç”¨å¤„åœ¨äºã€‚å½“æˆ‘ä»¬çš„ç‰¹å¾å­˜åœ¨è¾ƒå¼ºçš„çº¿æ€§ç›¸å…³æ€§çš„æ—¶å€™ï¼ˆå¯ä»¥è¯´åœ¨ç‰¹å¾æ–¹é¢ä¸æ»¡ç§©ï¼‰ï¼Œä¼šå¯¼è‡´$XX^T$çš„å€¼å¾ˆå°ï¼Œç”šè‡³è¶‹äºå¥‡å¼‚ã€‚è€Œå²­å›å½’ä¼šå¸®æˆ‘ä»¬é™åˆ¶å‚æ•°ç»å¯¹å€¼çš„å¤§å°ï¼ŒæŠ‘åˆ¶ç›¸å…³æ€§è¾ƒå¼ºçš„å±æ€§ç³»æ•°ã€‚</strong></p><p>æ‰€ä»¥ï¼Œå²­å›å½’å®é™…ä¸Šå¹¶ä¸åªæ˜¯ç”¨åœ¨åˆšæ‰çš„å¤šé¡¹å¼æ‹Ÿåˆä¸Šï¼Œè€Œæ˜¯å¯¹æ‰€æœ‰å­˜åœ¨è¾ƒå¤šçº¿æ€§ç›¸å…³å±æ€§æ—¶çš„é€šç”¨è§£å†³æ–¹å¼ã€‚ä¸ªäººç†è§£æœ‰ç‚¹ç±»ä¼¼â€œé™ç»´â€çš„æ“ä½œï¼Œä½†æ˜¯ç¨æœ‰ä¸åŒã€‚æ•°å­¦ä¸Šä½¿ç”¨æœ¯è¯­<strong>å‹ç¼©ä¼°è®¡</strong>ï¼ˆshinkageï¼‰æè¿°è¿™ä¸€æ“ä½œã€‚</p><h3 id="Lasso"><a href="#Lasso" class="headerlink" title="Lasso"></a>Lasso</h3><p>å’ŒRidgeç›¸ä¼¼ï¼Œå”¯ä¸€çš„ä¸åŒåœ¨äºæƒ©ç½šé¡¹çš„é˜¶æ•°ï¼š</p><p>$a^*=argmin\Sigma_{i=1}^N(y_i-x_i^Ta)^2+\lambda\Sigma_{j=1}^p|a_j|=(y-X^Ta)^T(y-X^Ta)+\lambda ||a||_1$</p><p>å®ƒå¸¦æ¥çš„å½±å“ä¹Ÿç¨æœ‰ä¸åŒï¼Œä¼šå¯¼è‡´æ¨¡å‹çš„å‚æ•°å¤§å¤šå˜æˆ0ï¼Œä¹Ÿå°±æ˜¯å¾—åˆ°<strong>ç¨€ç–åŒ–</strong>çš„å‚æ•°ã€‚</p><p>ç”¨ä¸€å¹…å›¾ç›´è§‚ç†è§£ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/lasso-ridge.png" alt></p><p>çº¢è‰²çš„æ¤­åœ†å’Œè“è‰²çš„åŒºåŸŸçš„åˆ‡ç‚¹å°±æ˜¯ç›®æ ‡å‡½æ•°çš„æœ€ä¼˜è§£ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæ˜¯åœ†ï¼Œåˆ™å¾ˆå®¹æ˜“åˆ‡åˆ°åœ†å‘¨çš„ä»»æ„ä¸€ç‚¹ï¼Œä½†æ˜¯å¾ˆéš¾åˆ‡åˆ°åæ ‡è½´ä¸Šï¼Œå› æ­¤æ²¡æœ‰ç¨€ç–ï¼›ä½†æ˜¯å¦‚æœæ˜¯è±å½¢æˆ–è€…å¤šè¾¹å½¢ï¼Œåˆ™å¾ˆå®¹æ˜“åˆ‡åˆ°åæ ‡è½´ä¸Šï¼Œå› æ­¤å¾ˆå®¹æ˜“äº§ç”Ÿç¨€ç–çš„ç»“æœã€‚è¿™ä¹Ÿè¯´æ˜äº†ä¸ºä»€ä¹ˆLassoä¼šæ˜¯ç¨€ç–çš„ã€‚</p><h3 id="ä»è´å¶æ–¯è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–"><a href="#ä»è´å¶æ–¯è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–" class="headerlink" title="ä»è´å¶æ–¯è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–"></a>ä»è´å¶æ–¯è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–</h3><p>è¿™ä¸€éƒ¨åˆ†éå¸¸è€äººå¯»å‘³ï¼Œå®ƒæ­ç¤ºäº†è´å¶æ–¯æ¦‚ç‡ä¸çº¿æ€§æ¨¡å‹ä¹‹é—´å­˜åœ¨ä¸€å®šçš„è”ç³»ã€‚</p><p>æˆ‘ä»¬å‡å®šä¸€ä¸ªç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºæ˜¯è¿™æ ·çš„ï¼š$y=f(x,a)+\epsilon$ï¼Œå…¶ä¸­ï¼š</p><ul><li>$f(x,a)$ä¸ºåˆ¤åˆ«å‡½æ•°</li><li>$\epsilon$ä¸ºéšæœºå™ªéŸ³ï¼Œæ˜¯æˆ‘ä»¬ä¸èƒ½ç›´æ¥è·å–çš„ï¼Œæˆ‘ä»¬å‡å®šå®ƒæœä»é«˜æ–¯åˆ†å¸ƒï¼š$\epsilon\sim N(0,\sigma)$</li></ul><p>é‚£ä¹ˆæ ¹æ®é«˜æ–¯æ¦‚ç‡å¯†åº¦å…¬å¼ï¼Œ$p(y|x,a,\sigma)=\frac{1}{\sigma\sqrt{2\pi}}\exp(-\frac{1}{2\sigma^2}(y-f(x,a))^2)$</p><p>è€Œæ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬æœ‰$p(a|D)=\frac{p(D|a)p(a)}{p(D)}$ï¼Œå…¶ä¸­ï¼š</p><ul><li>$p(D|a)=p(y|x,a,\sigma)$ä¸ºä¼¼ç„¶æ¦‚ç‡</li><li>$p(a)$ä¸ºå…ˆéªŒæ¦‚ç‡</li><li>$p(a|D)$ä¸ºåéªŒæ¦‚ç‡</li></ul><ol><li><p>å¯¹äºè¿™ä¸ªå…ˆéªŒï¼Œæˆ‘ä»¬é€‰å–$p(a)=N(a|0,\lambda^{-1}I)=\frac{1}{(2\pi)^{d/2}|\lambda^{-1}I|^{1/2}}\exp(-\frac{1}{2}(a-0)^T(\lambda^{-1}I)^{-1}(a-0))$</p><ol><li>å–å¯¹æ•°æœ‰ï¼š$\ln(p(a))=-\frac{\lambda}{2}a^Ta+c$ï¼Œ$c$ä¸ºå¸¸æ•°</li></ol></li><li><p>å¯¹ä¼¼ç„¶ï¼Œ$p(D|a)=\prod_{i=1}^np(y_i|x_i,a,\sigma)$</p><ol><li>æˆ‘ä»¬é‡‡ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡çš„log-likelihoodæ–¹æ³•ï¼š$\ln(p(D|a))=-\frac{1}{2\sigma^2}(y_i-f(x_i,a)^2))+c(\sigma)$</li></ol></li><li><p>è€ŒåéªŒæ¦‚ç‡æ­£æ¯”äºå…ˆéªŒå’Œä¼¼ç„¶ä¹˜ç§¯ï¼š$p(a|D)\propto p(D|a)p(a)$</p><ol><li>å–å¯¹æ•°ï¼Œæˆ‘ä»¬æœ‰ï¼š$\ln(p(a|D))\propto\ln(p(D|a))+\ln(p(a))$ï¼Œç­”æ¡ˆå‘¼ä¹‹æ¬²å‡º</li></ol></li></ol><p>äºæ˜¯ï¼Œæˆ‘ä»¬æŠŠä¸¤é¡¹åŠ èµ·æ¥å¾—åˆ°ï¼š$ln(p(a|D))\propto -\frac{1}{2\sigma^2}(y_i-f(x_i,a)^2)-\frac{\lambda}{2}a^Ta$</p><p>æˆ‘ä»¬å¸Œæœ›è¿™ä¸€é¡¹æœ€å¤§ï¼ˆå³æœ€å¤§åéªŒæ¦‚ç‡ï¼‰ï¼Œå°±æ˜¯å¸Œæœ›å…¶ç›¸åæ•°æœ€å°ï¼Œä¹Ÿå°±æ˜¯ï¼š</p><p>$a=argmin \frac{1}{2\sigma^2}(y_i-f(x_i,a)^2)+\frac{\lambda}{2}a^Ta$</p><p>çœ‹ï¼Œè¿™ä¸å°±æ˜¯Ridgeæ­£åˆ™åŒ–çš„æŸå¤±å‡½æ•°ï¼Ÿ</p><h3 id="ä»é‡åŒ–çš„åå·®ã€æ–¹å·®ä¸å™ªéŸ³çš„è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–ï¼ˆå¾…è¡¥å……è¯´æ˜ï¼‰"><a href="#ä»é‡åŒ–çš„åå·®ã€æ–¹å·®ä¸å™ªéŸ³çš„è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–ï¼ˆå¾…è¡¥å……è¯´æ˜ï¼‰" class="headerlink" title="ä»é‡åŒ–çš„åå·®ã€æ–¹å·®ä¸å™ªéŸ³çš„è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–ï¼ˆå¾…è¡¥å……è¯´æ˜ï¼‰"></a>ä»é‡åŒ–çš„åå·®ã€æ–¹å·®ä¸å™ªéŸ³çš„è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–ï¼ˆå¾…è¡¥å……è¯´æ˜ï¼‰</h3><p>åˆ°è¿™é‡Œæˆ‘ä»¬ä»é‡åŒ–çš„è§’åº¦æ¥çœ‹è¿™ä¸‰ä¸ªæ¦‚å¿µï¼š</p><p>æˆ‘ä»¬ç”¨ä¸€ä¸ªæ¦‚å¿µæ¥ä»£è¡¨æ¨¡å‹çš„æ€»è¯¯å·®ï¼šExpected Prediction Errorï¼ŒEPEã€‚</p><p>é‡åŒ–çš„è®¡ç®—å¦‚ä¸‹ï¼ˆç›®å‰æˆ‘å¯¹è¿™éƒ¨åˆ†ç†è§£ä¸æ·±ï¼Œè¿™ä¸€éƒ¨åˆ†å¾…è¡¥å……ï¼‰ï¼š</p><p>$EPE(f)=\int\int(y-f(x))^2p(x,y)dxdy$</p><p>$EPE=var+bias^2+noise$</p><ul><li>$bias^2=\int{E_D(f(x;D))-E(y|x)}^2p(x)dx$</li><li>$variance=\int E_D{[f(x;D)-E_D(f(x;D))]^2}p(x)dx$</li><li>$noise=\int var(y|x)p(x)dx$</li></ul><p>è¿™é‡Œè´´å‡ºä¸åŒ$\lambda$å‚æ•°å¯¹åå·®ä¸æ–¹å·®çš„å½±å“ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/-2.4.png" alt></p><p><img src="/Machine-Learning-03-Linear-Regression/-0.31.png" alt></p><p><img src="/Machine-Learning-03-Linear-Regression/2.6.png" alt></p><p>å¯ä»¥å¾ˆæ˜æ˜¾çš„çœ‹å‡ºï¼Œæ­£åˆ™é¡¹é™ä½äº†å›¾çº¿çš„æ‹Ÿåˆç¨‹åº¦ï¼Œä½†æ˜¯ä¹Ÿé™ä½äº†æ–¹å·®ï¼ˆå³ä¸åŒé¢„æµ‹çº¿çš„å˜åŒ–å¹…åº¦ï¼‰ã€‚</p><p>ä»è€Œï¼Œæˆ‘ä»¬å¯¹Bias-Varianceçš„Trade-offæœ‰äº†æ›´æ·±çš„ç†è§£ï¼š</p><p><img src="/Machine-Learning-03-Linear-Regression/tradeoff.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸‰ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†çº¿æ€§å›å½’çš„è¯¦ç»†ç†è®ºå’Œç®€å•çº¿æ€§å›å½’çš„å®ç°ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-02ï¼šè´å¶æ–¯åˆ†ç±»</title>
    <link href="http://riroaki.github.io/Machine-Learning-02-Bayes/"/>
    <id>http://riroaki.github.io/Machine-Learning-02-Bayes/</id>
    <published>2019-06-21T04:00:00.000Z</published>
    <updated>2019-06-25T07:38:48.588Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬äºŒç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†è´å¶æ–¯åˆ†ç±»çš„è¯¦ç»†ç†è®ºå’Œç®€å•é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨çš„å®ç°ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkä¸prã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>è´å¶æ–¯åˆ†ç±»çš„æ ¸å¿ƒæ˜¯è´å¶æ–¯å…¬å¼ï¼š</p><ul><li>$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$</li><li>$P(A) = \Sigma_{i=1}^n{P(B|A_i)P(A_i)}$</li><li>è´å¶æ–¯å…¬å¼å¯¹å¤šå…ƒå˜é‡åŒæ ·é€‚ç”¨ï¼Œä¸å˜é‡æ˜¯å¦ç‹¬ç«‹ä¹Ÿæ— å…³ï¼Œæ˜¯æ™®é€‚çš„å…¬å¼ã€‚</li></ul><p>ä¸ºäº†ä»‹ç»è¿™ä¸ªå…¬å¼ï¼Œæˆ‘ä»¬é¦–å…ˆæ¥çœ‹ä¸€é“æ¦‚ç‡é¢˜ï¼š</p><blockquote><p>ç°åˆ†åˆ«æœ‰ Aã€B ä¸¤ä¸ªå®¹å™¨ï¼Œåœ¨å®¹å™¨ A é‡Œåˆ†åˆ«æœ‰ 7 ä¸ªçº¢çƒå’Œ 3 ä¸ªç™½çƒï¼Œåœ¨å®¹å™¨ B é‡Œæœ‰ 1 ä¸ªçº¢çƒå’Œ 9 ä¸ªç™½çƒï¼Œè€Œè®¾å®šä»Aä¸­æŠ½å–çš„æ¦‚ç‡å’ŒBä¸­æŠ½å–çš„æ¦‚ç‡ä¸º1:2ã€‚</p><p>ç°å·²çŸ¥ä»è¿™ä¸¤ä¸ªå®¹å™¨é‡Œä»»æ„æŠ½å‡ºäº†ä¸€ä¸ªçº¢çƒï¼Œé—®è¿™ä¸ªçƒæ¥è‡ªå®¹å™¨ A çš„æ¦‚ç‡æ˜¯å¤šå°‘?</p></blockquote><p>è®°æŠ½ä¸­çº¢çƒçš„äº‹ä»¶ä¸º$P(B)$ï¼Œè®°ä»å®¹å™¨AæŠ½çƒçš„æ¦‚ç‡ä¸º$P(A)$ã€‚</p><p>æ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬æœ‰ï¼š$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$ã€‚å…¶ä¸­$P(B|A)$è¡¨ç¤ºä»å®¹å™¨Aä¸­æŠ½çƒï¼ŒæŠ½åˆ°çº¢çƒçš„æ¦‚ç‡ã€‚</p><p>åœ¨è¿™ä¸ªå…¬å¼ä¸­ï¼š</p><ul><li>$P(A|B)$æ˜¯å·²çŸ¥Bå‘ç”ŸåAçš„æ¡ä»¶æ¦‚ç‡ï¼Œä¹Ÿå«åšAçš„åéªŒæ¦‚ç‡ï¼ˆposterior probabilityï¼‰ã€‚</li><li>$P(B|A)$æ˜¯å·²çŸ¥Aå‘ç”ŸåBçš„æ¡ä»¶æ¦‚ç‡ï¼Œæ˜¯Bçš„åéªŒæ¦‚ç‡ï¼Œåœ¨è¿™é‡Œå«Açš„ä¼¼ç„¶æ¦‚ç‡ï¼ˆlikelihoodï¼‰ã€‚</li><li>$P(A)$æ˜¯äº‹ä»¶å‘ç”Ÿä¹‹å‰æˆ‘ä»¬å¯¹Açš„ç»éªŒçŸ¥è¯†ï¼Œä¸Bæ— å…³ï¼Œå«åšAçš„å…ˆéªŒæ¦‚ç‡ï¼ˆprior probabilityï¼‰ã€‚</li><li>$P(B)$æ˜¯Bçš„å…ˆéªŒæ¦‚ç‡ï¼Œåœ¨è¿™é‡Œå«åšæ ‡å‡†åŒ–å¸¸é‡ï¼ˆnormalized constantï¼‰ã€‚</li><li>æ ¹æ®è¿™ä¸ªå…³ç³»ï¼ŒåéªŒ$P(A|B)$ä¹Ÿå¯ä»¥å«åš<strong>æ ‡å‡†åŒ–</strong>çš„ä¼¼ç„¶ï¼›ä¼¼ç„¶å’ŒåéªŒæ˜¯å¯ä»¥ç›¸äº’è½¬åŒ–çš„ã€‚</li></ul><h2 id="è´å¶æ–¯åˆ†ç±»ç†è®º"><a href="#è´å¶æ–¯åˆ†ç±»ç†è®º" class="headerlink" title="è´å¶æ–¯åˆ†ç±»ç†è®º"></a>è´å¶æ–¯åˆ†ç±»ç†è®º</h2><p>ä»è¿™ä¸ªå…¬å¼å¼•ç”³å¼€ï¼Œæˆ‘ä»¬å¯ä»¥å¥—ç”¨åœ¨åˆ†ç±»ç†è®ºä¸Šï¼š</p><ul><li>æˆ‘ä»¬å¯ä»¥ç±»æ¯”è®¤ä¸ºæ¯ä¸€ä¸ªç±»å¯¹åº”ä¸€ä¸ªå®¹å™¨ï¼Œæ ·æœ¬éƒ½æ˜¯è¿™ä¸ªç±»ä¸­ç”Ÿæˆï¼ˆå–å‡ºï¼‰çš„ã€‚</li><li>åˆ†ç±»é—®é¢˜å¯ä»¥é‡‡ç”¨è¿™æ ·çš„è¡¨è¿°ï¼šå·²çŸ¥ä¸€ä¸ªå¾…å½’ç±»æ ·æœ¬$X_i$çš„ç‰¹å¾ï¼Œé‚£ä¹ˆæ±‚$X_i$å±äºç¬¬jä¸ªç±»çš„æ¦‚ç‡ï¼Œå°±å˜æˆäº†ä¸€ä¸ªåéªŒæ¦‚ç‡ã€‚</li><li>æŠŠæ ·æœ¬å±äºç¬¬jä¸ªç±»çš„æ¦‚ç‡è®°ä½œäº‹ä»¶$w_j$ï¼Œè¿™ä¸ªåéªŒæ¦‚ç‡å¯ä»¥è¡¨è¿°ä¸ºï¼š$P(w_j|x=X_i)$ï¼Œç®€è®°ä½œ$P(w_j|X_i)$ã€‚</li><li>é‚£ä¹ˆï¼Œæ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬æœ‰ï¼š$P(w_j|X_i)=\frac{P(X_i|w_j)P(w_j)}{P(X_i)}$ã€‚</li><li>è¿™é‡Œçš„ä¼¼ç„¶æ˜¯$P(X_i|w_j)$ï¼Œå…ˆéªŒæ¦‚ç‡æ˜¯$P(w_j)$ï¼Œæ ‡å‡†åŒ–å¸¸é‡ä¸º$P(X_i)$ã€‚</li></ul><p>é‚£ä¹ˆï¼Œæœ‰äº†æŸä¸ªæ ·æœ¬å±äºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œå¦‚ä½•åˆ†ç±»å‘¢ï¼Ÿ</p><p>å¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬é€‰æ‹©åéªŒæ¦‚ç‡æ¯”è¾ƒå¤§çš„é‚£ä¸€ä¸ªæ¦‚ç‡å¯¹åº”çš„ç±»åˆ«ä½œä¸º$X_i$çš„åˆ†ç±»ã€‚</p><ul><li>è¡¥å……1ï¼šå½“æˆ‘ä»¬åªæœ‰å…ˆéªŒæ¦‚ç‡çš„æ—¶å€™ï¼Œæˆ‘ä»¬é€‰æ‹©å…ˆéªŒæ¦‚ç‡è¾ƒå¤§çš„é‚£ä¸€ä¸ªç±»åˆ«ä½œä¸ºåˆ†ç±»ã€‚ç”¨å…ˆéªŒæ¦‚ç‡ç›´æ¥ä¼°è®¡çš„åå¤„åœ¨äºâ€é©¬å¤ªæ•ˆåº”â€ï¼Œå› ä¸ºå®ƒæ€»æ˜¯æŠŠæ–°æ ·æœ¬å½’ç±»åˆ°åŸæœ¬å å¤šæ•°çš„é‚£ä¸€ä¸ªç±»ã€‚</li><li>è¡¥å……2ï¼šå½“é‡‡ç”¨é£é™©çŸ©é˜µï¼ˆrisk matrixï¼‰è¿›è¡Œè¯„ä¼°çš„æ—¶å€™ï¼Œåˆ†ç±»è§„åˆ™ä¼šæ›´å¤æ‚ä¸€äº›ã€‚</li></ul><h2 id="å‚æ•°ä¼°è®¡"><a href="#å‚æ•°ä¼°è®¡" class="headerlink" title="å‚æ•°ä¼°è®¡"></a>å‚æ•°ä¼°è®¡</h2><p>æˆ‘ä»¬å·²ç»æœ‰äº†æ¦‚ç‡çš„å…¬å¼å’Œå†³ç­–ç†è®ºï¼Œå¦‚ä½•ä¼°è®¡æ¦‚ç‡å…¬å¼ä¸­çš„å„ä¸ªæ¦‚ç‡ï¼Ÿ</p><p>ç­”æ¡ˆæ˜¯ï¼šä»æœ‰ç±»æ ‡ç­¾çš„æ•°æ®ï¼ˆè®­ç»ƒæ•°æ®ï¼‰ä¸­æ€»ç»“æå–ã€‚</p><h3 id="å…ˆéªŒæ¦‚ç‡çš„ä¼°è®¡"><a href="#å…ˆéªŒæ¦‚ç‡çš„ä¼°è®¡" class="headerlink" title="å…ˆéªŒæ¦‚ç‡çš„ä¼°è®¡"></a>å…ˆéªŒæ¦‚ç‡çš„ä¼°è®¡</h3><p>è¿™é‡Œçš„å…ˆéªŒæ¦‚ç‡ï¼Œå°±æ˜¯åœ¨æ²¡æœ‰è®­ç»ƒæ ·æœ¬å…·ä½“ç‰¹å¾çš„å€¼çš„åˆ†å¸ƒæƒ…å†µä¸‹ï¼ŒæŸä¸ªç±»åŸå§‹çš„ä¿¡æ¯ã€‚</p><p>å¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬ä¼šæŠŠè¿™ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°å å…¨éƒ¨æœ‰æ ‡ç­¾çš„æ ·æœ¬çš„æ¯”é‡å½“ä½œå…ˆéªŒæ¦‚ç‡ï¼Œ</p><p>å³ï¼š$P(w_j)=\Sigma_{i=1}^N{I(y_i=c_j)}/N$</p><h3 id="ä¼¼ç„¶æ¦‚ç‡çš„ä¼°è®¡"><a href="#ä¼¼ç„¶æ¦‚ç‡çš„ä¼°è®¡" class="headerlink" title="ä¼¼ç„¶æ¦‚ç‡çš„ä¼°è®¡"></a>ä¼¼ç„¶æ¦‚ç‡çš„ä¼°è®¡</h3><p>è¿™é‡Œæˆ‘ä»¬éœ€è¦åˆ†ä¸ºè¿ç»­å˜é‡å’Œç¦»æ•£å˜é‡ä¸¤ç§æƒ…å†µè®¨è®ºï¼š</p><h4 id="è¿ç»­å˜é‡"><a href="#è¿ç»­å˜é‡" class="headerlink" title="è¿ç»­å˜é‡"></a>è¿ç»­å˜é‡</h4><p>æˆ‘ä»¬æœ‰ä¸åŒçš„å‡è®¾å¯ä»¥åšå‡ºä¸åŒçš„ä¼°è®¡ã€‚å¸¸ç”¨çš„æœ‰é«˜æ–¯åˆ†å¸ƒå‡è®¾ã€äºŒé¡¹åˆ†å¸ƒå‡è®¾ã€ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚</p><p>è¿™é‡Œåªä»‹ç»é«˜æ–¯åˆ†å¸ƒå‡è®¾å¯¹åº”çš„å‚æ•°ä¼°è®¡æ–¹æ³•ã€‚</p><ul><li>é«˜æ–¯åˆ†å¸ƒçš„å…·ä½“å‡è®¾ï¼šå¯¹äºæŸä¸€ä¸ªç±»$c_i$ï¼Œå…¶ç”Ÿæˆçš„æ ·æœ¬æ»¡è¶³é«˜æ–¯åˆ†å¸ƒï¼Œå³ï¼š$X\sim N(\mu, \Sigma)$ï¼Œå…¶äº§ç”Ÿçš„æ¯ä¸€ä¸ªæ ·æœ¬ä¹‹é—´çš„æ¦‚ç‡æ˜¯äº’ç›¸ç‹¬ç«‹ä¸”åŒåˆ†å¸ƒçš„ï¼ˆi.i.dï¼ŒIndependent and identically distributedï¼‰</li><li>åœ¨è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimationï¼‰çš„åšæ³•æ¥é€‰å–æœ€ä½³å‚æ•°ï¼š<ul><li>ç›®æ ‡å‡½æ•°æ˜¯$L(\mu_j,\Sigma_j)=\prod_{i=1}^N{P(X_i|w_j)}$ã€‚</li><li>ç”±äºä¸æ–¹ä¾¿å¯¹ç›®æ ‡å‡½æ•°æ±‚å¯¼ï¼Œæˆ‘ä»¬é‡‡ç”¨å–å¯¹æ•°çš„æŠ€å·§ï¼Œå°†è¿ä¹˜è½¬åŒ–ä¸ºè¿åŠ ï¼š$l(\mu_j,\Sigma_j)=log(L)=\Sigma_{i=1}^NP(X_i|w_j)$</li><li>å¯¹å¯¹æ•°ä¼¼ç„¶æ±‚å¯¼ï¼Œä»¤å¯¼æ•°ä¸º0æ±‚å‡º$\mu,\Sigma$ã€‚ç”±äºæ ·æœ¬æ˜¯å¤šç»´ï¼Œæ±‚å¯¼è¿‡ç¨‹æ¯”è¾ƒå¤æ‚ï¼Œè¯¦æƒ…å‚è€ƒé™„å½•ã€‚</li><li>æ€»ä¹‹ï¼Œæœ€ç»ˆæ±‚å‡ºçš„ç»“æœå’Œæ ‡é‡å½¢å¼çš„æƒŠäººä¸€è‡´ï¼š<ul><li>$\hat\mu_j=\frac{1}{N_j}\Sigma_{i=0}^{N_j}X_i=\bar{x}$</li><li>$\hat\Sigma=\frac{1}{N_j}\Sigma_{i=1}^{N_j}(X_i-\hat\mu)(X_i-\hat\mu)^T=cov(X_i), where\ y_i = w_j$</li><li>å¾ˆå®¹æ˜“è”æƒ³åˆ°æ ‡é‡æƒ…å†µä¸‹ï¼Œ$\hat\mu=\bar{X}, \hat\sigma=var(X)$</li></ul></li></ul></li><li>æœ‰äº†ä¼°è®¡çš„å‚æ•°ä»¥åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é«˜æ–¯æ¦‚ç‡å¯†åº¦å…¬å¼æ±‚ä¼¼ç„¶æ¦‚ç‡ï¼š$P(X; \mu, \Sigma)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(X-\mu)^T\Sigma^{-1}(X-\mu))$</li></ul><blockquote><p><strong>P.S.å…¶å®æˆ‘æœ‰ä¸€ç‚¹ç–‘é—®ğŸ¤”ï¸ï¼Œä¸ºä»€ä¹ˆè¿™é‡Œä¸èƒ½ä½¿ç”¨æ¢¯åº¦æ±‚è§£è€Œæ˜¯ç›´æ¥ä»¤æ¢¯åº¦ä¸º0æ±‚è§£è¯æ˜çš„å‘¢ï¼Œæœ‰æ²¡æœ‰å¤§ä½¬èƒ½å¤Ÿåœ¨è¯„è®ºåŒºè¯´ä¸€è¯´è‡ªå·±çš„æƒ³æ³•â€¦â€¦</strong></p></blockquote><h4 id="ç¦»æ•£å˜é‡"><a href="#ç¦»æ•£å˜é‡" class="headerlink" title="ç¦»æ•£å˜é‡"></a>ç¦»æ•£å˜é‡</h4><p>å¯¹äºç¦»æ•£å˜é‡çš„ä¼°è®¡åˆ™è¾ƒä¸ºç®€å•ï¼Œæˆ‘ä»¬é€‰å–ä»¥å‰è¿™ä¸€ç‰¹å¾å‡ºç°è¿‡çš„å€¼çš„åˆ†å¸ƒæƒ…å†µä½œä¸ºä¼°è®¡ï¼Œå³ï¼š</p><p>$P(X_i^k|w_j)=\frac{|X_i^k|}{N_{w_j}}$</p><p>æ¯”å¦‚åœ¨æŸä¸ªç±»çš„æ€§åˆ«ç‰¹å¾ä¸­ï¼Œç”·æ€§å‡ºç°äº†100æ¬¡ï¼Œå¥³æ€§å‡ºç°äº†200æ¬¡ï¼Œæˆ‘ä»¬å°±ä¼°è®¡ä¸€ä¸ªè¿™ä¸ªå±æ€§ä¸ºç”·æ€§çš„ä¼¼ç„¶æ¦‚ç‡ä¸º100/300=0.33333â€¦ï¼Œå¯¹å¥³æ€§åŒç†ã€‚</p><h3 id="æ ‡å‡†åŒ–å¸¸é‡"><a href="#æ ‡å‡†åŒ–å¸¸é‡" class="headerlink" title="æ ‡å‡†åŒ–å¸¸é‡"></a>æ ‡å‡†åŒ–å¸¸é‡</h3><ul><li>å¯¹äºè¿ç»­å˜é‡æ¥è¯´ï¼Œç†è®ºä¸Šæ˜¯é€šè¿‡$P(X_i)=\Sigma_{j=1}^cP(X_i|w_j)P(w_j)$æ±‚å‡ºæ¦‚ç‡å¯†åº¦ï¼Œä¹Ÿå°±æ˜¯è¯´å¾—ç®—å‡ºå¯¹æ ·æœ¬å¯¹æ¯ä¸€ä¸ªç±»çš„å…ˆéªŒæ¦‚ç‡å’Œä¼¼ç„¶çš„ä¹˜ç§¯ä¹‹å’Œï¼Œæ‰èƒ½è®¡ç®—åˆ†æ¯ã€‚</li><li>å¯¹äºç¦»æ•£å˜é‡æ¥è¯´ï¼Œåˆ™æ˜¯æ±‚å‡ºè¿™ä¸€ä¸ªä¸€æ¨¡ä¸€æ ·çš„æ ·æœ¬åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚<ul><li>å¦‚æœè¿‡å»æ²¡æœ‰å‡ºç°è¿‡è¿™ä¸€æ ·æœ¬ï¼Œæˆ‘ä»¬æ€»ä¸èƒ½æŠŠ0ä½œä¸ºå®ƒçš„æ¦‚ç‡ï¼Œè¿™æ˜¯ä¸åˆç†çš„ï¼ˆä¸€æ¥æœ‰å¯èƒ½æ˜¯æ ·æœ¬æ•°é‡è¿‡å°‘ï¼ŒäºŒæ¥äººå®¶æ˜¯åˆ†æ¯å•Šï¼Œæ€ä¹ˆèƒ½æ˜¯0ï¼‰ï¼Œæ‰€ä»¥é‡‡ç”¨å¹³æ»‘ï¼ˆSmoothingï¼‰çš„æŠ€æœ¯ï¼Œåœ¨åˆ†å­åˆ†æ¯åŒæ—¶åŠ å…¥ä¸€ä¸ªä¸æ ·æœ¬æ•°æœ‰å…³çš„å¹³æ»‘é¡¹ã€‚å…·ä½“æŠ€æœ¯åœ¨æ­¤ä¸åšè¯¦ç»†ä»‹ç»ã€‚</li></ul></li></ul><p>ç„¶è€Œæ­£å¸¸æƒ…å†µä¸‹ï¼Œå®ƒå¹¶ä¸åœ¨æˆ‘ä»¬çš„è€ƒè™‘èŒƒå›´å†…ï¼š</p><p>å› ä¸ºï¼Œæ¯ä¸€ä¸ªç±»çš„è®¡ç®—æ¦‚ç‡çš„åˆ†æ¯éƒ½æ˜¯è¿™ä¸€é¡¹ã€‚æ—¢ç„¶æˆ‘ä»¬æœ€ç»ˆçš„ç›®æ ‡æ˜¯æ¯”è¾ƒåéªŒæ¦‚ç‡çš„å¤§å°ï¼ˆæˆ–è€…ä¸é£é™©çŸ©é˜µå…³è”åçš„å¤§å°ï¼Œwhateverï¼‰ï¼Œè¿™ä¸€é¡¹ä½œä¸ºç›¸åŒçš„ç³»æ•°å¹¶ä¸ä¼šäº§ç”Ÿå½±å“ï¼šï¼‰</p><h2 id="ç›®æ ‡å‡½æ•°"><a href="#ç›®æ ‡å‡½æ•°" class="headerlink" title="ç›®æ ‡å‡½æ•°"></a>ç›®æ ‡å‡½æ•°</h2><p>åœ¨è¿™é‡Œå› ä¸ºæˆ‘ä»¬å¹¶ä¸æ˜¯é‡‡å–è¿­ä»£ä¼˜åŒ–ï¼Œè€Œæ˜¯é€šè¿‡å‡è®¾æ¨¡å‹ç›´æ¥ä¼°è®¡å¾—å‡ºå‚æ•°ï¼Œæ‰€ä»¥ä¸éœ€è¦ç›®æ ‡å‡½æ•°å¯å¯¼ã€‚</p><p>é‡‡ç”¨0-1æŸå¤±å‡½æ•°å°±å¯ä»¥ï¼Œå³åˆ†ç±»é”™è¯¯ï¼Œç»“æœå°±åŠ ä¸€ï¼Œåˆ†ç±»æ­£ç¡®ç»“æœå°±ä¸å˜åŒ–çš„å‡½æ•°ã€‚</p><p>åœ¨è´å¶æ–¯ä¸­åˆ†ç±»ä¸­ï¼Œè¿˜æœ‰ä¸€ä¸ªå¸¸è§çš„è¯„ä»·æ ‡å‡†ï¼ˆmetricsï¼‰ï¼šæ··æ·†çŸ©é˜µå’Œé£é™©çŸ©é˜µï¼Œå…·ä½“è§ä¸Šä¸€ç¯‡çš„ååŠæ®µã€‚</p><h2 id="æœ´ç´ è´å¶æ–¯"><a href="#æœ´ç´ è´å¶æ–¯" class="headerlink" title="æœ´ç´ è´å¶æ–¯"></a>æœ´ç´ è´å¶æ–¯</h2><p>æœ´ç´ è´å¶æ–¯ï¼ˆNaive Bayesï¼‰æ¨¡å‹æ˜¯è´å¶æ–¯æ¨¡å‹çš„ä¸€ä¸ªå˜ç§ï¼Œæ˜¯ç®€åŒ–è´å¶æ–¯å‚æ•°çš„ä¸€ç§æ¨¡å‹ã€‚</p><p>åœ¨æœ´ç´ è´å¶æ–¯ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºå„ä¸ªç‰¹å¾ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œäº’ç›¸ä¸ä¼šå½±å“ï¼Œå³ï¼š</p><p>$P(X_i|w_j)=P(X^1_i,X^2_i,X^3_i,â€¦X_i^p|w_j)=P(X_i^1|w_j)P(X_i^2|w_j)P(X_i^3|w_j)â€¦P(X_i^p|w_j)$</p><p>$=\prod_{k=1}^pP(X_i^k|w_j)$</p><p>å°†è¿™ä¸€å‡è®¾åº”ç”¨åœ¨é«˜æ–¯æ¨¡å‹ä¸­ï¼Œè´å¶æ–¯-é«˜æ–¯æ¨¡å‹çš„$\Sigma$å‚æ•°å°±é€€åŒ–ä¸ºå¯¹è§’çŸ©é˜µï¼Œå› ä¸ºå®ƒæœ¬è´¨æ˜¯åæ–¹å·®çŸ©é˜µï¼Œå¦‚ä»Šå„ä¸ªç‰¹å¾ä¹‹é—´çš„åæ–¹å·®ä¸º0ï¼Œæ¯ä¸ªç‰¹å¾æœä»ç‹¬ç«‹çš„é«˜æ–¯åˆ†å¸ƒã€‚</p><p>æ‰€ä»¥è®¡ç®—å…¬å¼ä¹Ÿå˜å¾—ç®€å•ï¼Œåªéœ€è¦å•ç‹¬è®¡ç®—æ¯ä¸€ç»´åº¦çš„é«˜æ–¯åˆ†å¸ƒæ¦‚ç‡å†ç›¸ä¹˜å°±å¯ä»¥è®¡ç®—ã€‚</p><p>æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è‡³ä»Šä¹Ÿæ˜¯ä¸€ä¸ªç®€å•çš„æµè¡Œåˆ†ç±»å™¨ï¼Œä¸è¿‡åœ¨å¾ˆå¤šæ—¶å€™ï¼Œæ ·æœ¬çš„å±æ€§å¾€å¾€æ˜¯ç›¸å…³çš„ï¼Œè¿™ç§æƒ…å½¢ä¸‹ä½¿ç”¨æœ´ç´ è´å¶æ–¯æ¨¡å‹å°±ä¸å¤ªå¥½ã€‚</p><h2 id="ä»£ç å®ç°"><a href="#ä»£ç å®ç°" class="headerlink" title="ä»£ç å®ç°"></a>ä»£ç å®ç°</h2><p>å¥½äº†ï¼Œè¯´äº†è¿™ä¹ˆå¤šç»ˆäºè¦ä¸Šä»£ç äº†ï½</p><p>è¿™é‡Œå®ç°äº†é«˜æ–¯è´å¶æ–¯å¤šåˆ†ç±»å™¨ï¼Œç»§æ‰¿è‡ª<code>SupervisedModel</code>åŸºç±»ï¼ˆè¯¦è§æœ¬äººçš„<a href="https://github.com/Riroaki/LemonML/">repo</a>ï¼‰ï¼Œä¸»è¦æ–¹æ³•å®ç°äº†<code>fit,predict,evaluate</code>ï¼Œä»£ç ä¸­åŒ…å«ä¸€å®šçš„æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®å¯ä»¥åœ¨è¯„è®ºåŒºç•™è¨€ã€‚</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> supervised<span class="token punctuation">.</span>_base <span class="token keyword">import</span> SupervisedModel<span class="token keyword">class</span> <span class="token class-name">Bayes</span><span class="token punctuation">(</span>SupervisedModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Bayes model, multi-class (or binary) classifier.    Bayes models include Gaussian, Multinomial, Bernoulli,    however here I only implemented Gaussian.    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>_prior_dict <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_mean_dict <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_cov_dict <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_cov_all <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_p <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_mean_dict <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_cov_dict <span class="token keyword">is</span> None \                <span class="token operator">or</span> self<span class="token punctuation">.</span>_prior_dict <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_p <span class="token operator">!=</span> p<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>_prior_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            self<span class="token punctuation">.</span>_mean_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            self<span class="token punctuation">.</span>_cov_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            self<span class="token punctuation">.</span>_p <span class="token operator">=</span> p        <span class="token comment" spellcheck="true"># Calculate mean and co-variance matrix for each class</span>        all_class <span class="token operator">=</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span>        <span class="token keyword">for</span> c <span class="token keyword">in</span> all_class<span class="token punctuation">:</span>            group <span class="token operator">=</span> x<span class="token punctuation">[</span>label <span class="token operator">==</span> c<span class="token punctuation">]</span>            mean<span class="token punctuation">,</span> cov <span class="token operator">=</span> self<span class="token punctuation">.</span>__param_gaussian<span class="token punctuation">(</span>group<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>_prior_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">=</span> group<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> n            self<span class="token punctuation">.</span>_mean_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">=</span> mean            self<span class="token punctuation">.</span>_cov_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">=</span> cov        <span class="token comment" spellcheck="true"># Calculate the whole co-variance matrix</span>        _<span class="token punctuation">,</span> cov <span class="token operator">=</span> self<span class="token punctuation">.</span>__param_gaussian<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_cov_all <span class="token operator">=</span> cov        <span class="token comment" spellcheck="true"># Calculate loss on x</span>        _<span class="token punctuation">,</span> loss <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_cov_dict <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> self<span class="token punctuation">.</span>_mean_dict <span class="token keyword">is</span> <span class="token operator">not</span> None        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_cov_all <span class="token keyword">is</span> <span class="token operator">not</span> None        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_p <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Default: non-linear classifier</span>        linear <span class="token operator">=</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> <span class="token string">'linear'</span> <span class="token keyword">in</span> kwargs<span class="token punctuation">:</span>            <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>kwargs<span class="token punctuation">[</span><span class="token string">'linear'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bool<span class="token punctuation">)</span>            linear <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'linear'</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Calculate posterior propability for each class</span>        <span class="token comment" spellcheck="true"># All class share a same co-variance matrix if linear == True</span>        prob<span class="token punctuation">,</span> label_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> c<span class="token punctuation">,</span> mean <span class="token keyword">in</span> self<span class="token punctuation">.</span>_mean_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> linear<span class="token punctuation">:</span>                cov <span class="token operator">=</span> self<span class="token punctuation">.</span>_cov_all            <span class="token keyword">else</span><span class="token punctuation">:</span>                cov <span class="token operator">=</span> self<span class="token punctuation">.</span>_cov_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span>            prior <span class="token operator">=</span> self<span class="token punctuation">.</span>_prior_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span>            current_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>__posterior_gaussian<span class="token punctuation">(</span>x<span class="token punctuation">,</span> prior<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> cov<span class="token punctuation">)</span>            prob<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_prob<span class="token punctuation">)</span>            label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Get index of class having maximum probability for each x</span>        pred_val <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prob<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        label_list <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>label_list<span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> label_list<span class="token punctuation">[</span>pred_val<span class="token punctuation">]</span>        <span class="token keyword">return</span> pred_label    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Calculate 0-1 loss</span>        loss <span class="token operator">=</span> np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred_label <span class="token operator">-</span> label<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Use loss to calculate precision</span>        precision <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> loss <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">__param_gaussian</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Estimate mean and variance."""</span>        mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        diff <span class="token operator">=</span> x <span class="token operator">-</span> mean        cov <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>diff<span class="token punctuation">.</span>T<span class="token punctuation">,</span> diff<span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> mean<span class="token punctuation">,</span> cov    @staticmethod    <span class="token keyword">def</span> <span class="token function">__posterior_gaussian</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> prior<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">,</span>                             mean<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> cov<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Calculate posterior probability P(wi | x)."""</span>        <span class="token comment" spellcheck="true"># Calculate likelihood probability:</span>        <span class="token comment" spellcheck="true"># P(xj | wi) ~ 1 / sqrt(det(cov))</span>        <span class="token comment" spellcheck="true"># * exp(-0.5 * (xj - mean)^T * cov^(-1) * (xi - mean))</span>        diff <span class="token operator">=</span> x <span class="token operator">-</span> mean        coef <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>det<span class="token punctuation">(</span>cov<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span>        inv <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>pinv<span class="token punctuation">(</span>cov<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Get exponent for xj (0 &lt; j &lt; n)</span>        exponents <span class="token operator">=</span> np<span class="token punctuation">.</span>apply_along_axis<span class="token punctuation">(</span>            <span class="token keyword">lambda</span> row<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">(</span>np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>row<span class="token punctuation">,</span> inv<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> diff<span class="token punctuation">)</span>        likelihood <span class="token operator">=</span> coef <span class="token operator">*</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> exponents<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Posterior = prior * likelihood / evidence (omitted)</span>        posterior <span class="token operator">=</span> prior <span class="token operator">*</span> likelihood        <span class="token keyword">return</span> posterior<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="æ‹“å±•ï¼šåˆ†ç±»é¢å½¢çŠ¶"><a href="#æ‹“å±•ï¼šåˆ†ç±»é¢å½¢çŠ¶" class="headerlink" title="æ‹“å±•ï¼šåˆ†ç±»é¢å½¢çŠ¶"></a>æ‹“å±•ï¼šåˆ†ç±»é¢å½¢çŠ¶</h2><p>ä¸€èˆ¬è€Œè¨€ï¼Œè´å¶æ–¯åˆ†ç±»å™¨å¹¶ä¸æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ã€‚</p><h3 id="é«˜æ–¯æ¨¡å‹"><a href="#é«˜æ–¯æ¨¡å‹" class="headerlink" title="é«˜æ–¯æ¨¡å‹"></a>é«˜æ–¯æ¨¡å‹</h3><p>ä¸åŒç±»ä¹‹é—´çš„åˆ†ç±»é¢æ˜¯é«˜æ–¯é¢ä¹‹é—´çš„ç›¸äº¤é¢ï¼Œå’Œæ¯ä¸ªç±»çš„æ¨¡å‹å‚æ•°æœ‰å…³ã€‚</p><p>ç”¨äºŒç»´ç‰¹å¾ã€å¤šåˆ†ç±»çš„é«˜æ–¯åˆ†ç±»é¢çš„å›¾åƒè¯´æ˜ä¼šæ›´æ¸…æ™°ï¼ˆæ¦‚ç‡å¯†åº¦è¡¨ç°ä¸ºå›¾åƒä¸­çš„é«˜åº¦zå€¼ï¼Œä¸åŒçš„å³°è¡¨ç¤ºä¸åŒç±»çš„ä¸­å¿ƒæ¦‚ç‡å¯†åº¦ï¼‰ï¼š</p><p><img src="/Machine-Learning-02-Bayes/multiclass.png" alt></p><p>é™åˆ¶äº†äºŒç»´ç‰¹å¾ä¸äºŒåˆ†ç±»çš„é«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¹‹åï¼Œåˆ†ç±»é¢å…¶å®æœ‰ä¸€äº›æœ‰è¶£çš„è§„å¾‹ï¼Œè¿™æ˜¯ç”±é«˜æ–¯åˆ†å¸ƒçš„å½¢çŠ¶é€ æˆçš„ã€‚</p><p>è¿™é‡Œä»¥äºŒåˆ†ç±»ã€äºŒç»´ç‰¹å¾çš„é«˜æ–¯åˆ†ç±»æ¨¡å‹ä¸ºä¾‹è¯´æ˜è¿™ä¸€ç‚¹ï¼Œä¸‹å›¾å±•ç¤ºäº†ä¸åŒçš„å‚æ•°ï¼ˆ$\mu,\Sigma$ï¼‰å¸¦æ¥åˆ†ç±»é¢çš„ä¸åŒï¼š</p><p><img src="/Machine-Learning-02-Bayes/2class.png" alt></p><p>å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒä¸‰ç»´å›¾ï¼š</p><p><img src="/Machine-Learning-02-Bayes/2class2.png" alt></p><p>é‚£ä¹ˆï¼Œé«˜æ–¯æ¨¡å‹çš„å‚æ•°åˆæ˜¯å¦‚ä½•å½±å“åˆ†ç±»é¢å½¢çŠ¶çš„å‘¢ï¼Ÿ</p><p>å¯ä»¥è¯æ˜æœ‰ä»¥ä¸‹ç»“è®ºï¼ˆè¯æ˜è§é™„å½•ï¼‰ï¼š</p><ul><li><p>ç±»çš„$\mu$å‚æ•°ä¸ä¼šå½±å“åˆ†ç±»é¢çš„æ€§è´¨ï¼ˆçº¿æ€§/éçº¿æ€§ï¼‰ï¼Œåªä¼šæ”¹å˜ç±»åœ¨é«˜ç»´ç©ºé—´çš„ä¸­å¿ƒä½ç½®ã€‚</p></li><li><p>å¦‚æœæ‰€æœ‰ç‰¹å¾å‡æ˜¯ç‹¬ç«‹åˆ†å¸ƒï¼Œä¸”æ‰€æœ‰ç±»å…±äº«åæ–¹å·®çŸ©é˜µï¼Œå³ï¼š$\Sigma_j=\sigma^2I$ï¼Œé‚£ä¹ˆåˆ†ç±»é¢æ˜¯çº¿æ€§çš„ï¼Œä¸”ä¸¤ä¸ªç±»ä¹‹é—´çš„åˆ†ç±»ç›´çº¿å‚ç›´ç±»ä¸­å¿ƒä¹‹é—´çš„è¿çº¿ã€‚</p></li><li><p>å¦‚æœæ‰€æœ‰ç‰¹å¾å‡å…±äº«åæ–¹å·®çŸ©é˜µï¼Œå³ï¼š$\Sigma_j=\Sigma=cov(X)$ï¼Œé‚£ä¹ˆåˆ†ç±»é¢ä¹Ÿæ˜¯çº¿æ€§çš„ï¼Œä½†æ˜¯ç›´çº¿ä¼šå­˜åœ¨ä¸€å®šçš„å€¾æ–œã€‚</p></li><li><p>å¦‚æœä¸æ»¡è¶³è¿™ä¸¤ä¸ªæ¡ä»¶ä¹‹é—´çš„ä»»æ„æƒ…å†µï¼Œé‚£ä¹ˆåˆ†ç±»é¢æ˜¯åœ†é”¥æ›²çº¿ï¼ˆæŠ›ç‰©çº¿ã€åŒæ›²çº¿ã€åœ†â€¦â€¦ï¼‰ã€‚</p></li></ul><h2 id="ç‰¹ç‚¹"><a href="#ç‰¹ç‚¹" class="headerlink" title="ç‰¹ç‚¹"></a>ç‰¹ç‚¹</h2><ul><li>å¯¹å¶å°”çš„æ•°æ®å™ªå£°é²æ£’æ€§å¥½ï¼Œå› ä¸ºä½¿ç”¨äº†å‡è®¾æ¨¡å‹ï¼Œç›¸å½“äºæ¨¡å‹çš„ä¿¡æ¯ä¸å®Œå…¨æ¥è‡ªæ•°æ®ã€‚</li><li>ä½†æ˜¯ä¹Ÿå› ä¸ºæ¨¡å‹è‡ªå¸¦å‡è®¾ï¼Œåœ¨ä¸æ»¡è¶³å‡è®¾æƒ…å½¢çš„æ•°æ®ä¸Šæ‹Ÿåˆæ•ˆæœä¸å¥½ã€‚</li></ul><h2 id="é™„å½•ï¼š"><a href="#é™„å½•ï¼š" class="headerlink" title="é™„å½•ï¼š"></a>é™„å½•ï¼š</h2><h3 id="å¤šç»´é«˜æ–¯å‚æ•°ä¼°è®¡æ¨å¯¼ï¼ˆDeriving-the-Maximum-Likelihood-Estimatorsï¼‰"><a href="#å¤šç»´é«˜æ–¯å‚æ•°ä¼°è®¡æ¨å¯¼ï¼ˆDeriving-the-Maximum-Likelihood-Estimatorsï¼‰" class="headerlink" title="å¤šç»´é«˜æ–¯å‚æ•°ä¼°è®¡æ¨å¯¼ï¼ˆDeriving the Maximum Likelihood Estimatorsï¼‰"></a>å¤šç»´é«˜æ–¯å‚æ•°ä¼°è®¡æ¨å¯¼ï¼ˆDeriving the Maximum Likelihood Estimatorsï¼‰</h3><p>æ¥æºï¼š<a href="https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian">https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian</a></p><p>æˆ–è€…æŸ¥çœ‹æ–‡æ¡£ç‰ˆæœ¬ï¼š<a href="https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf">https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf</a></p><p><img src="/Machine-Learning-02-Bayes/appendix1.png" alt></p><p><img src="/Machine-Learning-02-Bayes/appendix2.png" alt></p><p><img src="/Machine-Learning-02-Bayes/appendix3.png" alt></p><h3 id="é«˜æ–¯åˆ†å¸ƒå‚æ•°ä¸åˆ†ç±»é¢å½¢çŠ¶è¯æ˜"><a href="#é«˜æ–¯åˆ†å¸ƒå‚æ•°ä¸åˆ†ç±»é¢å½¢çŠ¶è¯æ˜" class="headerlink" title="é«˜æ–¯åˆ†å¸ƒå‚æ•°ä¸åˆ†ç±»é¢å½¢çŠ¶è¯æ˜"></a>é«˜æ–¯åˆ†å¸ƒå‚æ•°ä¸åˆ†ç±»é¢å½¢çŠ¶è¯æ˜</h3><p>æ¥æºï¼š<a href="https://www.byclb.com/TR/Tutorials/neural_networks/ch4_1.htm">https://www.byclb.com/TR/Tutorials/neural_networks/ch4_1.htm</a></p><p>ç”±äºè¯æ˜è®¨è®ºè¿‡é•¿ï¼Œç¯‡å¹…æ‰€é™ï¼Œåœ¨æ­¤ä¸è´´å‡ºè¯¦ç»†è¯æ˜å†…å®¹ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬äºŒç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†è´å¶æ–¯åˆ†ç±»çš„è¯¦ç»†ç†è®ºå’Œç®€å•é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨çš„å®ç°ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkä¸pr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-01ï¼ˆä¸Šï¼‰ï¼šæœºå™¨å­¦ä¹ ç»¼è¿°</title>
    <link href="http://riroaki.github.io/Machine-Learning-01-Overview/"/>
    <id>http://riroaki.github.io/Machine-Learning-01-Overview/</id>
    <published>2019-06-20T16:00:00.000Z</published>
    <updated>2019-07-02T18:08:24.259Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¸ŠåŠéƒ¨åˆ†ï¼Œå†…å®¹åŒ…å«äº†æœºå™¨å­¦ä¹ çš„ç†è®ºç»¼è¿°ã€ç®—æ³•åˆ†ç±»ã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkå’Œprã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>å¦‚ä»Šæ·±åº¦å­¦ä¹ ã€æ•°æ®æŒ–æ˜ã€æœºå™¨å­¦ä¹ è¿™äº›æ¦‚å¿µå·²ç»ğŸ”¥åˆ°æˆä¸ºæ»¡å¤§è¡—éƒ½æ˜¯çš„æ¦‚å¿µï¼Œç”±äºå…¶é—¨æ§›ä½ï¼ˆè°ƒåŒ…ï¼‰å’ŒæŸäº›fancyçš„åŠŸèƒ½ï¼ŒåŠ ä¸Šåª’ä½“çš„å®£ä¼ å’Œé«˜è–ªçš„è¯±æƒ‘ï¼Œæ— è®ºè®¡ç®—æœºä¸“ä¸šè¿˜æ˜¯éè®¡ç®—æœºä¸“ä¸šå‡ºèº«çš„äººä»¬éƒ½çƒ­è¡·äºåœ¨å…¶ä¸­å¯»æ‰¾æœºä¼šï¼Œæˆ‘è¿™ä¸ªè½¯å·¥çš„èœğŸ”ä¹Ÿä¸ä¾‹å¤–ã€‚å½“ç„¶ï¼Œç›®å‰æ­£å¤„äºæ–°æ‰‹æœŸã€‚</p><p>è¿™ä¸€ä¸ªç³»åˆ—ä¸»è¦è®°å½•äº†æˆ‘åœ¨ZJUä¸Šæ•°æ®æŒ–æ˜è¯¾å­¦ä¹ å’Œæ¢³ç†çš„æœºå™¨å­¦ä¹ çš„çŸ¥è¯†ï¼Œå¹¶ä¸”åŒ…å«ä¸€äº›é¢å¤–çš„è¡¥å……çŸ¥è¯†ã€‚å…·ä½“å†…å®¹åŒ…æ‹¬äº†æ•°å­¦ç†è®ºå’Œä»£ç å®ç°ï¼Œå¸Œæœ›èƒ½å¤Ÿç»™å…¥é—¨è€…ï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±ï¼‰æä¾›ä¸€ä¸ªå‚è€ƒã€‚</p><p>ç”±äºæœ¬äººæ‡’ç™Œæ™šæœŸï¼Œåšå®¢å°†ä¸å®šæœŸæ›´æ–°ã€‚</p><p>è¯»è€…å¦‚æœæœ‰é—®é¢˜æˆ–è€…ç•™è¨€å¯ä»¥ç›´æ¥åœ¨ç›¸å…³çš„åšæ–‡ä¸‹é¢ç•™è¨€ï¼Œå¯ä»¥å…±åŒæ¢è®¨è§£å†³ã€‚</p><p>å½“ç„¶ä¹Ÿå¯ä»¥é‚®ä»¶è”ç³»æœ¬äººï¼š<a href="mailto:lilq1285@163.com">lilq1285@163.com</a>ï¼Œæ¬¢è¿ç†æ€§è®¨è®ºã€‚</p><p><strong>æœ¬ç³»åˆ—å†…å®¹å±äºä¸ªäººåŸåˆ›ï¼Œè½¬è½½è¯·å£°æ˜å‡ºå¤„ï¼Œå•†ä¸šè½¬è½½è¯·è”ç³»æœ¬äººï¼Œé‚®ç®±åŒä¸Šã€‚</strong></p><h2 id="æœºå™¨å­¦ä¹ æ€»è§ˆ"><a href="#æœºå™¨å­¦ä¹ æ€»è§ˆ" class="headerlink" title="æœºå™¨å­¦ä¹ æ€»è§ˆ"></a>æœºå™¨å­¦ä¹ æ€»è§ˆ</h2><p>æœºå™¨å­¦ä¹ å‘æºäºç»Ÿè®¡å­¦ï¼Œä¸»è¦çš„ç›®æ ‡æ˜¯ç”¨æ•°å­¦å’Œç¨‹åºè¯­è¨€æè¿°äº‹ç‰©çš„è§„å¾‹ï¼Œä»è€Œä¸ºé¢„æµ‹ã€å†³ç­–æä¾›å‚è€ƒã€‚</p><p>ä»¥å…¨å±€çš„è§†è§’æ¥çœ‹æœºå™¨å­¦ä¹ è¿™ä¸€é¢†åŸŸçš„ç®—æ³•ï¼Œä¸»è¦åˆ†ä¸ºæœ‰ç›‘ç£ï¼ˆSupervisedï¼‰å­¦ä¹ å’Œæ— ç›‘ç£ï¼ˆUnsupervisedï¼‰å­¦ä¹ ä¸¤ç±»ï¼Œæ­¤å¤–è¿˜æœ‰åŠç›‘ç£ï¼ˆHalf-supervisedï¼‰å­¦ä¹ ã€å¼ºåŒ–ï¼ˆReinforcementï¼‰å­¦ä¹ ï¼š</p><h3 id="æœ‰ç›‘ç£å­¦ä¹ "><a href="#æœ‰ç›‘ç£å­¦ä¹ " class="headerlink" title="æœ‰ç›‘ç£å­¦ä¹ "></a>æœ‰ç›‘ç£å­¦ä¹ </h3><h4 id="ä¸»è¦ä»»åŠ¡"><a href="#ä¸»è¦ä»»åŠ¡" class="headerlink" title="ä¸»è¦ä»»åŠ¡"></a>ä¸»è¦ä»»åŠ¡</h4><ul><li>å›å½’ï¼ˆRegressionï¼‰é€šå¸¸ç›®æ ‡æ˜¯å¾—åˆ°è¿ç»­çš„æ›²çº¿ï¼Œè¾“å‡ºæ˜¯è¿ç»­çš„å€¼</li><li>åˆ†ç±»ï¼ˆClassificationï¼‰é€šå¸¸ç›®æ ‡æ˜¯å¾—åˆ°å†³ç­–çš„è¾¹ç•Œï¼Œè¾“å‡ºçš„æ˜¯ç¦»æ•£çš„ç±»åˆ«</li></ul><h4 id="å¸¸è§ç®—æ³•"><a href="#å¸¸è§ç®—æ³•" class="headerlink" title="å¸¸è§ç®—æ³•"></a>å¸¸è§ç®—æ³•</h4><ul><li>Linear Regressionï¼šçº¿æ€§å›å½’ï¼Œä»¥çº¿æ€§æ–¹å¼ç»„åˆç‰¹å¾æ‹Ÿåˆè¿ç»­æ›²çº¿</li><li>Bayesï¼šè´å¶æ–¯åˆ†ç±»ï¼Œé€šè¿‡æ¦‚ç‡æ¨¡å‹è®¡ç®—æ ·æœ¬å±äºå„ä¸ªåˆ†ç±»çš„åéªŒæ¦‚ç‡ï¼Œè¿›è¡Œåˆ†ç±»</li><li>Logistic Regressionï¼šé€»è¾‘å›å½’ï¼Œåœ¨çº¿æ€§å›å½’åŸºç¡€ä¸Šå¢åŠ æ¿€æ´»å‡½æ•°ä»¥è¿›è¡Œåˆ†ç±»</li><li>Support Vector Machineï¼šæ”¯æŒå‘é‡æœºï¼Œé€‰å–å†³ç­–é¢è¾ƒè¿‘çš„ç‚¹ç”¨æ¥è®¡ç®—å†³ç­–é¢çš„å‚æ•°</li><li>K Nearest Neighborï¼šKè¿‘é‚»ï¼Œå¯»æ‰¾è·ç¦»è¾ƒè¿‘çš„Kä¸ªæ ·æœ¬çš„æ ‡ç­¾å–ä¼—æ•°ä½œä¸ºæ ·æœ¬å½’ç±»</li><li>Perceptronï¼šæ„ŸçŸ¥æœºï¼ŒäºŒåˆ†ç±»ç®—æ³•ï¼Œæœ€ç®€å•çš„ç¥ç»ç½‘ç»œ</li><li>Decision Treeï¼šå†³ç­–æ ‘ï¼Œå¯ä»¥çœ‹ä½œä»æ ·æœ¬æ•°æ®ä¸­å­¦ä¹ if-elseè¯­å¥çš„ç»„åˆï¼Œæ¯ä¸€ä¸ªåˆ¤æ–­éƒ½æ˜¯æ•°çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ç°åˆ†ç±»</li><li>Linear Discriminant Analysisï¼šçº¿æ€§åˆ¤åˆ«åˆ†æï¼Œé€šè¿‡æ‰¾åˆ°ç‰¹å¾çš„çº¿æ€§ç»„åˆä»¥ç”¨äºé™ç»´ï¼Œä¹Ÿæ˜¯ä¸€ç§åˆ†ç±»ç®—æ³•</li></ul><h4 id="ç®—æ³•çš„åˆ†ç±»"><a href="#ç®—æ³•çš„åˆ†ç±»" class="headerlink" title="ç®—æ³•çš„åˆ†ç±»"></a>ç®—æ³•çš„åˆ†ç±»</h4><ol><li>å¦‚æœä»ç®—æ³•è§£å†³çš„é—®é¢˜åˆ†ç±»ï¼Œå¯ä»¥åˆ†ä¸ºå›å½’å’Œåˆ†ç±»ä¸¤å¤§ç±»ç®—æ³•ï¼š</li></ol><ul><li>å…¶ä¸­ï¼Œçº¿æ€§å›å½’ä¸ºå›å½’ç±»çš„ç®—æ³•ï¼Œå…¶ä½™ç®—æ³•å‡ä¸»è¦ç”¨äºåˆ†ç±»ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æœ‰å›å½’çš„ä½œç”¨ã€‚å› ä¸ºè¿™äº›åˆ†ç±»ç®—æ³•å¤§å¤šæ˜¯åœ¨è¿ç»­çš„è¾“å‡ºå¤–è¿›è¡Œå¤„ç†è·å¾—ç±»åˆ«ï¼Œå¦‚é€»è¾‘å›å½’ã€æ„ŸçŸ¥æœºã€æ”¯æŒå‘é‡æœºç­‰ï¼Œå¦‚æœç”¨åœ¨å›å½’ä¸Šåˆ™è¾“å‡ºçš„æ˜¯åˆ†ç±»å‰è®¡ç®—çš„ç»“æœã€‚</li></ul><ol start="2"><li>å¦‚æœä»å†³ç­–é¢çš„è§’åº¦æ¥çœ‹ï¼Œä¸Šè¿°çš„åˆ†ç±»ç®—æ³•å¯ä»¥åˆ†ä¸ºçº¿æ€§åˆ†ç±»ç®—æ³•å’Œéçº¿æ€§åˆ†ç±»ç®—æ³•ï¼š</li></ol><ul><li>çº¿æ€§åˆ†ç±»ç®—æ³•ï¼šåˆ†ç±»é¢ä¸ºçº¿æ€§/è¾“å‡ºå‡½æ•°ä¸ºçº¿æ€§å½¢å¼ï¼ˆæœ¬è´¨ç›¸åŒï¼Œé‡‡ç”¨ä¸åŒçš„ç›®æ ‡å‡½æ•°å¾—åˆ°çš„æ¨¡å‹ï¼‰<ul><li>åŒ…æ‹¬ï¼šé€»è¾‘å›å½’ã€æ”¯æŒå‘é‡æœºã€æ„ŸçŸ¥æœºã€çº¿æ€§åˆ¤åˆ«åˆ†æ</li></ul></li><li>éçº¿æ€§ç®—æ³•ï¼šåˆ†ç±»é¢ä¸ºéçº¿æ€§/è¾“å‡ºå‡½æ•°çš„å½¢å¼ä¸ºéçº¿æ€§<ul><li>åŒ…æ‹¬ï¼šè´å¶æ–¯ã€Kè¿‘é‚»ã€å†³ç­–æ ‘</li></ul></li></ul><ol start="3"><li>å¦‚æœä»ç®—æ³•çš„å®é™…å«ä¹‰è§’åº¦çœ‹ï¼Œä¸Šè¿°çš„åˆ†ç±»ç®—æ³•å¯ä»¥åˆ†ä¸ºç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹ï¼š</li></ol><ul><li>ç”Ÿæˆæ¨¡å‹ï¼šæŒ‰ç…§æ¡ä»¶æ¦‚ç‡å»ºç«‹æ¨¡å‹ï¼ŒåŸºäºé«˜æ–¯åˆ†å¸ƒç­‰å‡è®¾ï¼Œå­¦ä¹ æ¨¡å‹çš„å‚æ•°ç”¨äºåˆ†ç±»<ul><li>åŒ…æ‹¬ï¼šè´å¶æ–¯æ¨¡å‹ã€çº¿æ€§åˆ¤åˆ«åˆ†æ</li></ul></li><li>åˆ¤åˆ«æ¨¡å‹ï¼šå‡ºäºæœ€å¤§åŒ–åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼Œè¿›è¡Œè®­ç»ƒ<ul><li>åŒ…æ‹¬ï¼šå¤§éƒ¨åˆ†å…¶ä»–åˆ†ç±»ç®—æ³•</li></ul></li></ul><p>åœ¨åŸºæœ¬ç®—æ³•çš„åŸºç¡€ä¸Šï¼Œç°ä»£æœºå™¨å­¦ä¹ å¸¸è§çš„è¿˜æœ‰é›†æˆï¼ˆEnsembleï¼‰å­¦ä¹ ï¼Œå…¶æ ¸å¿ƒæ˜¯â€ä¸‰ä¸ªè‡­å±åŒ ï¼Œé¡¶ä¸ªè¯¸è‘›äº®â€ï¼Œå¹¶ä¸è‡´åŠ›äºäº§ç”Ÿæœ€å¼ºçš„å•ä¸ªåˆ†ç±»å™¨ï¼Œè€Œæ˜¯é€šè¿‡æŠŠè®­ç»ƒä¸åŒçš„è¾ƒå¼±åˆ†ç±»å™¨ï¼Œå¹¶è¿›è¡Œé›†åˆå†³ç­–ä»¥è·å¾—æœ€å¥½çš„åˆ†ç±»æ•ˆæœã€‚</p><h4 id="é›†æˆå­¦ä¹ "><a href="#é›†æˆå­¦ä¹ " class="headerlink" title="é›†æˆå­¦ä¹ "></a>é›†æˆå­¦ä¹ </h4><ul><li>Bagging/Bootstrap Aggregatingï¼šé€šè¿‡éšæœºåˆ‡åˆ†æ•°æ®é›†ï¼Œå¹¶è¡Œè®­ç»ƒç›¸åŒæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„åˆ†ç±»æ•ˆæœã€‚<ul><li>éšæœºæ£®æ—ï¼ˆRandom Forestï¼‰ç®—æ³•æ­£æ˜¯åŸºäºbaggingç®—æ³•å®ç°ã€‚</li></ul></li><li>Boostingï¼šé€šè¿‡è®­ç»ƒä¸€ç³»åˆ—å¼±åˆ†ç±»å™¨å¹¶ç»„åˆè·å¾—å¼ºåˆ†ç±»å™¨ã€‚</li><li>Stackingï¼šè®­ç»ƒä¸€ä¸ªç»„åˆä¸åŒæ¨¡å‹çš„é«˜å±‚æ¨¡å‹è¿›è¡Œåˆ†ç±»ï¼ˆä¸Šé¢ä¸¤ç§ç®—æ³•å¯¹åº•å±‚æ¨¡å‹çš„ç»„åˆæ–¹å¼æ˜¯ç¡®å®šçš„ï¼‰ã€‚</li></ul><h3 id="æ— ç›‘ç£å­¦ä¹ "><a href="#æ— ç›‘ç£å­¦ä¹ " class="headerlink" title="æ— ç›‘ç£å­¦ä¹ "></a>æ— ç›‘ç£å­¦ä¹ </h3><h4 id="ä¸»è¦ä»»åŠ¡-1"><a href="#ä¸»è¦ä»»åŠ¡-1" class="headerlink" title="ä¸»è¦ä»»åŠ¡"></a>ä¸»è¦ä»»åŠ¡</h4><ul><li>é™ç»´ï¼ˆDimensionality Reductionï¼‰æŒ‡çš„æ˜¯å°†æ ·æœ¬ç©ºé—´ä»é«˜ç»´ç‰¹å¾æŠ•å½±åˆ°è¾ƒä½ç»´åº¦çš„ç‰¹å¾ä»è€Œå®ç°æé«˜è®¡ç®—æ•ˆç‡çš„ä½œç”¨ã€‚</li><li>èšç±»ï¼ˆClusteringï¼‰æŒ‡çš„æ˜¯å°†æ— æ ‡ç­¾çš„æ ·æœ¬æŒ‰ç…§æ ·æœ¬ä¹‹é—´çš„è·ç¦»ä¿¡æ¯ç­‰ï¼Œå°†ç›¸è¿‘çš„æ ·æœ¬å½’ä¸ºä¸€ä¸ªç°‡çš„ç®—æ³•ï¼Œå¯ä»¥ç†è§£ä¸ºæ²¡æœ‰æ ·æœ¬æ ‡ç­¾çš„åˆ†ç±»ç®—æ³•ã€‚</li></ul><h4 id="å¸¸è§ç®—æ³•-1"><a href="#å¸¸è§ç®—æ³•-1" class="headerlink" title="å¸¸è§ç®—æ³•"></a>å¸¸è§ç®—æ³•</h4><ul><li>Principle Component Analysisï¼šä¸»æˆåˆ†åˆ†æï¼Œé€šè¿‡æå–åæ–¹å·®çŸ©é˜µä¸­çš„ç‰¹å¾å‘é‡ä½œä¸ºæ–°ç‰¹å¾å®ç°é™ç»´ã€‚<ul><li>ä¸çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰ç›¸ä¼¼çš„ç®—æ³•ã€‚</li></ul></li><li>K Meansï¼šKå‡å€¼ç®—æ³•ï¼Œé€šè¿‡æŠ½å–ç›¸è¿‘ç‚¹ç°‡çš„é‡å¿ƒä½œä¸ºç°‡çš„ä»£è¡¨æ¥å®ç°èšç±»ã€‚</li><li>K Medoidsï¼šKä¸­å¿ƒç‚¹ç®—æ³•ï¼Œå’ŒK Meansç®—æ³•ç›¸è¿‘ï¼Œä¸åŒçš„æ˜¯é€‰å–ç°‡ä¸­æœ€æ¥è¿‘é‡å¿ƒçš„ç‚¹ä½œä¸ºç°‡çš„ä»£è¡¨ã€‚</li><li>Spectral Clusteringï¼šè°±èšç±»ï¼Œé€šè¿‡é™ç»´æ–¹æ³•å’ŒK Meansç®—æ³•å®ç°èšç±»ã€‚</li><li>Gaussian Mixture Modelï¼šé«˜æ–¯æ··åˆæ¨¡å‹ï¼Œæ˜¯åŸºäºé«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ï¼Œé€šè¿‡ç‚¹ç°‡çš„åˆ†å¸ƒä¼°è®¡å‚æ•°ä»¥å®ç°èšç±»ã€‚<ul><li>K Meansç®—æ³•å¯ä»¥è§†ä¸ºGMMçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ã€‚</li></ul></li><li>Matrix Factorizationï¼šçŸ©é˜µåˆ†è§£ï¼Œæ˜¯ä¸€ç±»é™ç»´ç®—æ³•ï¼ŒåŒ…æ‹¬å¥‡å¼‚å€¼åˆ†è§£ã€çŸ©é˜µéè´Ÿåˆ†è§£å’Œç¨€ç–ç¼–ç ç­‰ç®—æ³•ã€‚</li></ul><h4 id="ç®—æ³•çš„åˆ†ç±»-1"><a href="#ç®—æ³•çš„åˆ†ç±»-1" class="headerlink" title="ç®—æ³•çš„åˆ†ç±»"></a>ç®—æ³•çš„åˆ†ç±»</h4><ol><li>å¦‚æœæŒ‰ç…§ä¸»è¦ä»»åŠ¡ï¼Œå¯ä»¥å°†ç®—æ³•åˆ†ä¸ºé™ç»´ç®—æ³•å’Œèšç±»ç®—æ³•ï¼š</li></ol><ul><li>é™ç»´ç®—æ³•ï¼šä¸»è¦åŒ…æ‹¬ä¸»æˆåˆ†åˆ†æã€çŸ©é˜µåˆ†è§£</li><li>èšç±»ç®—æ³•ï¼šä¸»è¦åŒ…æ‹¬Kå‡å€¼ã€Kä¸­å¿ƒç‚¹ã€è°±èšç±»ã€é«˜æ–¯æ··åˆæ¨¡å‹</li></ul><h3 id="åŠç›‘ç£å­¦ä¹ "><a href="#åŠç›‘ç£å­¦ä¹ " class="headerlink" title="åŠç›‘ç£å­¦ä¹ "></a>åŠç›‘ç£å­¦ä¹ </h3><p>åˆ©ç”¨å°‘é‡æ ‡æ³¨æ ·æœ¬å’Œå¤§é‡æœªæ ‡æ³¨æ ·æœ¬è¿›è¡Œæœºå™¨å­¦ä¹ çš„ç®—æ³•ã€‚</p><p>ç”±äºæœ¬äººå¹¶ä¸äº†è§£è¿™ä¸€å—ï¼Œæ‰€ä»¥æ­¤å¤„å†…å®¹ä¸ä½œè¯¦ç»†ä»‹ç»ï¼Œæœ‰å…´è¶£è€…è¯·è‡ªè¡Œè°·æ­Œã€‚</p><h3 id="å¼ºåŒ–å­¦ä¹ "><a href="#å¼ºåŒ–å­¦ä¹ " class="headerlink" title="å¼ºåŒ–å­¦ä¹ "></a>å¼ºåŒ–å­¦ä¹ </h3><p>æ²¡æœ‰ç‰¹å®šçš„ç›®æ ‡ï¼Œå¼ºè°ƒç¯å¢ƒçš„åé¦ˆä½œç”¨ï¼Œé€šè¿‡åº”å¯¹ç¯å¢ƒè°ƒæ•´ç­–ç•¥çš„ç®—æ³•ã€‚</p><p>ç”±äºæœ¬äººå¹¶ä¸äº†è§£è¿™ä¸€å—ï¼Œæ‰€ä»¥æ­¤å¤„å†…å®¹ä¸ä½œè¯¦ç»†ä»‹ç»ï¼Œæœ‰å…´è¶£è€…è¯·è‡ªè¡Œè°·æ­Œã€‚</p><h3 id="æ·±åº¦å­¦ä¹ "><a href="#æ·±åº¦å­¦ä¹ " class="headerlink" title="æ·±åº¦å­¦ä¹ "></a>æ·±åº¦å­¦ä¹ </h3><p>è¿™ä¸€å—æ˜¯è¿‘åå¹´æ–°çš„æ–¹å‘ï¼Œä¹Ÿæ˜¯ç›®å‰æœºå™¨å­¦ä¹ æœ€ç«çš„åˆ†æ”¯ï¼Œä½†æ˜¯é¢„è®¡ä¸ä¼šåœ¨è¿‘æœŸå†…å®¹ä¸­å‡ºç°ã€‚</p><p>ç®€è¨€ä¹‹ï¼Œæ·±åº¦å­¦ä¹ å°±æ˜¯åŸºäºç¥ç»ç½‘ç»œçš„ç®—æ³•ï¼Œé€šè¿‡ç»„åˆçº¿æ€§çš„ç¥ç»å…ƒå’Œéçº¿æ€§çš„æ¿€æ´»å±‚ï¼Œä»¥åŠæ­å»ºä¸åŒç»“æ„çš„ç½‘ç»œï¼Œæ¥å®ç°å›å½’æˆ–è€…é¢„æµ‹ã€èšç±»ç­‰å·¥ä½œã€‚</p><p>å…¶â€ç¥ç»ç½‘ç»œâ€å½¢æ€çš„çµæ„Ÿå¾—ç›Šäºç”Ÿç‰©å¤§è„‘çš„ç¥ç»å…ƒè¿æ¥ç»“æ„ï¼Œè®©äººè”æƒ³åˆ°â€æœºå™¨çš„å¤§è„‘ğŸ§ â€ï¼ŒåŠ ä¸Šè¯¸å¦‚alphaGoç­‰ç­‰ä¸€äº›æ–°å¥‡çš„æˆå°±å¸¦æ¥çš„ç‹‚çƒ­ä½¿å¾—ä¼—äººä¸ºä¹‹ç–¯ç‹‚ï¼Œè®¸å¤šè¥é”€å·å’Œåª’ä½“ç”šè‡³è„‘æ´å¤§å¼€ï¼Œå¤§è‚†é¼“å¹â€äººå·¥æ™ºèƒ½æœ‰å®³è®ºâ€ã€‚</p><p>ä½†ç›®å‰è€Œè¨€ï¼Œå¯è§£é‡Šæ€§å·®ã€ç¼ºä¹è¾ƒç»Ÿä¸€çš„æ•°å­¦ç†è®ºæè¿°æ˜¯å…¶ç¡¬ä¼¤ã€‚è€Œä¸”ä¹Ÿæ²¡æœ‰å‡ºç°å¼ºäººå·¥æ™ºèƒ½çš„è¿¹è±¡ï¼Œç›®å‰çš„ç¥ç»ç½‘ç»œï¼Œæœ¬è´¨åªæ˜¯ä¸€ç§å¤æ‚çš„ç»Ÿè®¡æ¨¡å‹ã€‚</p><p>éšç€ç ”ç©¶é™·å…¥ç“¶é¢ˆï¼Œè¿™åœºèµ„æœ¬ä¸èˆ†è®ºçš„ç‹‚æ¬¢å·²ç»åœ¨é€æ¸å†·å´ï¼Œæœªæ¥ç©¶ç«Ÿå¦‚ä½•å‘å±•ä¹Ÿæœªå¯çŸ¥ï¼šï¼‰</p><h2 id="æœºå™¨å­¦ä¹ æ–¹æ³•è®º"><a href="#æœºå™¨å­¦ä¹ æ–¹æ³•è®º" class="headerlink" title="æœºå™¨å­¦ä¹ æ–¹æ³•è®º"></a>æœºå™¨å­¦ä¹ æ–¹æ³•è®º</h2><p><strong>æœºå™¨å­¦ä¹ çš„æœ¬è´¨åœ¨äºä»æ•°æ®æˆ–è€…å‡è®¾ä¸­å»ºç«‹æ¨¡å‹ã€å­¦ä¹ å‚æ•°ï¼Œå»æ‹Ÿåˆä¸€ä¸ªæœªçŸ¥çš„å‡½æ•°ã€‚</strong></p><p>æ ¹æ®è®ºæ–‡ã€ŠA Few Useful Things to Know about Machine Learningã€‹ï¼Œæœºå™¨å­¦ä¹ çš„è¿‡ç¨‹å¯ä»¥è¡¨ç¤ºä¸ºï¼š</p><p>$LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION$</p><p>ä¹Ÿå°±æ˜¯è¯´ï¼Œæœºå™¨å­¦ä¹ ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªè¿‡ç¨‹ï¼š</p><ol><li>è¡¨ç¤ºï¼ˆRepresentationï¼‰ï¼šä½¿ç”¨è®¡ç®—æœºèƒ½å¤Ÿæ‰§è¡Œçš„è¯­è¨€æè¿°ç®—æ³•ã€‚è¿™ä¸ªé˜¶æ®µç¡®å®šäº†æ¨¡å‹çš„ç±»å‹ï¼Œæ‰€ä»¥å†³å®šäº†æ‹Ÿåˆ/åˆ†ç±»å‡½æ•°çš„å‡è®¾ç©ºé—´ï¼ˆHypothesis Spaceï¼‰â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨è¿™ä¸€æ­¥ï¼Œæ¨¡å‹çš„å‚æ•°ä¸ªæ•°å’Œæ¨¡å‹çš„è®¡ç®—æ–¹å¼å·²ç»ç¡®å®šï¼Œæ¯”å¦‚çº¿æ€§æ¨¡å‹çš„$y=WX+B$ï¼Œé‚£ä¹ˆæ¨¡å‹æ— æ³•æ¨¡æ‹Ÿéçº¿æ€§çš„åˆ†ç±»/å›å½’ï¼Œè¿™æ˜¯é€‰å–çš„æ¨¡å‹å¯¼è‡´çš„ã€‚è€Œå…·ä½“æ˜¯å¦‚ä½•çº¿æ€§çš„å‡½æ•°ï¼Œéœ€è¦åœ¨æ¥ä¸‹æ¥çš„è¿‡ç¨‹ä¸­ç¡®å®šã€‚</li><li>è¯„ä¼°ï¼ˆEvaluationï¼‰ï¼šç”¨äºè¯„ä¼°æ¨¡å‹çš„å¥½åã€‚æ ¹æ®ä»»åŠ¡çš„ä¸åŒï¼ˆå›å½’ã€åˆ†ç±»ï¼‰ç¡®å®šäº†ä¸åŒçš„ç§ç±»ï¼ŒåŒæ—¶è¿™ä¸ªè¯„ä¼°æ–¹æ³•åº”å½“æ˜¯èƒ½å¤Ÿæ–¹ä¾¿åœ°æ‰¾åˆ°å¯¹åº”çš„ä¼˜åŒ–å‡½æ•°çš„ï¼ˆæ›´æ˜ç¡®ä¸€ç‚¹ï¼Œè¯„ä¼°çš„å‡½æ•°åº”è¯¥æ˜¯å¯å¯¼çš„ï¼‰ã€‚æˆ‘ä»¬è®­ç»ƒçš„ç›®æ ‡å°±æ˜¯æœ€å°åŒ–ç›®æ ‡å‡½æ•°ï¼ˆè¯¯å·®å‹ï¼‰æˆ–è€…æœ€å¤§åŒ–ç›®æ ‡å‡½æ•°ï¼ˆç²¾åº¦å‹ï¼‰ã€‚</li><li>ä¼˜åŒ–ï¼ˆOptimizationï¼‰ï¼šè¯„ä¼°å‡½æ•°å°±åƒè€ƒè¯•ï¼Œæœ‰äº†è€ƒè¯•æˆ‘ä»¬å°±å¯ä»¥çŸ¥é“è‡ªå·±çš„è–„å¼±ç¯èŠ‚ï¼Œä»è€Œç¡®å®šåŠªåŠ›çš„æ–¹å‘ã€‚è€Œæœ‰äº†è¯„ä¼°å‡½æ•°ï¼Œå°±æœ‰ä¸€ä¸ªå¯¹åº”çš„ä¼˜åŒ–å‡½æ•°ç”¨äºè°ƒæ•´æ¨¡å‹çš„å‚æ•°ã€‚<ul><li>é€šå¸¸æˆ‘ä»¬é‡‡ç”¨åŸºäºæ¢¯åº¦çš„æ–¹æ³•ï¼Œå…·ä½“ä¼šåœ¨ä¸‹é¢æ¢¯åº¦ä¸‹é™è¿™ä¸€æ¦‚å¿µä¸­è§£é‡Šã€‚</li></ul></li></ol><p>è®ºæ–‡ä¸­åˆ—å‡ºäº†ä¸€ä¸ªå…³äºè¿™ä¸‰ä¸ªéƒ¨åˆ†çš„è¡¨æ ¼ï¼Œåœ¨è¿™é‡Œè´´å‡ºæ¥ï¼š</p><p><img src="/Machine-Learning-01-Overview/table.png" alt></p><p>ä»è¡¨æ ¼ä¹Ÿå¯ä»¥çœ‹å‡ºæ¥ï¼Œå¯¹æŸä¸€ç§ç®—æ³•ï¼Œå¹¶éæ‰€æœ‰çš„è¯„ä¼°å‡½æ•°éƒ½èƒ½å¤Ÿä½¿ç”¨ï¼Œæœ‰äº›ç®—æ³•æ˜¯ç»‘å®šäº†è¯„ä¼°å‡½æ•°çš„ã€‚</p><p>åŒæ—¶ï¼Œè¯„ä¼°å‡½æ•°ä¸ä¼˜åŒ–å‡½æ•°å­˜åœ¨å¯¹åº”å…³ç³»ï¼Œé€‰æ‹©æŸä¸€ç±»è¯„ä¼°å‡½æ•°æ—¶ï¼Œå¯¹åº”çš„ä¼˜åŒ–ç­–ç•¥ä¹Ÿå°±å†³å®šäº†ã€‚</p><p>ï¼ˆæ¥ä¸‹ç¯‡ï¼š<a href="/Machine-Learning-01-Overview-2">æœºå™¨å­¦ä¹ æ¦‚å¿µ</a>ï¼‰</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¸ŠåŠéƒ¨åˆ†ï¼Œå†…å®¹åŒ…å«äº†æœºå™¨å­¦ä¹ çš„ç†è®ºç»¼è¿°ã€ç®—æ³•åˆ†ç±»ã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkå’Œpr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>æœºå™¨å­¦ä¸åŠ¨äº†-01ï¼ˆä¸‹ï¼‰ï¼šæœºå™¨å­¦ä¹ æ¦‚å¿µ</title>
    <link href="http://riroaki.github.io/Machine-Learning-01-Overview-2/"/>
    <id>http://riroaki.github.io/Machine-Learning-01-Overview-2/</id>
    <published>2019-06-20T16:00:00.000Z</published>
    <updated>2019-07-02T18:52:38.362Z</updated>
    
    <content type="html"><![CDATA[<p>æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¸‹åŠéƒ¨åˆ†ï¼Œå†…å®¹åŒ…å«äº†æœºå™¨å­¦ä¹ çš„æ¦‚å¿µè§£é‡Šã€‚</p><p>å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š<a href="https://github.com/Riroaki/LemonML/">https://github.com/Riroaki/LemonML/</a></p><p>æ¬¢è¿starã€forkå’Œprã€‚</p><h2 id="å¼•å­"><a href="#å¼•å­" class="headerlink" title="å¼•å­"></a>å¼•å­</h2><p>ç´§æ¥ä¸ŠåŠç¯‡æ–‡ç« çš„ç®—æ³•ä»‹ç»ï¼Œè¿™é‡Œä¸»è¦ä¼šä»‹ç»ä¸€äº›åŸºæœ¬æ¦‚å¿µã€‚</p><h2 id="é¢„å¤„ç†"><a href="#é¢„å¤„ç†" class="headerlink" title="é¢„å¤„ç†"></a>é¢„å¤„ç†</h2><h3 id="ç‰¹å¾ç¼©æ”¾"><a href="#ç‰¹å¾ç¼©æ”¾" class="headerlink" title="ç‰¹å¾ç¼©æ”¾"></a>ç‰¹å¾ç¼©æ”¾</h3><p>ç‰¹å¾ç¼©æ”¾ï¼ˆFeature Scalingï¼‰æ˜¯ä¸€é¡¹é¢„å¤„ç†æŠ€æœ¯ï¼Œå®ƒå°†æ‰€æœ‰çš„è¾“å…¥æŒ‰ç…§ç»Ÿä¸€çš„æ ‡å‡†è¿›è¡Œå¤„ç†ï¼š</p><ul><li>æœ€å¤§æœ€å°ç¼©æ”¾ï¼ˆMin-Max Normalizationï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªç‰¹å¾çš„å„ä¸ªå€¼æŒ‰ç…§å¤§å°ç¼©æ”¾åˆ°$[0,1]$çš„åŒºé—´ä¸­ã€‚</li><li>å‡å€¼ç¼©æ”¾ï¼ˆMean Normalizationï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªç‰¹å¾çš„å„ä¸ªå€¼æŒ‰ç…§å¤§å°ç¼©æ”¾åˆ°$[-1, 1]$åŒºé—´ä¸­ã€‚</li><li>æ ‡å‡†åŒ–ï¼ˆStandardizationï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªç‰¹å¾ç¼©æ”¾æˆå¹³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„å˜é‡ã€‚</li><li>å•ä½åŒ–ï¼ˆScaling to Unit Lengthï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªæ ·æœ¬çš„é•¿åº¦ï¼ˆå³å‘é‡çš„ç¬¬äºŒèŒƒæ•°ï¼‰ç¼©æ”¾ä¸º1ã€‚</li></ul><h2 id="è¯„ä¼°"><a href="#è¯„ä¼°" class="headerlink" title="è¯„ä¼°"></a>è¯„ä¼°</h2><h3 id="æ³›åŒ–-ã€æ–¹å·®ã€åå·®å’Œå™ªå£°"><a href="#æ³›åŒ–-ã€æ–¹å·®ã€åå·®å’Œå™ªå£°" class="headerlink" title="æ³›åŒ– ã€æ–¹å·®ã€åå·®å’Œå™ªå£°"></a>æ³›åŒ– ã€æ–¹å·®ã€åå·®å’Œå™ªå£°</h3><p>é¦–å…ˆï¼Œæ³›åŒ–ï¼ˆGeneralizationï¼‰æ˜¯æŒ‡æ¨¡å‹åœ¨ç»è¿‡ä¸€å®šçš„æ•°æ®è®­ç»ƒä¹‹åå¯¹ç°å®æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹èƒ½å¤Ÿæœ€å°åŒ–æµ‹è¯•è¯¯å·®ï¼ˆtesting errorï¼‰ï¼Œè€Œè®­ç»ƒæ•°æ®é›†ä¸Šçš„è¯¯å·®ä¸æµ‹è¯•æ•°æ®é›†ä¸Šçš„è¯¯å·®å°±æ˜¯æ³›åŒ–è¯¯å·®ï¼ˆGeneralization Errorï¼‰ã€‚</p><p>è€Œæ³›åŒ–è¯¯å·®åˆ†ä¸ºæ–¹å·®ï¼ˆVarianceï¼‰ä¸åå·®ï¼ˆBiasï¼‰ï¼Œé€šè¿‡è¿™ä¸¤ä¸ªæ–¹é¢å¯ä»¥æè¿°æ¨¡å‹ä¸ç°å®æ¨¡å‹çš„è¯¯å·®ï¼š</p><ul><li>Biasæ˜¯æ¨¡å‹é¢„æµ‹ä¸çœŸå®ç»“æœçš„å·®è·ï¼Œå¯ä»¥ç›´è§‚ç†è§£ä¸ºè®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰ï¼Œè¡¨ç°äº†æ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ï¼›</li><li>Varianceåˆ™æ˜¯â€œ<strong>ï¼ˆå¤§å°ç›¸åŒçš„ï¼‰ä¸åŒè®­ç»ƒæ•°æ®é›†</strong>è®­ç»ƒå‡ºçš„æ¨¡å‹â€çš„è®­ç»ƒè¯¯å·®ä¹‹é—´çš„å·®å¼‚ï¼Œè¡¨ç°äº†æ•°æ®æ‰°åŠ¨çš„å½±å“ã€‚</li></ul><p>é€šå¸¸æ¥è¯´ï¼Œæ¨¡å‹è¶Šå¤æ‚ï¼ˆç»„æˆæ¨¡å‹çš„å‚æ•°è¶Šå¤šï¼‰ï¼Œæ–¹å·®è¶Šå¤§ï¼Œåå·®è¶Šå°ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹çš„æè¿°èƒ½åŠ›è¶Šå¼ºï¼›æ¨¡å‹è¶Šç®€å•ï¼Œåå·®ä¹Ÿå®¹æ˜“å¤§ï¼Œå¾ˆå¯èƒ½æ— æ³•æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚</p><p>é€šå¸¸æ¨¡å‹å¤æ‚ç¨‹åº¦ä¸æ–¹å·®/åå·®çš„å…³ç³»ï¼š</p><p><img src="/Machine-Learning-01-Overview-2/complex.png" alt></p><p>åœ¨å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œéšç€æ¨¡å‹å˜å¾—å¤æ‚ï¼Œè®­ç»ƒè¯¯å·®/åå·®å˜å°ï¼Œè€Œæ–¹å·®ï¼ˆåœ¨å›¾ä¸­å¯ä»¥çœ‹ä½œæµ‹è¯•è¯¯å·®ä¸è®­ç»ƒè¯¯å·®ä¹‹é—´çš„å·®å€¼ï¼‰å˜å¤§ï¼Œè®­ç»ƒè¯¯å·®åœ¨ä¸­é—´æœ‰ä¸€ä¸ªè¾ƒä½å€¼ã€‚</p><p>ç”±æ­¤å¯å‘æˆ‘ä»¬å¯»æ‰¾ä¸€ä¸ªå¤æ‚åº¦çš„å¹³è¡¡ç‚¹ï¼Œä½¿å¾—æ¨¡å‹å…·æœ‰è¾ƒä½çš„biaså’Œvarianceï¼›è‡³äºnoiseåˆ™æ˜¯æ— æ³•æ”¹å˜çš„ã€‚</p><p>æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¦‚å¿µå«åšå™ªå£°ï¼ˆnoiseï¼‰ï¼šå™ªå£°åœ¨å½“å‰ä»»åŠ¡ä¸Šä»»ä½•å­¦ä¹ ç®—æ³•æ‰€èƒ½è¾¾åˆ°çš„æœŸæœ›æ³›åŒ–è¯¯å·®çš„ä¸‹ç•Œï¼Œå³åˆ»ç”»äº†å­¦ä¹ é—®é¢˜æœ¬èº«çš„éš¾åº¦ã€‚</p><p>æ¨¡å‹çš„è¯¯å·®ä¸»è¦æ¥è‡ªä¸‰éƒ¨åˆ†çš„æ€»å’Œã€‚</p><h3 id="è¿‡æ‹Ÿåˆ-æ¬ æ‹Ÿåˆ"><a href="#è¿‡æ‹Ÿåˆ-æ¬ æ‹Ÿåˆ" class="headerlink" title="è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ"></a>è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ</h3><ul><li>æ¬ æ‹Ÿåˆä¸»è¦æè¿°çš„æ˜¯æ¨¡å‹å¤æ‚åº¦è¿‡ä½ï¼Œéš¾ä»¥æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œæ­¤æ—¶åå·®è¿‡å¤§ï¼ˆä¸Šå›¾å·¦ä¾§éƒ¨åˆ†ï¼‰</li><li>è¿‡æ‹Ÿåˆæ˜¯æŒ‡æ¨¡å‹è¿‡äºå¤æ‚ï¼Œè™½ç„¶åœ¨è®­ç»ƒæ•°æ®ä¸Šèƒ½å¤Ÿè¾ƒå¥½æ‹Ÿåˆï¼Œä½†æ˜¯åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯¯å·®æå¤§ï¼Œæ­¤æ—¶åå·®è¾ƒå°è€Œè¯¯å·®è¾ƒå¤§ï¼ˆä¸Šå›¾å³ä¾§éƒ¨åˆ†ï¼‰</li></ul><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæµ‹è¯•è¯¯å·®è¾ƒå¤§ä¸èƒ½è¯´æ˜æ˜¯è¿‡æ‹Ÿåˆè¿˜æ˜¯æ¬ æ‹Ÿåˆï¼›éœ€è¦çœ‹è®­ç»ƒè¯¯å·®çš„å¤§å°ä»¥åŒºåˆ†ã€‚</p><h2 id="åˆ†ç±»"><a href="#åˆ†ç±»" class="headerlink" title="åˆ†ç±»"></a>åˆ†ç±»</h2><h3 id="æ··æ·†çŸ©é˜µä¸é£é™©çŸ©é˜µ"><a href="#æ··æ·†çŸ©é˜µä¸é£é™©çŸ©é˜µ" class="headerlink" title="æ··æ·†çŸ©é˜µä¸é£é™©çŸ©é˜µ"></a>æ··æ·†çŸ©é˜µä¸é£é™©çŸ©é˜µ</h3><h4 id="æ··æ·†çŸ©é˜µ"><a href="#æ··æ·†çŸ©é˜µ" class="headerlink" title="æ··æ·†çŸ©é˜µ"></a>æ··æ·†çŸ©é˜µ</h4><p>ä¸€å¼ å›¾è¯´æ˜æ··æ·†çŸ©é˜µï¼š</p><p><img src="/Machine-Learning-01-Overview-2/confuse.jpg" alt></p><p>æ··æ·†çŸ©é˜µç”¨äºé¢„æµ‹ä¸å®é™…çš„å·®è·ï¼Œå¯¹ä¸€ä¸ªNå…ƒåˆ†ç±»å™¨è€Œè¨€æ˜¯ä¸€ä¸ªN*Nçš„çŸ©é˜µï¼Œ$M[i][j]$è¡¨ç¤ºäº†é¢„æµ‹ç±»ä¸º$i$ï¼ŒçœŸå®ç±»ä¸º$j$çš„æ ·æœ¬æ•°ã€‚æ˜¾ç„¶ï¼Œæ­£ç¡®çš„åˆ†ç±»è½åœ¨çŸ©é˜µçš„ä¸»å¯¹è§’çº¿ä¸Šï¼Œå³æ‰€æœ‰çš„$M[i][i]$å…ƒç´ ã€‚è€Œå…¶ä»–é¡¹è¡¨ç¤ºäº†åˆ†ç±»é”™è¯¯çš„ä¸ªæ•°ã€‚</p><p>å½“ç„¶ä¹Ÿæœ‰</p><p>å¯¹äºäºŒåˆ†ç±»è€Œè¨€ï¼Œæˆ‘ä»¬ä¼šæŠŠæŸä¸€ä¸ªç±»å«åšæ­£ç±»ï¼Œå¦ä¸€ä¸ªç±»å«åšè´Ÿç±»ï¼Œé¢„è®¡æŸä¸ªç±»ä¸ºæ­£ç±»å«åšé˜³æ€§ï¼Œåä¹‹å«é˜´æ€§ï¼Œæ‰€ä»¥åˆäº§ç”Ÿäº†å¦‚ä¸‹æ¦‚å¿µï¼š</p><ul><li>é¢„æµ‹å’ŒçœŸå®å‡ä¸ºæ­£ç±»çš„å«åš<strong>çœŸé˜³æ€§</strong>ï¼ˆTPï¼ŒTrue Positiveï¼‰</li><li>é¢„æµ‹ä¸çœŸå®å‡ä¸ºè´Ÿç±»çš„å«åš<strong>çœŸé˜´æ€§</strong>ï¼ˆTFï¼ŒTrue Negativeï¼‰</li><li>é¢„æµ‹ä¸ºæ­£ç±»è€ŒçœŸå®ä¸ºè´Ÿç±»çš„å«åš<strong>å‡é˜³æ€§</strong>ï¼ˆFPï¼ŒFalse Positiveï¼‰</li><li>é¢„æµ‹ä¸ºè´Ÿç±»è€ŒçœŸå®ä¸ºæ­£ç±»çš„å«åš<strong>å‡é˜´æ€§</strong>ï¼ˆFNï¼ŒFalse Negativeï¼‰</li></ul><p>ç¨åŠ æ‹“å±•ï¼Œå½“åº”ç”¨åœ¨å¤šåˆ†ç±»ä¸Šï¼Œå°±æ˜¯æŠŠåˆ†ç±»é”™è¯¯ç»Ÿç§°ä¸ºè´Ÿç±»ï¼Œåˆ†ç±»æ­£ç¡®çš„å½“åšæ­£ç±»ã€‚</p><p>ç”±æ­¤å‡ºå‘ï¼Œæˆ‘ä»¬å¾—åˆ°æ–°çš„æ¦‚å¿µä½œä¸ºè¯„ä»·æŒ‡æ ‡ï¼š</p><ul><li><strong>å‡†ç¡®ç‡</strong>ï¼ˆAccuracyï¼‰ï¼š$Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$</li><li><strong>ç²¾ç¡®ç‡</strong>ï¼ˆPrecisionï¼‰ï¼š$Precision=\frac{TP}{TP+FP}$</li><li><strong>å¬å›ç‡</strong>ï¼ˆRecallï¼‰ï¼š$Recall=\frac{TP}{TP+FN}$</li></ul><p>è¿™äº›æ¦‚å¿µå®¹æ˜“ææ··ï¼Œå¦å¤–ä¸æœç´¢å¼•æ“çš„è¯„ä¼°ä¹Ÿæœ‰ä¸€å®šå…³è”ã€‚</p><p>é‚£ä¹ˆè¿™ä¸‰ä¸ªåˆ†ç±»æ ‡å‡†åˆ†åˆ«æœ‰ä»€ä¹ˆç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ï¼Ÿ</p><p>æˆ‘ä»¬ä»¥æ£€æµ‹ç–¾ç—…çš„åˆ†ç±»å™¨ä¸ºä¾‹è¯´æ˜ï¼š</p><ol><li>Accuracyä¸åˆ†ç±»ç›®æ ‡æ— å…³ï¼Œå®é™…åªçœ‹åˆ†å¯¹äº†æ²¡æœ‰ï¼›åœ¨ç±»åˆ«ä¸å‡è¡¡çš„é—®é¢˜ä¸Šè¯„ä¼°ç²’åº¦å¤ªå¤§ï¼Œä¸å¦‚åä¸¤ç§æ‰‹æ®µæœ‰æ•ˆã€‚å› æ­¤ï¼Œåœ¨æ²¡æœ‰ç‰¹å®šè¦æ±‚æŸä¸ªç±»çš„å‡†ç¡®ç‡è€Œæ˜¯å…³æ³¨æ•´ä½“å‡†ç¡®ç‡çš„æ—¶å€™ï¼Œä½¿ç”¨è¿™ä¸€æŒ‡æ ‡ã€‚</li><li>Precisionæ˜¯æŒ‡åˆ†ç±»å™¨æ‰€æŒ‘å‡ºçš„æŸä¸ªç±»ä¸­ï¼ŒçœŸæ­£æ˜¯æˆ‘ä»¬å¸Œæœ›çš„é‚£ä¸€ç±»çš„æ¦‚ç‡ã€‚ä½¿ç”¨è¿™ä¸ªä¸ºæŒ‡æ ‡å°±æ˜¯æœŸå¾…åˆ†ç±»å™¨é™ä½æŠŠæ²¡ç—…çš„äººå½“ä½œæœ‰ç—…çš„æ¦‚ç‡ã€‚</li><li>Recallæ˜¯æŒ‡æ²¡æœ‰è¢«è¯†åˆ«å‡ºæ˜¯æˆ‘ä»¬æƒ³è¦çš„é‚£ä¸€ç±»çš„æ¦‚ç‡ã€‚ç®€å•æ¥è¯´å°±æ˜¯ä½¿ç”¨è¿™ä¸ªæŒ‡æ ‡å°±æ˜¯æœŸå¾…åˆ†ç±»å™¨ä¸è¦é”™æ”¾è¿‡æœ‰ç—…çš„äººã€‚</li></ol><h4 id="é£é™©çŸ©é˜µ"><a href="#é£é™©çŸ©é˜µ" class="headerlink" title="é£é™©çŸ©é˜µ"></a>é£é™©çŸ©é˜µ</h4><p>ç”Ÿæ´»ç»éªŒä¸­ï¼ŒåŒæ ·æ˜¯åˆ†ç±»é”™è¯¯ï¼Œæˆ‘ä»¬å¯¹äºä¸åŒé”™è¯¯åˆ†ç±»çš„å®¹å¿åº¦å¾€å¾€æ˜¯ä¸åŒçš„ï¼Œæ¯”å¦‚ï¼š</p><ul><li>åƒåœ¾é‚®ä»¶åˆ†ç±»é—®é¢˜ä¸­ï¼Œç›¸æ¯”é‡è¦é‚®ä»¶è¢«é”™è¯¯åˆ†ç±»ä¸ºåƒåœ¾é‚®ä»¶è€Œè¿›å…¥åƒåœ¾ç®±ï¼Œæˆ‘ä»¬æ›´æƒ…æ„¿å¤šæ”¶åˆ°ä¸€äº›è¢«å½“ä½œæ­£å¸¸é‚®ä»¶çš„åƒåœ¾é‚®ä»¶ã€‚<ul><li>åœ¨è¿™é‡Œå¦‚æœæ­£ç±»æ˜¯åƒåœ¾é‚®ä»¶ï¼Œé‚£ä¹ˆæˆ‘ä»¬å…³æ³¨Precisionå¤šäºRecallï¼›åè¿‡æ¥å¦‚æœæ­£å¸¸é‚®ä»¶æ˜¯æ­£ç±»ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ›´åŠ å…³æ³¨Recallã€‚</li></ul></li><li>å½“åˆ¤å†³æŸä¸ªç»†èƒæ˜¯æ­£å¸¸ç»†èƒè¿˜æ˜¯ç™Œç»†èƒçš„æ—¶å€™ï¼Œæ˜¾ç„¶æŠŠä¸€ä¸ªæ­£å¸¸ç»†èƒé”™åˆ¤ä¸ºç™Œç»†èƒçš„é£é™©è¦æ¯”æŠŠä¸€ä¸ªç™Œç»†èƒé”™åˆ¤ä¸ºæ­£å¸¸ç»†èƒçš„é£é™©å¤§å¾ˆå¤šï¼Œåè€…çš„é”™è¯¯æ˜¯è‡´å‘½çš„ã€‚<ul><li>å¦‚æœæˆ‘ä»¬çš„æ­£ç±»æ˜¯ç™Œç»†èƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å…³æ³¨Recallå¤šäºPrecisionï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›æ”¾è¿‡æ¯ä¸€ä¸ªæ­£ç±»ã€‚</li></ul></li></ul><p>åœ¨è¿™äº›æƒ…å½¢ä¸‹ï¼ŒåŒæ ·éƒ½æ˜¯åˆ†ç±»é”™è¯¯ï¼ŒæŸä¸€ç§åˆ†ç±»é”™è¯¯çš„å½±å“æ›´ä¸¥é‡ï¼Œæ‰€ä»¥å¹¶ä¸æ˜¯æœ€å°é”™è¯¯ç‡ï¼ˆMinimum Probability Errorï¼‰è€Œæ˜¯æœ€å°é£é™©è¯¯å·®ï¼ˆMinimum Riskï¼‰æ‰èƒ½å¤Ÿè¡¨ç¤ºæˆ‘ä»¬çš„æœŸå¾…ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬ä¼šæŠŠåˆ†ç±»é”™è¯¯æ·»åŠ ä¸€ä¸ªæƒé‡ï¼Œä½¿ç”¨æƒé‡æ¥æ”¹å˜è¯„åˆ¤æ ‡å‡†ã€‚</p><p>é£é™©ï¼ˆRiskï¼‰ï¼Œå¯ä»¥ç†è§£ä¸ºå¯¹æŸç§é”™è¯¯åˆ†ç±»æƒ…å½¢ä¸‹é€ æˆåæœçš„ä¸¥é‡ç¨‹åº¦ï¼Œå½¢çŠ¶å’Œæ··æ·†çŸ©é˜µä¸€è‡´ï¼Œæ˜¯äººä¸ºæ·»åŠ çš„åŠå®šé‡çŸ©é˜µã€‚</p><p>æˆ‘ä»¬å°†é£é™©çŸ©é˜µä¸æ··æ·†çŸ©é˜µå¯¹åº”ä½ç½®å…ƒç´ ç›¸ä¹˜å¾—åˆ°çš„æ€»å’Œå°±æ˜¯æ–°çš„ç›®æ ‡å‡½æ•°å€¼ï¼Œæˆ‘ä»¬çš„åˆ†ç±»ç»“æœåº”å½“ä½¿å¾—è¿™ä¸€ç›®æ ‡å‡½æ•°å€¼è¾¾åˆ°æœ€å°ã€‚</p><p>è¿™ä¸€æ”¹å˜å°†å¦‚ä½•å½±å“æˆ‘ä»¬çš„åˆ†ç±»ç­–ç•¥ï¼Ÿ</p><ul><li>å¯¹ä¸€ä¸ªæ ·æœ¬$X_i$ï¼š<ul><li>å¯¹æ¯ä¸€ä¸ªç±»jï¼Œæˆ‘ä»¬è®¡ç®—å‡º$X_i$å±äºjç±»çš„æ¦‚ç‡åˆ†åˆ«ä¸º$P(w_j|X_i)$ï¼Œå¹¶è®¡ç®—jç±»çš„è¯¯åˆ†ç±»é£é™©ä¹‹å’Œï¼š$\Sigma_{i!=j}M[j][i]$</li><li>å°†ç±»çš„è¯¯åˆ†ç±»é£é™©ä¸æ¦‚ç‡ç›¸ä¹˜ï¼Œä¹˜ç§¯å°±æ˜¯jç±»è¯¯åˆ†ç±»çš„æ¦‚ç‡é£é™©</li><li>å°†æ¯ä¸€ä¸ªç±»çš„è¯¯åˆ†ç±»æ¦‚ç‡é£é™©æ±‚å‡ºï¼Œæ‰¾åˆ°æ¦‚ç‡é£é™©æœ€å°çš„é‚£ä¸€ä¸ªåˆ†ç±»ä½œä¸ºå½“å‰çš„åˆ†ç±»</li></ul></li></ul><p>æŒ‰ç…§è¿™ä¸€æ–¹æ³•åˆ†ç±»è®¡ç®—å¾—åˆ°çš„è¯¯åˆ†ç±»æ¦‚ç‡é£é™©æ˜¯æœ€å°çš„ã€‚</p><h3 id="ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»"><a href="#ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»" class="headerlink" title="ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»"></a>ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»</h3><p>å¸¸è§çš„åˆ†ç±»å™¨å¦‚æ”¯æŒå‘é‡æœºã€æ„ŸçŸ¥æœºåªèƒ½åšåˆ°äºŒåˆ†ç±»ï¼Œé‚£ä¹ˆå¤šåˆ†ç±»é—®é¢˜åº”è¯¥å¦‚ä½•è§£å†³ï¼Ÿ</p><p>ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç§æ€è·¯ï¼š</p><h4 id="Ont-versus-Oneï¼šä¸€å¯¹ä¸€"><a href="#Ont-versus-Oneï¼šä¸€å¯¹ä¸€" class="headerlink" title="Ont-versus-Oneï¼šä¸€å¯¹ä¸€"></a>Ont-versus-Oneï¼šä¸€å¯¹ä¸€</h4><p>å¯¹æ¯ä¸€ç»„ä¸åŒçš„ç±»$j_1,j_2$ï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ªäºŒåˆ†ç±»å™¨ï¼›</p><p>ç„¶åï¼Œå¯¹æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œè®¡ç®—æ‰€æœ‰åˆ†ç±»å™¨ï¼Œå¯¹æ¯ä¸€ä¸ªç±»è¿›è¡ŒæŠ•ç¥¨ã€‚</p><h4 id="One-versus-Restï¼šä¸€å¯¹å…¶ä½™"><a href="#One-versus-Restï¼šä¸€å¯¹å…¶ä½™" class="headerlink" title="One-versus-Restï¼šä¸€å¯¹å…¶ä½™"></a>One-versus-Restï¼šä¸€å¯¹å…¶ä½™</h4><p>å¯¹æ¯ä¸€ä¸ªç±»$j$ï¼Œæ„é€ ä¸€ä¸ªäºŒåˆ†ç±»å™¨ï¼ŒåŒºåˆ†çš„ç±»æ˜¯ç¬¬jç±»å’Œæ‰€æœ‰çš„å…¶ä»–ç±»ï¼›</p><p>ç„¶åï¼Œå¯¹æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œè®¡ç®—æ‰€æœ‰åˆ†ç±»å™¨ï¼Œæ­¤æ—¶å¦‚æœåªæœ‰ä¸€ä¸ªåˆ†ç±»å™¨é¢„æµ‹ä¸ºæ­£ç±»ï¼Œé‚£ä¹ˆå°±å°†å…¶åˆ†ç±»ä¸ºæ­£ç±»ï¼›å¦åˆ™ï¼Œåœ¨é¢„æµ‹æ­£ç±»çš„ç±»ä¸­æŒ‘é€‰ç½®ä¿¡åº¦æœ€å¤§åˆ†ç±»å™¨å¯¹åº”çš„ç±»ã€‚</p><h4 id="äºŒè€…çš„æ¯”è¾ƒ"><a href="#äºŒè€…çš„æ¯”è¾ƒ" class="headerlink" title="äºŒè€…çš„æ¯”è¾ƒ"></a>äºŒè€…çš„æ¯”è¾ƒ</h4><p>OvOåªéœ€è¦ä¸¤ä¸ªç±»çš„æ ·æœ¬ï¼Œä½†æ˜¯æ¯ä¸ªåˆ†ç±»å™¨éœ€è¦è®­ç»ƒ$k(k-1)/2$ä¸ªåˆ†ç±»å™¨ï¼›</p><p>OvRéœ€è¦kä¸ªåˆ†ç±»å™¨ï¼Œä½†æ˜¯æ¯ä¸ªåˆ†ç±»å™¨éœ€è¦è®­ç»ƒå…¨éƒ¨æ ·æœ¬ã€‚</p><p>ç»¼åˆæ¥çœ‹ï¼ŒOvOè®­ç»ƒçš„æ—¶é—´å¼€é”€è¾ƒå°ï¼ŒOvRçš„å­˜å‚¨å¼€é”€è¾ƒå°ã€‚</p><h4 id="Multi-versus-Multiï¼šå¤šå¯¹å¤š"><a href="#Multi-versus-Multiï¼šå¤šå¯¹å¤š" class="headerlink" title="Multi-versus-Multiï¼šå¤šå¯¹å¤š"></a>Multi-versus-Multiï¼šå¤šå¯¹å¤š</h4><p>æ¯æ¬¡é€‰å–ç‰¹å®šçš„å¤šä¸ªç±»ä½œä¸ºæ­£ç±»ï¼Œç‰¹å®šçš„å¤šä¸ªç±»ä½œä¸ºè´Ÿç±»è¿›è¡Œåˆ†ç±»ï¼Œä»è€Œç¡®å®šæ‰€å±çš„ç±»åŒºé—´ã€‚</p><p>è¿™é‡Œé€‰å–çš„ç±»ä¸èƒ½éšæ„é€‰å–ï¼Œä¸»è¦æœ‰çº é”™è¾“å‡ºç æŠ€æœ¯ï¼ˆError-Correcting Output Codesï¼ŒECOCï¼‰ï¼Œåœ¨æ­¤ä¸åšå±•å¼€ ï¼Œæœ‰å…´è¶£å¯ä»¥å‚è€ƒï¼š<a href="https://hyper.ai/wiki/4350">https://hyper.ai/wiki/4350</a></p><p>è¿™ä¸ªæ¨å¹¿å¯¹å…¶å®ƒäºŒåˆ†ç±»åˆ†ç±»å™¨ä¹Ÿé€‚ç”¨ã€‚</p><h3 id="ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"><a href="#ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜" class="headerlink" title="ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜"></a>ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜</h3><p>ç±»åˆ«ä¸å¹³è¡¡ï¼ˆclass imbalanceï¼‰ï¼Œåˆç§°ä¸ºæ•°æ®åæ–œï¼ˆclass skewï¼‰ã€‚</p><p>ä»¥äºŒåˆ†ç±»é—®é¢˜ä¸ºä¾‹ï¼Œè¯¥é—®é¢˜ä¸€èˆ¬æŒ‡çš„æ˜¯è®­ç»ƒé›†ä¸­æ­£è´Ÿæ ·æœ¬æ•°æ¯”ä¾‹ç›¸å·®è¿‡å¤§ï¼Œä¸€èˆ¬ä¼šé€ æˆï¼š</p><ol><li><p>ç±»åˆ«å°‘çš„è¯¯åˆ¤æƒ©ç½šè¿‡ä½ï¼Œå¯¼è‡´æœ‰æ‰€åè¢’ï¼Œå½“æ ·æœ¬ä¸ç¡®å®šæ—¶å€¾å‘äºæŠŠæ ·æœ¬åˆ†ç±»ä¸ºå¤šæ•°ç±»ã€‚</p></li><li><p>æ ·æœ¬æ•°é‡åˆ†å¸ƒå¾ˆä¸å¹³è¡¡æ—¶ï¼Œç‰¹å¾çš„åˆ†å¸ƒåŒæ ·ä¼šä¸å¹³è¡¡ã€‚</p></li><li><p>ä¼ ç»Ÿçš„è¯„ä»·æŒ‡æ ‡å˜å¾—ä¸å¯é ï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€‚</p></li></ol><p>è€Œåœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­ï¼Œå°½ç®¡åŸå§‹è®­ç»ƒé›†ä¸­å¯èƒ½ä¸åŒç±»åˆ«è®­ç»ƒæ ·æœ¬æ•°ç›®ç›¸å½“ï¼Œé€šè¿‡OvRã€MvMè¿›è¡Œæ‹†åˆ†æ—¶ä¹Ÿæœ‰å¯èƒ½ä¼šé€ æˆä¸Šè¿°æƒ…å†µï¼Œæ‰€ä»¥ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜äºŸå¾…è§£å†³ã€‚</p><p>å¸¸è§çš„è§£å†³æ–¹æ¡ˆæœ‰ï¼š</p><ul><li>å¯¹è¾ƒå¤šçš„é‚£ä¸ªç±»åˆ«è¿›è¡Œæ¬ é‡‡æ ·(under-sampling)ï¼Œèˆå¼ƒä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½¿å…¶ä¸è¾ƒå°‘ç±»åˆ«çš„æ•°æ®ç›¸å½“ã€‚</li><li>å¯¹è¾ƒå°‘çš„ç±»åˆ«è¿›è¡Œè¿‡é‡‡æ ·(over-sampling)ï¼Œé‡å¤ä½¿ç”¨ä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½¿å…¶ä¸è¾ƒå¤šç±»åˆ«çš„æ•°æ®ç›¸å½“ã€‚</li><li>é˜ˆå€¼è°ƒæ•´ï¼ˆthreshold movingï¼‰ï¼Œå°†åŸæœ¬é»˜è®¤ä¸º0.5çš„é˜ˆå€¼è°ƒæ•´åˆ° è¾ƒå°‘ç±»åˆ«/ï¼ˆè¾ƒå°‘ç±»åˆ«+è¾ƒå¤šç±»åˆ«ï¼‰å³å¯ã€‚</li></ul><h2 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h2><h3 id="äº¤å‰éªŒè¯"><a href="#äº¤å‰éªŒè¯" class="headerlink" title="äº¤å‰éªŒè¯"></a>äº¤å‰éªŒè¯</h3><p>äº¤å‰éªŒè¯ï¼ˆCross Validationï¼‰æ˜¯ä¸€ç§é¿å…è¿‡æ‹Ÿåˆçš„è®­ç»ƒæŠ€å·§ã€‚</p><p>å…·ä½“æ€è·¯åœ¨äºå°†è®­ç»ƒåˆ‡åˆ†ï¼Œæ¯ä¸€æ¬¡ç”¨ä¸åŒçš„æ•°æ®é›†æ¥è®­ç»ƒï¼Œä¼˜åŒ–å¹³å‡çš„è¯¯å·®ï¼Œä»è€Œé™ä½ä¸åŒæ•°æ®é›†å¸¦æ¥æ¨¡å‹æ€§èƒ½çš„å˜åŒ–ï¼Œè¾¾åˆ°é™ä½æ–¹å·®çš„ç›®çš„ã€‚</p><p>ä¸»è¦æœ‰ä¸¤ç§æ–¹æ³•ï¼š</p><ul><li>KæŠ˜éªŒè¯ï¼ˆK-Foldï¼‰ï¼šæŒ‡å°†æ•°æ®åˆ‡åˆ†ä¸ºKä»½ï¼Œæ¯ä¸€ä»½è½®æµä½œä¸ºéªŒè¯é›†ï¼ˆValidation Setï¼‰ï¼Œå…¶ä»–æ•°æ®ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œè®­ç»ƒKè½®æ¬¡è·å¾—è®­ç»ƒè¯¯å·®ã€‚</li><li>ç•™ä¸€éªŒè¯ï¼ˆLeave-One-Outï¼‰ï¼šæ˜¯K=nçš„KæŠ˜éªŒè¯ï¼Œé€šè¿‡æ¯æ¬¡å–ä¸€ä¸ªæ ·æœ¬ä½œä¸ºéªŒè¯é›†è¿›è¡Œäº¤å‰éªŒè¯è®­ç»ƒã€‚</li></ul><h3 id="æ¢¯åº¦ä¸‹é™"><a href="#æ¢¯åº¦ä¸‹é™" class="headerlink" title="æ¢¯åº¦ä¸‹é™"></a>æ¢¯åº¦ä¸‹é™</h3><p>æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰æ˜¯åœ¨é€šå¸¸æ¨¡å‹ä¸­é€šç”¨çš„è¿­ä»£å‹å‚æ•°ä¼°è®¡æ–¹æ³•ã€‚</p><p>æˆ‘ä»¬å¯ä»¥è®¤ä¸ºï¼Œç›®æ ‡å‡½æ•°æ˜¯ä¸€ä¸ªè‡ªå˜é‡ä¸ºæ¨¡å‹å‚æ•°çš„å‡½æ•°ï¼Œè€Œæˆ‘ä»¬å¸Œæœ›è¾¾åˆ°å®ƒçš„æœ€å¤§/æœ€å°å€¼ã€‚</p><p>æˆ‘ä»¬çŸ¥é“ï¼Œä¸€ä¸ªå‡½æ•°åœ¨æœ€å¤§æˆ–è€…æœ€å°å€¼çš„ä½ç½®ï¼Œå®ƒçš„ä¸€é˜¶æ¢¯åº¦ä¸ºå…¨0çš„å‘é‡ã€‚è‡³äºå®ƒç©¶ç«Ÿæ˜¯æœ€å¤§å€¼è¿˜æ˜¯æœ€å°å€¼ï¼Œå¾—çœ‹å…¶äºŒé˜¶å¯¼æ•°ï¼Œæˆ–è€…è¿›è¡Œæµ‹è¯•å±€éƒ¨å˜åŒ–æ¥éªŒè¯ã€‚</p><p>å½“ç„¶ï¼Œé€šå¸¸æˆ‘ä»¬ä¼šå¸Œæœ›ç›®æ ‡å‡½æ•°æ˜¯çº¯å‡¸/çº¯å‡¹çš„ï¼Œå› ä¸ºè¿™æ ·å®ƒçš„é©»ç‚¹ï¼ˆæå¤§æå°å€¼ç‚¹ï¼‰åªæœ‰ä¸€ä¸ªï¼Œä¸€æ—¦æ‰¾åˆ°æå€¼ç‚¹å°±èƒ½å¤Ÿç¡®å®šå®ƒæ˜¯æœ€ä¼˜çš„ã€‚åœ¨è¿™ä¸€ç†è®ºçš„é©±åŠ¨ä¸‹ï¼Œè¯ç”Ÿäº†å‡¸ä¼˜åŒ–è¿™ä¸€å­¦ç§‘ï¼Œç›®æ ‡å°±æ˜¯æŠŠå„ç§éå‡¸é—®é¢˜è½¬åŒ–æˆå‡¸çš„é—®é¢˜ã€‚</p><p>å› æ­¤æˆ‘ä»¬ä¼šå¯¹å®ƒè¿›è¡Œæ±‚å¯¼ï¼Œå¯»æ‰¾ä¸€é˜¶å¯¼æ•°ä¸º0çš„ç‚¹å¯¹åº”çš„è‡ªå˜é‡ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹å‚æ•°çš„å€¼ã€‚</p><p>æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åˆ©ç”¨ç­‰å¼çš„æ¢¯åº¦ä¸º0æ±‚è§£å‡ºå‚æ•°ï¼Œä¹Ÿå¯ä»¥é‡‡ç”¨è¿­ä»£æ±‚è§£çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•ã€‚</p><p>å‰è€…çœ‹èµ·æ¥ä¸æ˜¯æ›´ç›´æ¥è€Œä¸”ç²¾ç¡®å˜›ï¼Ÿä½†æ˜¯äº‹å®ä¸Šæˆ‘ä»¬å¤§å¤šé‡‡ç”¨çš„æ˜¯åè€…ã€‚ç†ç”±å°±æ˜¯ï¼Œç¬¬ä¸€ä¸ªæ–¹æ³•çš„å®è´¨æ˜¯è®¡ç®—æ–¹ç¨‹ç»„çš„è§£ï¼Œæ¶‰åŠæ±‚é€†çŸ©é˜µçš„è¿‡ç¨‹ï¼Œä½†æ˜¯ä¸€æ¥è®¡ç®—é‡å¤§ï¼ŒäºŒæ¥éš¾ä»¥ä¿è¯çŸ©é˜µéå¥‡å¼‚æˆ–è€…éç—…æ€çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—è¿‡ç¨‹å¯¹æ–¹ç¨‹ç»„å€¼çš„æ‰°åŠ¨éå¸¸æ•æ„Ÿï¼Œå™ªå£°å¸¦æ¥çš„è¯¯å·®è¾ƒå¤§å¯¼è‡´ç»“æœåç¦»ç†è®ºè§£ã€‚</p><p>é‚£ä¹ˆï¼Œåè€…æ˜¯å¦‚ä½•æ“ä½œçš„ï¼Ÿ</p><p>åœ¨æ¯æ¬¡è®­ç»ƒæ—¶ï¼Œå‡å»æ¢¯åº¦å€¼å’Œå­¦ä¹ ç‡çš„ä¹˜ç§¯ã€‚å¯¹äºä¸€ä¸ªå±€éƒ¨å‡¸çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨å‡å»æ¢¯åº¦ä¹‹åæˆ‘ä»¬çš„å‚æ•°åæ ‡ä¼šå‘æå€¼ç‚¹ï¼ˆæœ€ä½ç‚¹ï¼‰é è¿‘ï¼Œä¸”æ¢¯åº¦ç»å¯¹å€¼è¶Šå¤§ï¼Œä¸‹é™è¶Šå¿«ã€‚</p><p>ç†è®ºä¾æ®ï¼šæ¢¯åº¦çš„åæ–¹å‘å°±æ˜¯å‡½æ•°å±€éƒ¨å€¼ä¸‹é™æœ€å¿«çš„æ–¹å‘ã€‚</p><p><img src="/Machine-Learning-01-Overview-2/gradient.png" alt></p><p>ä¸ºäº†å¿«é€Ÿæ”¶æ•›ã€é¿å…éœ‡è¡çš„ç›®çš„ï¼Œä¹Ÿå‡ºç°äº†å¾ˆå¤šå­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚è‡ªé€‚åº”æ€§ä¼˜åŒ–ï¼ˆAdamï¼‰ã€Adagradå’Œéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ã€Momentumç­‰ç­–ç•¥ï¼Œè¿™ä¸€å—æš‚æ—¶ä¸åšä»‹ç»ã€‚</p><h3 id="æ‰¹é‡æ¢¯åº¦ä¸‹é™-éšæœºæ¢¯åº¦ä¸‹é™"><a href="#æ‰¹é‡æ¢¯åº¦ä¸‹é™-éšæœºæ¢¯åº¦ä¸‹é™" class="headerlink" title="æ‰¹é‡æ¢¯åº¦ä¸‹é™/éšæœºæ¢¯åº¦ä¸‹é™"></a>æ‰¹é‡æ¢¯åº¦ä¸‹é™/éšæœºæ¢¯åº¦ä¸‹é™</h3><p>è¿™æ˜¯æ¢¯åº¦ä¸‹é™çš„ä¸¤ç§æ“ä½œæ–¹å¼ã€‚</p><ul><li>éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descentï¼‰æ˜¯æŒ‡ï¼Œå¯¹æ¯ä¸€ä¸ªè®­ç»ƒçš„æ ·æœ¬éƒ½è®¡ç®—ä¸€æ¬¡æ¢¯åº¦å¹¶ä¸”ç”¨æ¢¯åº¦æ‰§è¡Œæ›´æ–°å‚æ•°çš„æ“ä½œã€‚è¿™ç§æ–¹æ³•çš„å¥½å¤„æ˜¯æ›´æ–°æ¬¡æ•°å¿«ï¼Œä¸”å­˜åœ¨ä¸€å®šçš„éšæœºæ€§ä¸ä¼šé™·å…¥å±€éƒ¨æå°å€¼ï¼›ä½†æ˜¯ä¹Ÿå› ä¸ºéšæœºæ€§å¼ºï¼Œå¾€å¾€æ¢¯åº¦çš„æ³¢åŠ¨å¤§ï¼ŒæŸä¸€ä¸¤ä¸ªæ ·æœ¬å¸¦æ¥çš„å‚æ•°å˜åŒ–å¤ªå¤§ï¼Œæ›´æ–°ä¸ç¨³å®šï¼Œç”šè‡³å¯¼è‡´ä¸æ”¶æ•› ã€‚</li><li>æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆBatch Gradient Descentï¼‰æ˜¯æŒ‡ï¼Œæ¯æ¬¡å¯¹æ‰€æœ‰è®­ç»ƒæ ·æœ¬è¿›è¡Œè®¡ç®—æ¢¯åº¦å¹¶ä¸”åªç”¨æ‰€æœ‰æ¢¯åº¦çš„å¹³å‡å€¼è¿›è¡Œä¸€æ¬¡æ›´æ–°ã€‚è¿™ç§æ–¹æ³•çš„å¥½å¤„è‡ªç„¶å°±æ˜¯ç¨³å®šæ›´æ–°ï¼›ä½†æ˜¯å…¶æ›´æ–°å¤ªæ…¢ï¼Œåœ¨ä¸€å®šçš„æ—¶é—´é‡Œéš¾ä»¥è¾¾åˆ°æ”¶æ•›ï¼Œè€Œä¸”ä¹Ÿå®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°å€¼ï¼Œæœ€ç»ˆåœ¨è¾ƒå°çš„æ¢¯åº¦ä¸‹åœæ­¢æ›´æ–°ã€‚</li></ul><p>ä¸€èˆ¬æ¥è¯´ç°æœ‰çš„æŠ€å·§åœ¨äºæŠ˜è¡·ä¸¤ç§æ–¹æ¡ˆï¼Œè¿›è¡Œå°æ‰¹é‡çš„æ¢¯åº¦ä¸‹é™ï¼Œå¹¶ä¸”æ‰“ä¹±æ ·æœ¬ä»¥è·å–éšæœºæ€§ã€‚</p><p>è¿™æ ·åšçš„å¥½å¤„åœ¨äºï¼š</p><ol><li>åˆ©ç”¨äº†éšæœºæ¢¯åº¦ä¸‹é™çš„éšæœºæ€§ï¼Œä¸€èˆ¬ä¸ä¼šé™·å…¥å±€éƒ¨æå°å€¼ã€‚</li><li>æ›´æ–°é€Ÿåº¦é€‚ä¸­ï¼Œä¿æŒè¾ƒå¥½çš„ç¨³å®šæ€§ä¸ä¼šéœ‡è¡ï¼ŒåŒæ—¶ä¹Ÿèƒ½å¤Ÿè¾ƒå¿«è¾¾åˆ°æ”¶æ•›ã€‚</li><li>æœ€é‡è¦çš„æ˜¯ï¼Œæ–¹ä¾¿åº•å±‚GPUä¼˜åŒ–ã€‚å› ä¸ºæ¢¯åº¦è®¡ç®—çš„åº•å±‚æ“ä½œæ˜¯çŸ©é˜µè¿ç®—ï¼Œè€ŒGPUç”±äºå¤šæ ¸è®¡ç®—èƒ½å¤Ÿå¹¶è¡Œåœ°è®¡ç®—æŸä¸€è¡Œçš„è®¡ç®—ç»“æœï¼Œä»è€ŒåŠ é€Ÿæ¢¯åº¦æ›´æ–°è¿‡ç¨‹ã€‚æ‰€ä»¥ä¸€èˆ¬è€Œè¨€ï¼Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™çš„æ•ˆç‡æ¯”éšæœºæ¢¯åº¦ä¸‹é™æ›´é«˜ã€‚</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¸‹åŠéƒ¨åˆ†ï¼Œå†…å®¹åŒ…å«äº†æœºå™¨å­¦ä¹ çš„æ¦‚å¿µè§£é‡Šã€‚&lt;/p&gt;
&lt;p&gt;å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼š&lt;a href=&quot;https://github.com/Riroaki/LemonML/&quot;&gt;https://github.com/Riroaki/LemonML/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ¬¢è¿starã€forkå’Œpr
        
      
    
    </summary>
    
      <category term="æœºå™¨å­¦ä¸åŠ¨äº†" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Restart</title>
    <link href="http://riroaki.github.io/Restart/"/>
    <id>http://riroaki.github.io/Restart/</id>
    <published>2019-05-28T01:52:55.000Z</published>
    <updated>2019-06-02T14:33:47.956Z</updated>
    
    <content type="html"><![CDATA[<p>ä»Šå¤©æŠŠåšå®¢æ–‡ç« å…¨éƒ½æ¸…ç©ºäº†ã€‚</p><p>ä¸»è¦æ˜¯ä¹‹å‰çš„æ–‡ç« å¤ªä¹±ï¼Œç¼ºä¹æ•´ç†ï¼›åŠ ä¸Šè¿‘æœŸå­¦äº†å¾ˆå¤šä¸œè¥¿ä¹‹åï¼Œå›å¤´çœ‹è¿‡å»çš„å†…å®¹è§‰å¾—æœ‰äº›æµ…è–„ï¼Œå†³å¿ƒä»å¤´å¼€å§‹å†™ã€‚</p><p>ä»Šåä¼šåœ¨è¿™é‡Œå†™ä¸€äº›æœºå™¨å­¦ä¹ ï¼Œä»¥åŠæ•°æ®å¤„ç†çš„ä¸œè¥¿ã€‚</p><p>å½“ç„¶è¿˜æœ‰ä¸€äº›å·¥ç¨‹å‘çš„å†…å®¹ï¼Œæ€»ä¹‹æˆ‘ä¼šæ›´åŠ æ·±æ€ç†Ÿè™‘åœ°æ¨é€æ–‡ç« ã€‚</p><p>ï¼ˆæ˜¯ä¸æ˜¯ä¹Ÿè€ƒè™‘ä¸€ä¸‹æ¢ä¸»é¢˜å‘¢â€¦â€¦å“ˆå“ˆè¿˜æ˜¯ç®—äº†ä¼°è®¡åˆè¦æŒ‘å¾ˆä¹…ï¼‰</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;ä»Šå¤©æŠŠåšå®¢æ–‡ç« å…¨éƒ½æ¸…ç©ºäº†ã€‚&lt;/p&gt;
&lt;p&gt;ä¸»è¦æ˜¯ä¹‹å‰çš„æ–‡ç« å¤ªä¹±ï¼Œç¼ºä¹æ•´ç†ï¼›åŠ ä¸Šè¿‘æœŸå­¦äº†å¾ˆå¤šä¸œè¥¿ä¹‹åï¼Œå›å¤´çœ‹è¿‡å»çš„å†…å®¹è§‰å¾—æœ‰äº›æµ…è–„ï¼Œå†³å¿ƒä»å¤´å¼€å§‹å†™ã€‚&lt;/p&gt;
&lt;p&gt;ä»Šåä¼šåœ¨è¿™é‡Œå†™ä¸€äº›æœºå™¨å­¦ä¹ ï¼Œä»¥åŠæ•°æ®å¤„ç†çš„ä¸œè¥¿ã€‚&lt;/p&gt;
&lt;p&gt;å½“ç„¶è¿˜æœ‰ä¸€äº›å·¥ç¨‹å‘çš„å†…å®¹ï¼Œæ€»ä¹‹æˆ‘ä¼šæ›´åŠ æ·±æ€ç†Ÿè™‘åœ°æ¨é€æ–‡ç« 
        
      
    
    </summary>
    
    
      <category term="Hello, world!" scheme="http://riroaki.github.io/tags/Hello-world/"/>
    
  </entry>
  
</feed>
