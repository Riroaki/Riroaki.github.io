<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Riroaki</title>
  
  <subtitle>Riroaki&#39;s home</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://riroaki.github.io/"/>
  <updated>2019-06-22T16:49:52.282Z</updated>
  <id>http://riroaki.github.io/</id>
  
  <author>
    <name>Riroaki</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学不动了-03：线性回归</title>
    <link href="http://riroaki.github.io/Machine-Learning-02-Linear-Regression/"/>
    <id>http://riroaki.github.io/Machine-Learning-02-Linear-Regression/</id>
    <published>2019-06-22T04:00:00.000Z</published>
    <updated>2019-06-22T16:49:52.282Z</updated>
    
    <content type="html"><![CDATA[<p>本文是”机器学不动了”系列的第三篇文章，内容包含了线性回归的详细理论和简单线性回归的实现。</p><p>全系列推荐结合个人实现的代码食用：<a href="https://github.com/Riroaki/LemonML/，欢迎star、fork与pr。">https://github.com/Riroaki/LemonML/，欢迎star、fork与pr。</a></p><h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>上回讨论了贝叶斯模型，这一模型属于生成模型（Generative Model），基于一定的假设，认为样本是由类按照一定概率模型产生的，然后根据样本学习数据。</p><p>同时我们注意到，在高斯贝叶斯分类器中，如果所有类别共享权重，那么模型就转化为线性的表达式，从而可以使用形如$y=w^Tx+b$的简洁形式建模，直接求出描述分类面的表达式（详见上次附录的证明），这就是判别模型（Discriminant Model）的思路。</p><p>那么接下来我们将深入讨论判别模型，这是直接根据数据学习得到的更加直接的规律。</p><p>线性模型就是一种判别模型，这一次我们讨论它在回归任务上的应用，也就是线性回归。</p><h2 id="线性回归理论"><a href="#线性回归理论" class="headerlink" title="线性回归理论"></a>线性回归理论</h2><p>对$x=[x_1,x_2,x_3,…,x_d]^T\in R^d$，线性函数的形式为$y=w^Tx+b$，其中$w=[w_1, w_2,…, w_d]\in R^d$，$b\in R$。</p><p>这一表达式还有一种表述，那就是将$b$这一项加入$w$中，变成：</p><p>$x=[x_1,x_2,…,x_d,1]^T\in R^{d+1},w=[w_1,w_2,…,w_d,b]^T\in R^{d+1}$</p><p>简单的模型蕴含着不可小视的力量。<strong>任意模型的表达式都可以转化为线性组合，故也可以转化为线性模型。</strong></p><p>比如，多项式可以转化为线性组合的形式：</p><p>$f(x,a)=a_0+a_1x+a_2x^2+…+a_Mx^M=\Sigma_{i=0}^Ma_ix^i$</p><p>可以转化为：$f(x,a)=A^TX$，其中：</p><p>$X=[1,x,x^2,x^3,…,x^M]^T,a=[a_0,a_1,a_2,…,a_M]^T$</p><p>基本理论部分十分简洁明了。</p><h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>这里目标函数通常使用最小二乘误差（Mean Square Error）：</p><p>$J_n(a)=\frac{1}{N}\Sigma_{i=1}^N(y_i-a^Tx_i)^2=(y-X^Ta)^T(y-X^Ta)$</p><p>当然，使用平方残差（Residual Sum of Squares）也是可以的，区别在于比最小二乘误差少了系数$\frac{1}{N}$。</p><p>你可能会问，为什么不使用平均绝对值误差（Mean Absolute Error）：$J_n(a)=\frac{1}{N}\Sigma_{i=1}^N|y_i-a^Tx_i|$，但是它存在一些缺陷：</p><ol><li>在零点处不可导。</li><li>其导出的梯度是常数（+1或者-1），梯度求解容易导致不收敛。</li></ol><p>接下来我们抱着让目标函数最小化的目标，对它求梯度：</p><p>$\nabla J_n=-\frac{2}{N}X(y-X^Ta)$</p><p>然后就可以开始愉快地参数估计啦（＾∇＾）</p><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p>这里我们有两种估计方法：基于正规矩阵（Normal Equation）的直接求解，或者给予梯度下降的迭代法。</p><h3 id="正规矩阵"><a href="#正规矩阵" class="headerlink" title="正规矩阵"></a>正规矩阵</h3><p>由上面的梯度，我们直接令梯度为0：</p><p>$a=(XX^T)^{-1}Xy$，这就是理论最优解——因为梯度为0，目标函数是完全凸的，所以可以认为训练数据的目标函数达到了最小值。</p><ul><li><p>如果$XX^T$非奇异，那么我们可以获得<strong>唯一解</strong>（奇异情况下使用伪逆，理论上应该是有无数组解）。</p></li><li><p>特别地，如果$X$是方阵（一般不是），那么$a=X^{-T}X^{-1}Xy=X^{-T}y$。</p></li></ul><p>好，然后我们看一下梯度求解的做法：</p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>如果你还不知道梯度下降是什么的话，我在<a href="https://riroaki.github.io/Machine-Learning-00-Overview/">第一篇文章</a>里已经写过梯度下降、批量梯度下降/随机梯度下降这些概念了哦，最好还是去补补课～</p><p>通过迭代的方式更新参数，只需要把梯度乘上一个学习率$\alpha$就可以：</p><p>$grad=\alpha * -2X(y-X^Ta)$</p><p>$a-=grad$</p><p>好了，这里再次提出第一篇文章的问题，为什么第一种方法看起来简单直接，而且能够得到确定的“精确解”，而实际操作往往使用基于梯度的做法呢？看起来第二种做法很不精确，而且似乎未必收敛到正确的解。</p><blockquote><p>理由就是，第一个方法的实质是计算方程组的解，涉及求逆矩阵的过程，但是一来计算量大，二来难以保证矩阵非奇异或者非病态的情况下，计算过程对方程组值的扰动非常敏感，噪声带来的误差较大导致结果偏离理论解。</p></blockquote><h2 id="正规化"><a href="#正规化" class="headerlink" title="正规化"></a>正规化</h2><p>好了，我们的模型看起来很完美不是吗？</p><p>现在我们试着用线性模型去拟合开头提到的多项式曲线$f(x,a)=a_0+a_1x+a_2x^2+…+a_Mx^M=\Sigma_{i=0}^Ma_ix^i$</p><p>假如图线长这样，$y=sin(x)$：</p><p><img src="/Machine-Learning-02-Linear-Regression/polynomial.png" alt></p><p>这种图线，0阶、1阶都是单调，看起来都拟合不了啊，2阶又不能先凹后凸。</p><p>咱们上三阶试试：</p><p><img src="/Machine-Learning-02-Linear-Regression/3.png" alt></p><p>看起来还行，但是没办法做到完美贴合。</p><p>我们试试更厉害的，让M=9：</p><p><img src="/Machine-Learning-02-Linear-Regression/9.png" alt></p><p>嚯，厉害了，要不是背景把真实曲线画出来我还真就信了。</p><p>虽然做到训练误差为0，但是我们有理由相信，在真实数据上测试结果一定惨不忍睹。</p><p>结果如下：</p><p><img src="/Machine-Learning-02-Linear-Regression/results.png" alt></p><p>很明显，模型过拟合了。于是可以复习一下第一篇文章关于偏差与方差的理解：</p><blockquote><p>模型越复杂（组成模型的参数越多），方差越大，偏差越小，这是因为模型的描述能力越强；模型越简单，偏差也容易大，很可能无法拟合训练数据。</p></blockquote><p>我们还发现一个特征，那就是越高阶的那个系数绝对值越大：</p><p><img src="/Machine-Learning-02-Linear-Regression/coef.png" alt></p><p>为了避免过拟合，我们引入一种叫做正规化（Regularization）的技巧。</p><p>下面介绍两种正规化技巧，Ridge与Lasso。</p><h3 id="Ridge"><a href="#Ridge" class="headerlink" title="Ridge"></a>Ridge</h3><p>我们使用二阶残差作为目标函数，并引入一个惩罚项，变为：</p><p>$a^*=argmin\Sigma_{i=1}^N(y_i-x_i^Ta)^2+\lambda\Sigma_{j=1}^pa_j^2=(y-X^Ta)^T(y-X^Ta)+\lambda a^Ta$</p><p>计算梯度得到：$\nabla a=-2X(y-X^Ta)+2\lambda a$</p><p>用正规方程的方法，我们可以得到：$a^*=(XX^T+\lambda I)^{-1}Xy$，其中$\lambda$是一个常数。</p><p>再次求解，我们惊奇的发现，高阶的系数变小了：</p><p><img src="/Machine-Learning-02-Linear-Regression/coef1.png" alt></p><p>这就比较耐人寻味了。从理论角度分析一下这个事实：</p><p>岭回归以增大偏差为代价，换取更小的方差——这是随着$\lambda$增大，模型发生的变化。</p><p>在这个多项式中，因为很明显地看到随着模型变得复杂，模型的方差越来越大，岭回归正是降低方差的手段。</p><p><strong>不仅如此，岭回归更大的用处在于。当我们的特征存在较强的线性相关性的时候（可以说在特征方面不满秩），会导致$XX^T$的值很小，甚至趋于奇异。而岭回归会帮我们限制参数绝对值的大小，抑制相关性较强的属性系数。</strong></p><p>所以，岭回归实际上并不只是用在刚才的多项式拟合上，而是对所有存在较多线性相关属性时的通用解决方式。个人理解有点类似“降维”的操作，但是稍有不同。数学上使用术语<strong>压缩估计</strong>（shinkage）描述这一操作。</p><h3 id="Lasso"><a href="#Lasso" class="headerlink" title="Lasso"></a>Lasso</h3><p>和Ridge相似，唯一的不同在于惩罚项的阶数：</p><p>$a^*=argmin\Sigma_{i=1}^N(y_i-x_i^Ta)^2+\lambda\Sigma_{j=1}^p|a_j|=(y-X^Ta)^T(y-X^Ta)+\lambda ||a||_1$</p><p>它带来的影响也稍有不同，会导致模型的参数大多变成0，也就是得到<strong>稀疏化</strong>的参数。</p><p>用一幅图直观理解：</p><p><img src="/Machine-Learning-02-Linear-Regression/lasso-ridge.png" alt></p><p>红色的椭圆和蓝色的区域的切点就是目标函数的最优解，我们可以看到，如果是圆，则很容易切到圆周的任意一点，但是很难切到坐标轴上，因此没有稀疏；但是如果是菱形或者多边形，则很容易切到坐标轴上，因此很容易产生稀疏的结果。这也说明了为什么Lasso会是稀疏的。</p><h3 id="从量化的偏差、方差与噪音的角度看待正则化（待补充说明）"><a href="#从量化的偏差、方差与噪音的角度看待正则化（待补充说明）" class="headerlink" title="从量化的偏差、方差与噪音的角度看待正则化（待补充说明）"></a>从量化的偏差、方差与噪音的角度看待正则化（待补充说明）</h3><p>到这里我们从量化的角度来看这三个概念：</p><p>我们用一个概念来代表模型的总误差：Expected Prediction Error，EPE。</p><p>量化的计算如下（目前我对这部分理解不深，这一部分待补充）：</p><p>$EPE(f)=\int\int(y-f(x))^2p(x,y)dxdy$</p><p>$EPE=var+bias^2+noise$</p><ul><li>$bias^2=\int{E_D(f(x;D))-E(y|x)}^2p(x)dx$</li><li>$variance=\int E_D{[f(x;D)-E_D(f(x;D))]^2}p(x)dx$</li><li>$noise=\int var(y|x)p(x)dx$</li></ul><p>这里贴出不同$\lambda$参数对偏差与方差的影响：</p><p><img src="/Machine-Learning-02-Linear-Regression/-2.4.png" alt></p><p><img src="/Machine-Learning-02-Linear-Regression/-0.31.png" alt></p><p><img src="/Machine-Learning-02-Linear-Regression/2.6.png" alt></p><p>可以很明显的看出，正则项降低了图线的拟合程度，但是也降低了方差（即不同预测线的变化幅度）。</p><p>从而，我们对Bias-Variance的Trade-off有了更深的理解：</p><p><img src="/Machine-Learning-02-Linear-Regression/tradeoff.png" alt></p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>又到了动手实践的时间了。这一次实现了<code>LinearRegression</code>类基于<code>LinearModel</code>基类，并实现了其抽象方法。在这一份代码中不但实现了基于梯度下降的迭代方法，也实现了基于<code>normal equation</code>的直接求解法。</p><p>暂时没有实现Ridge和Lasso的正则部分，主要是希望和其他线性分类器一同构思实现，把正则化做一个更佳泛用型的模块。</p><p>代码中已经给出部分注释，如有疑问请在评论区留言。其他详情请见我的<a href="https://github.com/Riroaki/LemonML/">repo</a>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> supervised<span class="token punctuation">.</span>_base <span class="token keyword">import</span> LinearModel<span class="token keyword">from</span> utils <span class="token keyword">import</span> batch<span class="token keyword">class</span> <span class="token class-name">LinearRegression</span><span class="token punctuation">(</span>LinearModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Linear regression model."""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        <span class="token keyword">if</span> kwargs <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Update parameters of training</span>            self<span class="token punctuation">.</span>_update_params<span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span>        iters<span class="token punctuation">,</span> loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span>        <span class="token comment" spellcheck="true"># Iterates till converge or iterating times exceed bound</span>        <span class="token keyword">while</span> iters <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_iter_bound<span class="token punctuation">:</span>            iters <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment" spellcheck="true"># Update weights using mini-batch gradient desent</span>            <span class="token keyword">for</span> batch_x<span class="token punctuation">,</span> batch_y <span class="token keyword">in</span> batch<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>                pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>                loss <span class="token operator">+=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span> <span class="token operator">*</span> batch_x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                grad_w<span class="token punctuation">,</span> grad_b <span class="token operator">=</span> self<span class="token punctuation">.</span>_grad<span class="token punctuation">(</span>batch_x<span class="token punctuation">,</span> pred_val<span class="token punctuation">,</span> batch_y<span class="token punctuation">)</span>                self<span class="token punctuation">.</span>_w <span class="token operator">-=</span> grad_w                self<span class="token punctuation">.</span>_b <span class="token operator">-=</span> grad_b            loss <span class="token operator">/=</span> n            <span class="token comment" spellcheck="true"># Break if model converges.</span>            <span class="token keyword">if</span> loss <span class="token operator">&lt;=</span> self<span class="token punctuation">.</span>_loss_tol<span class="token punctuation">:</span>                <span class="token keyword">break</span>        <span class="token comment" spellcheck="true"># Update model with current weight and bias</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">fit_norm_eq</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Fit x using normal equation</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_w <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_b <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">!=</span> p<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># Initialize weights using random values</span>            self<span class="token punctuation">.</span>_init_model<span class="token punctuation">(</span>p<span class="token punctuation">)</span>        x_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">)</span>        w_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>pinv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x_ext<span class="token punctuation">.</span>T<span class="token punctuation">,</span> x_ext<span class="token punctuation">)</span><span class="token punctuation">)</span>        w_ext <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>w_ext<span class="token punctuation">,</span> x_ext<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b <span class="token operator">=</span> w_ext<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> w_ext<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Calculate training loss</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_b<span class="token punctuation">)</span>        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_update_model<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_val    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">assert</span> <span class="token operator">not</span> np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        pred_val <span class="token operator">=</span> self<span class="token punctuation">.</span>_predict_value<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                       self<span class="token punctuation">.</span>_optimum<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># The precision part of regression is None</span>        precision <span class="token operator">=</span> None        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>_loss<span class="token punctuation">(</span>pred_val<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_value</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> w<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>                       b<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        pred_val <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b        <span class="token keyword">return</span> pred_val    @staticmethod    <span class="token keyword">def</span> <span class="token function">_predict_label</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># NO labeling in regression.</span>        <span class="token keyword">pass</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">_loss</span><span class="token punctuation">(</span>pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> true_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Use MSE loss</span>        loss <span class="token operator">=</span> float<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_val<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        loss <span class="token operator">/=</span> <span class="token number">2</span> <span class="token operator">*</span> true_val<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">_grad</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> pred_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span>              true_val<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Use MSE loss</span>        grad_w <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">*</span> <span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_val<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        grad_b <span class="token operator">=</span> <span class="token punctuation">(</span>pred_val <span class="token operator">-</span> true_val<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Use simple gradient by multiplying learning rate and grad.</span>        grad_w <span class="token operator">*=</span> self<span class="token punctuation">.</span>_learn_rate        grad_b <span class="token operator">*=</span> self<span class="token punctuation">.</span>_learn_rate        <span class="token keyword">return</span> grad_w<span class="token punctuation">,</span> grad_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;本文是”机器学不动了”系列的第三篇文章，内容包含了线性回归的详细理论和简单线性回归的实现。&lt;/p&gt;
&lt;p&gt;全系列推荐结合个人实现的代码食用：&lt;a href=&quot;https://github.com/Riroaki/LemonML/，欢迎star、fork与pr。&quot;&gt;https://github.com/Riroaki/LemonML/，欢迎star、fork与pr
        
      
    
    </summary>
    
      <category term="机器学不动了" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学不动了-2：贝叶斯分类</title>
    <link href="http://riroaki.github.io/Machine-Learning-01-Bayes/"/>
    <id>http://riroaki.github.io/Machine-Learning-01-Bayes/</id>
    <published>2019-06-21T04:00:00.000Z</published>
    <updated>2019-06-22T14:47:19.410Z</updated>
    
    <content type="html"><![CDATA[<p>本文是”机器学不动了”系列的第二篇文章，内容包含了贝叶斯分类的详细理论和简单高斯贝叶斯分类器的实现。</p><p>全系列推荐结合个人实现的代码食用：<a href="https://github.com/Riroaki/LemonML/，欢迎star、fork与pr。">https://github.com/Riroaki/LemonML/，欢迎star、fork与pr。</a></p><h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>贝叶斯分类的核心是贝叶斯公式：</p><ul><li>$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$</li><li>$P(A) = \Sigma_{i=1}^n{P(B|A_i)P(A_i)}$</li><li>贝叶斯公式对多元变量同样适用，与变量是否独立也无关，是普适的公式。</li></ul><p>为了介绍这个公式，我们首先来看一道概率题：</p><blockquote><p>现分别有 A、B 两个容器，在容器 A 里分别有 7 个红球和 3 个白球，在容器 B 里有 1 个红球和 9 个白球，而设定从A中抽取的概率和B中抽取的概率为1:2。</p><p>现已知从这两个容器里任意抽出了一个红球，问这个球来自容器 A 的概率是多少?</p></blockquote><p>记抽中红球的事件为$P(B)$，记从容器A抽球的概率为$P(A)$。</p><p>根据贝叶斯公式，我们有：$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$。其中$P(B|A)$表示从容器A中抽球，抽到红球的概率。</p><p>在这个公式中：</p><ul><li>$P(A|B)$是已知B发生后A的条件概率，也叫做A的后验概率（posterior probability）。</li><li>$P(B|A)$是已知A发生后B的条件概率，是B的后验概率，在这里叫A的似然概率（likelihood）。</li><li>$P(A)$是事件发生之前我们对A的经验知识，与B无关，叫做A的先验概率（prior probability）。</li><li>$P(B)$是B的先验概率，在这里叫做标准化常量（normalized constant）。</li><li>根据这个关系，后验$P(A|B)$也可以叫做<strong>标准化</strong>的似然；似然和后验是可以相互转化的。</li></ul><h2 id="贝叶斯分类理论"><a href="#贝叶斯分类理论" class="headerlink" title="贝叶斯分类理论"></a>贝叶斯分类理论</h2><p>从这个公式引申开，我们可以套用在分类理论上：</p><ul><li>我们可以类比认为每一个类对应一个容器，样本都是这个类中生成（取出）的。</li><li>分类问题可以采用这样的表述：已知一个待归类样本$X_i$的特征，那么求$X_i$属于第j个类的概率，就变成了一个后验概率。</li><li>把样本属于第j个类的概率记作事件$w_j$，这个后验概率可以表述为：$P(w_j|x=X_i)$，简记作$P(w_j|X_i)$。</li><li>那么，根据贝叶斯公式，我们有：$P(w_j|X_i)=\frac{P(X_i|w_j)P(w_j)}{P(X_i)}$。</li><li>这里的似然是$P(X_i|w_j)$，先验概率是$P(w_j)$，标准化常量为$P(X_i)$。</li></ul><p>那么，有了某个样本属于各个类别的概率，如何分类呢？</p><p>很自然的，我们选择后验概率比较大的那一个概率对应的类别作为$X_i$的分类。</p><ul><li>补充1：当我们只有先验概率的时候，我们选择先验概率较大的那一个类别作为分类。用先验概率直接估计的坏处在于”马太效应”，因为它总是把新样本归类到原本占多数的那一个类。</li><li>补充2：当采用风险矩阵（risk matrix）进行评估的时候，分类规则会更复杂一些，将在下文中作为拓展内容介绍。</li></ul><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p>我们已经有了概率的公式和决策理论，如何估计概率公式中的各个概率？</p><p>答案是：从有类标签的数据（训练数据）中总结提取。</p><h3 id="先验概率的估计"><a href="#先验概率的估计" class="headerlink" title="先验概率的估计"></a>先验概率的估计</h3><p>这里的先验概率，就是在没有训练样本具体特征的值的分布情况下，某个类原始的信息。</p><p>很自然的，我们会把这个类别的样本数占全部有标签的样本的比重当作先验概率，</p><p>即：$P(w_j)=\Sigma_{i=1}^N{I(y_i=c_j)}/N$</p><h3 id="似然概率的估计"><a href="#似然概率的估计" class="headerlink" title="似然概率的估计"></a>似然概率的估计</h3><p>这里我们需要分为连续变量和离散变量两种情况讨论：</p><h4 id="连续变量"><a href="#连续变量" class="headerlink" title="连续变量"></a>连续变量</h4><p>我们有不同的假设可以做出不同的估计。常用的有高斯分布假设、二项分布假设、伯努利分布。</p><p>这里只介绍高斯分布假设对应的参数估计方法。</p><ul><li>高斯分布的具体假设：对于某一个类$c_i$，其生成的样本满足高斯分布，即：$X\sim N(\mu, \Sigma)$，其产生的每一个样本之间的概率是互相独立且同分布的（i.i.d，Independent and identically distributed）</li><li>在这里我们采用极大似然估计（Maximum Likelihood Estimation）的做法来选取最佳参数：<ul><li>目标函数是$L(\mu_j,\Sigma_j)=\prod_{i=1}^N{P(X_i|w_j)}$。</li><li>由于不方便对目标函数求导，我们采用取对数的技巧，将连乘转化为连加：$l(\mu_j,\Sigma_j)=log(L)=\Sigma_{i=1}^NP(X_i|w_j)$</li><li>对对数似然求导，令导数为0求出$\mu,\Sigma$。由于样本是多维，求导过程比较复杂，详情参考附录。</li><li>总之，最终求出的结果和标量形式的惊人一致：<ul><li>$\hat\mu_j=\frac{1}{N_j}\Sigma_{i=0}^{N_j}X_i=\bar{x}$</li><li>$\hat\Sigma=\frac{1}{N_j}\Sigma_{i=1}^{N_j}(X_i-\hat\mu)(X_i-\hat\mu)^T=cov(X_i), where\ y_i = w_j$</li><li>很容易联想到标量情况下，$\hat\mu=\bar{X}, \hat\sigma=var(X)$</li></ul></li></ul></li><li>有了估计的参数以后，我们可以通过高斯概率密度公式求似然概率：$P(X; \mu, \Sigma)=\frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(X-\mu)^T\Sigma^{-1}(X-\mu))$</li></ul><blockquote><p><strong>P.S.其实我有一点疑问🤔️，为什么这里不能使用梯度求解而是直接令梯度为0求解证明的呢，有没有大佬能够在评论区说一说自己的想法……</strong></p></blockquote><h4 id="离散变量"><a href="#离散变量" class="headerlink" title="离散变量"></a>离散变量</h4><p>对于离散变量的估计则较为简单，我们选取以前这一特征出现过的值的分布情况作为估计，即：</p><p>$P(X_i^k|w_j)=\frac{|X_i^k|}{N_{w_j}}$</p><p>比如在某个类的性别特征中，男性出现了100次，女性出现了200次，我们就估计一个这个属性为男性的似然概率为100/300=0.33333…，对女性同理。</p><h3 id="标准化常量"><a href="#标准化常量" class="headerlink" title="标准化常量"></a>标准化常量</h3><ul><li>对于连续变量来说，理论上是通过$P(X_i)=\Sigma_{j=1}^cP(X_i|w_j)P(w_j)$求出概率密度，也就是说得算出对样本对每一个类的先验概率和似然的乘积之和，才能计算分母。</li><li>对于离散变量来说，则是求出这一个一模一样的样本在训练数据中出现的次数。<ul><li>如果过去没有出现过这一样本，我们总不能把0作为它的概率，这是不合理的（一来有可能是样本数量过少，二来人家是分母啊，怎么能是0），所以采用平滑（Smoothing）的技术，在分子分母同时加入一个与样本数有关的平滑项。具体技术在此不做详细介绍。</li></ul></li></ul><p>然而正常情况下，它并不在我们的考虑范围内：</p><p>因为，每一个类的计算概率的分母都是这一项。既然我们最终的目标是比较后验概率的大小（或者与风险矩阵关联后的大小，whatever），这一项作为相同的系数并不会产生影响：）</p><h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>在这里因为我们并不是采取迭代优化，而是通过假设模型直接估计得出参数，所以不需要目标函数可导。</p><p>采用0-1损失函数就可以，即分类错误，结果就加一，分类正确结果就不变化的函数。</p><p>下面就以贝叶斯为例，讲一下分类中一个常见的评价标准（metrics）：混淆矩阵和风险矩阵。</p><h2 id="混淆矩阵与风险矩阵"><a href="#混淆矩阵与风险矩阵" class="headerlink" title="混淆矩阵与风险矩阵"></a>混淆矩阵与风险矩阵</h2><h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><p>一张图说明混淆矩阵：</p><p><img src="/Machine-Learning-01-Bayes/confusion.jpg" alt></p><p>混淆矩阵用于预测与实际的差距，对一个N元分类器而言是一个N*N的矩阵，$M[i][j]$表示了预测类为$i$，真实类为$j$的样本数。显然，正确的分类落在矩阵的主对角线上，即所有的$M[i][i]$元素。而其他项表示了分类错误的个数。</p><p>当然也有</p><p>对于二分类而言，我们会把某一个类叫做正类，另一个类叫做负类，预计某个类为正类叫做阳性，反之叫阴性，所以又产生了如下概念：</p><ul><li>预测和真实均为正类的叫做<strong>真阳性</strong>（TP，True Positive）</li><li>预测与真实均为负类的叫做<strong>真阴性</strong>（TF，True Negative）</li><li>预测为正类而真实为负类的叫做<strong>假阳性</strong>（FP，False Positive）</li><li>预测为负类而真实为正类的叫做<strong>假阴性</strong>（FN，False Negative）</li></ul><p>稍加拓展，当应用在多分类上，就是把分类错误统称为负类，分类正确的当做正类。</p><p>由此出发，我们得到新的概念作为评价指标：</p><ul><li><p><strong>准确率</strong>（Accuracy）：$Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$</p></li><li><p><strong>精确率</strong>（Precision）：$Precision=\frac{TP}{TP+FP}$</p></li><li><p><strong>召回率</strong>（Recall）：$Recall=\frac{TP}{TP+FN}$</p></li></ul><p>这些概念容易搞混，另外与搜索引擎的评估也有一定关联。</p><p>那么这三个分类标准分别有什么特点和适用场景？</p><p>我们以检测疾病的分类器为例说明：</p><ol><li>Accuracy与分类目标无关，实际只看分对了没有；在类别不均衡的问题上评估粒度太大，不如后两种手段有效。因此，在没有特定要求某个类的准确率而是关注整体准确率的时候，使用这一指标。</li><li>Precision是指分类器所挑出的某个类中，真正是我们希望的那一类的概率。使用这个为指标就是期待分类器降低把没病的人当作有病的概率。</li><li>Recall是指没有被识别出是我们想要的那一类的概率。简单来说就是使用这个指标就是期待分类器不要错放过有病的人。</li></ol><h3 id="风险矩阵"><a href="#风险矩阵" class="headerlink" title="风险矩阵"></a>风险矩阵</h3><p>生活经验中，同样是分类错误，我们对于不同错误分类的容忍度往往是不同的，比如：</p><ul><li>垃圾邮件分类问题中，相比重要邮件被错误分类为垃圾邮件而进入垃圾箱，我们更情愿多收到一些被当作正常邮件的垃圾邮件。<ul><li>在这里如果正类是垃圾邮件，那么我们关注Precision多于Recall；反过来如果正常邮件是正类，那么我们更加关注Recall。</li></ul></li><li>当判决某个细胞是正常细胞还是癌细胞的时候，显然把一个正常细胞错判为癌细胞的风险要比把一个癌细胞错判为正常细胞的风险大很多，后者的错误是致命的。<ul><li>如果我们的正类是癌细胞，那么我们关注Recall多于Precision，因为我们不希望放过每一个正类。</li></ul></li></ul><p>在这些情形下，同样都是分类错误，某一种分类错误的影响更严重，所以并不是最小错误率（Minimum Probability Error）而是最小风险误差（Minimum Risk）才能够表示我们的期待，这个时候我们会把分类错误添加一个权重，使用权重来改变评判标准。</p><p>风险（Risk），可以理解为对某种错误分类情形下造成后果的严重程度，形状和混淆矩阵一致，是人为添加的半定量矩阵。</p><p>我们将风险矩阵与混淆矩阵对应位置元素相乘得到的总和就是新的目标函数值，我们的分类结果应当使得这一目标函数值达到最小。</p><p>这一改变将如何影响我们的分类策略？</p><ul><li>对一个样本$X_i$：<ul><li>对每一个类j，我们计算出$X_i$属于j类的概率分别为$P(w_j|X_i)$，并计算j类的误分类风险之和：$\Sigma_{i!=j}M[j][i]$</li><li>将类的误分类风险与概率相乘，乘积就是j类误分类的概率风险</li><li>将每一个类的误分类概率风险求出，找到概率风险最小的那一个分类作为当前的分类</li></ul></li></ul><p>按照这一方法分类计算得到的误分类概率风险是最小的。</p><h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>朴素贝叶斯（Naive Bayes）模型是贝叶斯模型的一个变种，是简化贝叶斯参数的一种模型。</p><p>在朴素贝叶斯中，我们认为各个特征之间是独立的，互相不会影响，即：</p><p>$P(X_i|w_j)=P(X^1_i,X^2_i,X^3_i,…X_i^p|w_j)=P(X_i^1|w_j)P(X_i^2|w_j)P(X_i^3|w_j)…P(X_i^p|w_j)$</p><p>$=\prod_{k=1}^pP(X_i^k|w_j)$</p><p>将这一假设应用在高斯模型中，贝叶斯-高斯模型的$\Sigma$参数就退化为对角矩阵，因为它本质是协方差矩阵，如今各个特征之间的协方差为0，每个特征服从独立的高斯分布。</p><p>所以计算公式也变得简单，只需要单独计算每一维度的高斯分布概率再相乘就可以计算。</p><p>朴素贝叶斯分类器至今也是一个简单的流行分类器，不过在很多时候，样本的属性往往是相关的，这种情形下使用朴素贝叶斯模型就不太好。</p><h2 id="分类面形状"><a href="#分类面形状" class="headerlink" title="分类面形状"></a>分类面形状</h2><p>一般而言，贝叶斯分类器并不是一个线性分类器。</p><h3 id="高斯模型"><a href="#高斯模型" class="headerlink" title="高斯模型"></a>高斯模型</h3><p>不同类之间的分类面是高斯面之间的相交面，和每个类的模型参数有关。</p><p>用二维特征、多分类的高斯分类面的图像说明会更清晰（概率密度表现为图像中的高度z值，不同的峰表示不同类的中心概率密度）：</p><p><img src="/Machine-Learning-01-Bayes/multiclass.png" alt></p><p>限制了二维特征与二分类的高斯分布模型之后，分类面其实有一些有趣的规律，这是由高斯分布的形状造成的。</p><p>这里以二分类、二维特征的高斯分类模型为例说明这一点，下图展示了不同的参数（$\mu,\Sigma$）带来分类面的不同：</p><p><img src="/Machine-Learning-01-Bayes/2class.png" alt></p><p>对应的概率分布三维图：</p><p><img src="/Machine-Learning-01-Bayes/2class2.png" alt></p><p>那么，高斯模型的参数又是如何影响分类面形状的呢？</p><p>可以证明有以下结论（证明见附录）：</p><ul><li><p>类的$\mu$参数不会影响分类面的性质（线性/非线性），只会改变类在高维空间的中心位置。</p></li><li><p>如果所有特征均是独立分布，且所有类共享协方差矩阵，即：$\Sigma_j=\sigma^2I$，那么分类面是线性的，且两个类之间的分类直线垂直类中心之间的连线。</p></li><li><p>如果所有特征均共享协方差矩阵，即：$\Sigma_j=\Sigma=cov(X)$，那么分类面也是线性的，但是直线会存在一定的倾斜。</p></li><li><p>如果不满足这两个条件之间的任意情况，那么分类面是圆锥曲线（抛物线、双曲线、圆……）。</p></li></ul><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li>对偶尔的数据噪声鲁棒性好，因为使用了假设模型，相当于模型的信息不完全来自数据。</li><li>但是也因为模型自带假设，在不满足假设情形的数据上拟合效果不好。</li></ul><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>好了，说了这么多终于要上代码了～</p><p>这里实现了高斯贝叶斯多分类器，继承自<code>SupervisedModel</code>基类（详见本人的<a href="https://github.com/Riroaki/LemonML/">repo</a>），主要方法实现了<code>fit,predict,evaluate</code>，代码中包含一定的注释，如有疑问可以在评论区留言。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> supervised<span class="token punctuation">.</span>_base <span class="token keyword">import</span> SupervisedModel<span class="token keyword">class</span> <span class="token class-name">Bayes</span><span class="token punctuation">(</span>SupervisedModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Bayes model, multi-class (or binary) classifier.    Bayes models include Gaussian, Multinomial, Bernoulli,    however here I only implemented Gaussian.    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>_prior_dict <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_mean_dict <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_cov_dict <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_cov_all <span class="token operator">=</span> None        self<span class="token punctuation">.</span>_p <span class="token operator">=</span> None    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>float<span class="token punctuation">:</span>        <span class="token keyword">assert</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> label<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        n<span class="token punctuation">,</span> p <span class="token operator">=</span> x<span class="token punctuation">.</span>shape        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_mean_dict <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_cov_dict <span class="token keyword">is</span> None \                <span class="token operator">or</span> self<span class="token punctuation">.</span>_prior_dict <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_p <span class="token operator">!=</span> p<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>_prior_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            self<span class="token punctuation">.</span>_mean_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            self<span class="token punctuation">.</span>_cov_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>            self<span class="token punctuation">.</span>_p <span class="token operator">=</span> p        <span class="token comment" spellcheck="true"># Calculate mean and co-variance matrix for each class</span>        all_class <span class="token operator">=</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>label<span class="token punctuation">)</span>        <span class="token keyword">for</span> c <span class="token keyword">in</span> all_class<span class="token punctuation">:</span>            group <span class="token operator">=</span> x<span class="token punctuation">[</span>label <span class="token operator">==</span> c<span class="token punctuation">]</span>            mean<span class="token punctuation">,</span> cov <span class="token operator">=</span> self<span class="token punctuation">.</span>__param_gaussian<span class="token punctuation">(</span>group<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>_prior_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">=</span> group<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> n            self<span class="token punctuation">.</span>_mean_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">=</span> mean            self<span class="token punctuation">.</span>_cov_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">=</span> cov        <span class="token comment" spellcheck="true"># Calculate the whole co-variance matrix</span>        _<span class="token punctuation">,</span> cov <span class="token operator">=</span> self<span class="token punctuation">.</span>__param_gaussian<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_cov_all <span class="token operator">=</span> cov        <span class="token comment" spellcheck="true"># Calculate loss on x</span>        _<span class="token punctuation">,</span> loss <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_cov_dict <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> self<span class="token punctuation">.</span>_mean_dict <span class="token keyword">is</span> <span class="token operator">not</span> None        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_cov_all <span class="token keyword">is</span> <span class="token operator">not</span> None        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_p <span class="token operator">==</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Default: non-linear classifier</span>        linear <span class="token operator">=</span> <span class="token boolean">False</span>        <span class="token keyword">if</span> <span class="token string">'linear'</span> <span class="token keyword">in</span> kwargs<span class="token punctuation">:</span>            <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>kwargs<span class="token punctuation">[</span><span class="token string">'linear'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bool<span class="token punctuation">)</span>            linear <span class="token operator">=</span> kwargs<span class="token punctuation">[</span><span class="token string">'linear'</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Calculate posterior propability for each class</span>        <span class="token comment" spellcheck="true"># All class share a same co-variance matrix if linear == True</span>        prob<span class="token punctuation">,</span> label_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> c<span class="token punctuation">,</span> mean <span class="token keyword">in</span> self<span class="token punctuation">.</span>_mean_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> linear<span class="token punctuation">:</span>                cov <span class="token operator">=</span> self<span class="token punctuation">.</span>_cov_all            <span class="token keyword">else</span><span class="token punctuation">:</span>                cov <span class="token operator">=</span> self<span class="token punctuation">.</span>_cov_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span>            prior <span class="token operator">=</span> self<span class="token punctuation">.</span>_prior_dict<span class="token punctuation">[</span>c<span class="token punctuation">]</span>            current_prob <span class="token operator">=</span> self<span class="token punctuation">.</span>__posterior_gaussian<span class="token punctuation">(</span>x<span class="token punctuation">,</span> prior<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> cov<span class="token punctuation">)</span>            prob<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_prob<span class="token punctuation">)</span>            label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Get index of class having maximum probability for each x</span>        pred_val <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prob<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        label_list <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>label_list<span class="token punctuation">)</span>        pred_label <span class="token operator">=</span> label_list<span class="token punctuation">[</span>pred_val<span class="token punctuation">]</span>        <span class="token keyword">return</span> pred_label    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> label<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        pred_label <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Calculate 0-1 loss</span>        loss <span class="token operator">=</span> np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred_label <span class="token operator">-</span> label<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Use loss to calculate precision</span>        precision <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> loss <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> precision<span class="token punctuation">,</span> loss    @staticmethod    <span class="token keyword">def</span> <span class="token function">__param_gaussian</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> tuple<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Estimate mean and variance."""</span>        mean <span class="token operator">=</span> x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        diff <span class="token operator">=</span> x <span class="token operator">-</span> mean        cov <span class="token operator">=</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>diff<span class="token punctuation">.</span>T<span class="token punctuation">,</span> diff<span class="token punctuation">)</span> <span class="token operator">/</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> mean<span class="token punctuation">,</span> cov    @staticmethod    <span class="token keyword">def</span> <span class="token function">__posterior_gaussian</span><span class="token punctuation">(</span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> prior<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">,</span>                             mean<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> cov<span class="token punctuation">:</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Calculate posterior probability P(wi | x)."""</span>        <span class="token comment" spellcheck="true"># Calculate likelihood probability:</span>        <span class="token comment" spellcheck="true"># P(xj | wi) ~ 1 / sqrt(det(cov))</span>        <span class="token comment" spellcheck="true"># * exp(-0.5 * (xj - mean)^T * cov^(-1) * (xi - mean))</span>        diff <span class="token operator">=</span> x <span class="token operator">-</span> mean        coef <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>det<span class="token punctuation">(</span>cov<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span>        inv <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>pinv<span class="token punctuation">(</span>cov<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Get exponent for xj (0 &lt; j &lt; n)</span>        exponents <span class="token operator">=</span> np<span class="token punctuation">.</span>apply_along_axis<span class="token punctuation">(</span>            <span class="token keyword">lambda</span> row<span class="token punctuation">:</span> np<span class="token punctuation">.</span>float<span class="token punctuation">(</span>np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>row<span class="token punctuation">,</span> inv<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> diff<span class="token punctuation">)</span>        likelihood <span class="token operator">=</span> coef <span class="token operator">*</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> exponents<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Posterior = prior * likelihood / evidence (omitted)</span>        posterior <span class="token operator">=</span> prior <span class="token operator">*</span> likelihood        <span class="token keyword">return</span> posterior<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="附录："><a href="#附录：" class="headerlink" title="附录："></a>附录：</h2><h3 id="多维高斯参数估计推导（Deriving-the-Maximum-Likelihood-Estimators）"><a href="#多维高斯参数估计推导（Deriving-the-Maximum-Likelihood-Estimators）" class="headerlink" title="多维高斯参数估计推导（Deriving the Maximum Likelihood Estimators）"></a>多维高斯参数估计推导（Deriving the Maximum Likelihood Estimators）</h3><p>来源：<a href="https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian">https://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian</a></p><p>或者查看文档版本：<a href="https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf">https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf</a></p><p><img src="/Machine-Learning-01-Bayes/appendix1.png" alt></p><p><img src="/Machine-Learning-01-Bayes/appendix2.png" alt></p><p><img src="/Machine-Learning-01-Bayes/appendix3.png" alt></p><h3 id="高斯分布参数与分类面形状证明"><a href="#高斯分布参数与分类面形状证明" class="headerlink" title="高斯分布参数与分类面形状证明"></a>高斯分布参数与分类面形状证明</h3><p>来源：<a href="https://www.byclb.com/TR/Tutorials/neural_networks/ch4_1.htm">https://www.byclb.com/TR/Tutorials/neural_networks/ch4_1.htm</a></p><p>由于证明讨论过长，篇幅所限，在此不贴出详细证明内容。</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;本文是”机器学不动了”系列的第二篇文章，内容包含了贝叶斯分类的详细理论和简单高斯贝叶斯分类器的实现。&lt;/p&gt;
&lt;p&gt;全系列推荐结合个人实现的代码食用：&lt;a href=&quot;https://github.com/Riroaki/LemonML/，欢迎star、fork与pr。&quot;&gt;https://github.com/Riroaki/LemonML/，欢迎star、fork与pr
        
      
    
    </summary>
    
      <category term="机器学不动了" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>机器学不动了-1：机器学习综述</title>
    <link href="http://riroaki.github.io/Machine-Learning-00-Overview/"/>
    <id>http://riroaki.github.io/Machine-Learning-00-Overview/</id>
    <published>2019-06-20T16:00:00.000Z</published>
    <updated>2019-06-22T14:59:40.977Z</updated>
    
    <content type="html"><![CDATA[<p>本文是”机器学不动了”系列的第一篇文章，内容包含了机器学习的理论综述、算法分类和一些概念解释。</p><p>全系列推荐结合个人实现的代码食用：<a href="https://github.com/Riroaki/LemonML/，欢迎star、fork和pr。">https://github.com/Riroaki/LemonML/，欢迎star、fork和pr。</a></p><h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>如今深度学习、数据挖掘、机器学习这些概念已经🔥到成为满大街都是的概念，由于其门槛低（调包）和某些fancy的功能，加上媒体的宣传和高薪的诱惑，无论计算机专业还是非计算机专业出身的人们都热衷于在其中寻找机会，我这个软工的菜🐔也不例外。当然，目前正处于新手期。</p><p>这一个系列主要记录了我学习和梳理的机器学习的知识，包含数学理论和代码实现，希望能够给入门者（包括我自己）提供一个参考。</p><p>由于本人懒癌晚期，博客将不定期更新。</p><p>看客们如果有问题或者留言可以直接在相关的博文下面留言，我们可以共同探讨解决。</p><p>当然也可以邮件联系本人：<a href="mailto:lilq1285@163.com">lilq1285@163.com</a>，欢迎理性讨论。</p><p><strong>本系列内容属于个人原创，转载请声明出处，商业转载请联系本人，邮箱同上。</strong></p><h2 id="机器学习总览"><a href="#机器学习总览" class="headerlink" title="机器学习总览"></a>机器学习总览</h2><p>机器学习发源于统计学，主要的目标是用数学和程序语言描述事物的规律，从而为预测、决策提供参考。</p><p>以全局的视角来看机器学习这一领域的算法，主要分为有监督（Supervised）学习和无监督（Unsupervised）学习两类，此外还有半监督（Half-supervised）学习、强化（Reinforcement）学习：</p><h3 id="有监督学习"><a href="#有监督学习" class="headerlink" title="有监督学习"></a>有监督学习</h3><h4 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h4><ul><li>回归（Regression）通常目标是得到连续的曲线，输出是连续的值</li><li>分类（Classification）通常目标是得到决策的边界，输出的是离散的类别</li></ul><h4 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h4><ul><li>Linear Regression：线性回归，以线性方式组合特征拟合连续曲线</li><li>Bayes：贝叶斯分类，通过概率模型计算样本属于各个分类的后验概率，进行分类</li><li>Logistic Regression：逻辑回归，在线性回归基础上增加激活函数以进行分类</li><li>Support Vector Machine：支持向量机，选取决策面较近的点用来计算决策面的参数</li><li>K Nearest Neighbor：K近邻，寻找距离较近的K个样本的标签取众数作为样本归类</li><li>Perceptron：感知机，二分类算法，最简单的神经网络</li><li>Decision Tree：决策树，可以看作从样本数据中学习if-else语句的组合，每一个判断都是数的一个节点，实现分类</li><li>Linear Discriminant Analysis：线性判别分析，通过找到特征的线性组合以用于降维，也是一种分类算法</li></ul><h4 id="算法的分类"><a href="#算法的分类" class="headerlink" title="算法的分类"></a>算法的分类</h4><ol><li>如果从算法解决的问题分类，可以分为回归和分类两大类算法：</li></ol><ul><li>其中，线性回归为回归类的算法，其余算法均主要用于分类，当然也可以有回归的作用。因为这些分类算法大多是在连续的输出外进行处理获得类别，如逻辑回归、感知机、支持向量机等，如果用在回归上则输出的是分类前计算的结果。</li></ul><ol start="2"><li>如果从决策面的角度来看，上述的分类算法可以分为线性分类算法和非线性分类算法：</li></ol><ul><li>线性分类算法：分类面为线性/输出函数为线性形式（本质相同，采用不同的目标函数得到的模型）<ul><li>包括：逻辑回归、支持向量机、感知机、线性判别分析</li></ul></li><li>非线性算法：分类面为非线性/输出函数的形式为非线性<ul><li>包括：贝叶斯、K近邻、决策树</li></ul></li></ul><ol start="3"><li>如果从算法的实际含义角度看，上述的分类算法可以分为生成模型和判别模型：</li></ol><ul><li>生成模型：按照条件概率建立模型，基于高斯分布等假设，学习模型的参数用于分类<ul><li>包括：贝叶斯模型、线性判别分析</li></ul></li><li>判别模型：出于最大化在测试集上的表现，进行训练<ul><li>包括：大部分其他分类算法</li></ul></li></ul><p>在基本算法的基础上，现代机器学习常见的还有集成（Ensemble）学习，其核心是”三个臭屁匠，顶个诸葛亮”，并不致力于产生最强的单个分类器，而是通过把训练不同的较弱分类器，并进行集合决策以获得最好的分类效果。</p><h4 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h4><ul><li>Bagging/Bootstrap Aggregating：通过随机切分数据集，并行训练相同模型以获得更好的分类效果。<ul><li>随机森林（Random Forest）算法正是基于bagging算法实现。</li></ul></li><li>Boosting：通过训练一系列弱分类器并组合获得强分类器。</li><li>Stacking：训练一个组合不同模型的高层模型进行分类（上面两种算法对底层模型的组合方式是确定的）。</li></ul><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><h4 id="主要任务-1"><a href="#主要任务-1" class="headerlink" title="主要任务"></a>主要任务</h4><ul><li>降维（Dimensionality Reduction）指的是将样本空间从高维特征投影到较低维度的特征从而实现提高计算效率的作用。</li><li>聚类（Clustering）指的是将无标签的样本按照样本之间的距离信息等，将相近的样本归为一个簇的算法，可以理解为没有样本标签的分类算法。</li></ul><h4 id="常见算法-1"><a href="#常见算法-1" class="headerlink" title="常见算法"></a>常见算法</h4><ul><li>Principle Component Analysis：主成分分析，通过提取协方差矩阵中的特征向量作为新特征实现降维。<ul><li>与线性判别分析（LDA）相似的算法。</li></ul></li><li>K Means：K均值算法，通过抽取相近点簇的重心作为簇的代表来实现聚类。</li><li>K Medoids：K中心点算法，和K Means算法相近，不同的是选取簇中最接近重心的点作为簇的代表。</li><li>Spectral Clustering：谱聚类，通过降维方法和K Means算法实现聚类。</li><li>Gaussian Mixture Model：高斯混合模型，是基于高斯分布的假设，通过点簇的分布估计参数以实现聚类。<ul><li>K Means算法可以视为GMM的一种特殊形式。</li></ul></li><li>Matrix Factorization：矩阵分解，是一类降维算法，包括奇异值分解、矩阵非负分解和稀疏编码等算法。</li></ul><h4 id="算法的分类-1"><a href="#算法的分类-1" class="headerlink" title="算法的分类"></a>算法的分类</h4><ol><li>如果按照主要任务，可以将算法分为降维算法和聚类算法：</li></ol><ul><li>降维算法：主要包括主成分分析、矩阵分解</li><li>聚类算法：主要包括K均值、K中心点、谱聚类、高斯混合模型</li></ul><h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>利用少量标注样本和大量未标注样本进行机器学习的算法。</p><p>由于本人并不了解这一块，所以此处内容不作详细介绍，有兴趣者请自行谷歌。</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>没有特定的目标，强调环境的反馈作用，通过应对环境调整策略的算法。</p><p>由于本人并不了解这一块，所以此处内容不作详细介绍，有兴趣者请自行谷歌。</p><h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><p>这一块是近十年新的方向，也是目前机器学习最火的分支，但是预计不会在近期内容中出现。</p><p>简言之，深度学习就是基于神经网络的算法，通过组合线性的神经元和非线性的激活层，以及搭建不同结构的网络，来实现回归或者预测、聚类等工作。</p><p>其”神经网络”形态的灵感得益于生物大脑的神经元连接结构，让人联想到”机器的大脑🧠”，加上诸如alphaGo等等一些新奇的成就带来的狂热使得众人为之疯狂，许多营销号和媒体甚至脑洞大开，大肆鼓吹”人工智能有害论”。</p><p>但目前而言，可解释性差、缺乏较统一的数学理论描述是其硬伤。而且也没有出现强人工智能的迹象，目前的神经网络，本质只是一种复杂的统计模型。</p><p>随着研究陷入瓶颈，这场资本与舆论的狂欢已经在逐渐冷却，未来究竟如何发展也未可知：）</p><h2 id="机器学习方法论"><a href="#机器学习方法论" class="headerlink" title="机器学习方法论"></a>机器学习方法论</h2><p><strong>机器学习的本质在于从数据或者假设中建立模型、学习参数，去拟合一个未知的函数。</strong></p><p>根据论文《A Few Useful Things to Know about Machine Learning》，机器学习的过程可以表示为：</p><p>$LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION$</p><p>也就是说，机器学习主要分为三个过程：</p><ol><li>表示（Representation）：使用计算机能够执行的语言描述算法。这个阶段确定了模型的类型，所以决定了拟合/分类函数的假设空间（Hypothesis Space）——也就是说，在这一步，模型的参数个数和模型的计算方式已经确定，比如线性模型的$y=WX+B$，那么模型无法模拟非线性的分类/回归，这是选取的模型导致的。而具体是如何线性的函数，需要在接下来的过程中确定。</li><li>评估（Evaluation）：用于评估模型的好坏。根据任务的不同（回归、分类）确定了不同的种类，同时这个评估方法应当是能够方便地找到对应的优化函数的（更明确一点，评估的函数应该是可导的）。我们训练的目标就是最小化目标函数（误差型）或者最大化目标函数（精度型）。</li><li>优化（Optimization）：评估函数就像考试，有了考试我们就可以知道自己的薄弱环节，从而确定努力的方向。而有了评估函数，就有一个对应的优化函数用于调整模型的参数。<ul><li>通常我们采用基于梯度的方法，具体会在下面梯度下降这一概念中解释。</li></ul></li></ol><p>论文中列出了一个关于这三个部分的表格，在这里贴出来：</p><p><img src="/Machine-Learning-00-Overview/table.png" alt></p><p>从表格也可以看出来，对某一种算法，并非所有的评估函数都能够使用，有些算法是绑定了评估函数的。</p><p>同时，评估函数与优化函数存在对应关系，选择某一类评估函数时，对应的优化策略也就决定了。</p><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h3><p>特征缩放（Feature Scaling）是一项预处理技术，它将所有的输入按照统一的标准进行处理：</p><ul><li>最大最小缩放（Min-Max Normalization）：把每一个特征的各个值按照大小缩放到$[0,1]$的区间中。</li><li>均值缩放（Mean Normalization）：把每一个特征的各个值按照大小缩放到$[-1, 1]$区间中。</li><li>标准化（Standardization）：把每一个特征缩放成平均值为0，方差为1的变量。</li><li>单位化（Scaling to Unit Length）：把每一个样本的长度（即向量的第二范数）缩放为1。</li></ul><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>梯度下降（Gradient Descent）是在通常模型中通用的迭代型参数估计方法。</p><p>我们可以认为，目标函数是一个自变量为模型参数的函数，而我们希望达到它的最大/最小值。</p><p>我们知道，一个函数在最大或者最小值的位置，它的一阶梯度为全0的向量。至于它究竟是最大值还是最小值，得看其二阶导数，或者进行测试局部变化来验证。</p><p>当然，通常我们会希望目标函数是纯凸/纯凹的，因为这样它的驻点（极大极小值点）只有一个，一旦找到极值点就能够确定它是最优的。在这一理论的驱动下，诞生了凸优化这一学科，目标就是把各种非凸问题转化成凸的问题。</p><p>因此我们会对它进行求导，寻找一阶导数为0的点对应的自变量，也就是模型参数的值。</p><p>此时，我们可以直接利用等式的梯度为0求解出参数，也可以采用迭代求解的梯度下降方法。</p><p>前者看起来不是更直接而且精确嘛？但是事实上我们大多采用的是后者。理由就是，第一个方法的实质是计算方程组的解，涉及求逆矩阵的过程，但是一来计算量大，二来难以保证矩阵非奇异或者非病态的情况下，计算过程对方程组值的扰动非常敏感，噪声带来的误差较大导致结果偏离理论解。</p><p>那么，后者是如何操作的？</p><p>在每次训练时，减去梯度值和学习率的乘积。对于一个局部凸的部分，我们可以看到在减去梯度之后我们的参数坐标会向极值点（最低点）靠近，且梯度绝对值越大，下降越快。</p><p>理论依据：梯度的反方向就是函数局部值下降最快的方向。</p><p><img src="/Machine-Learning-00-Overview/grad.png" alt></p><p>为了快速收敛、避免震荡的目的，也出现了很多学习率优化算法，如自适应性优化（Adam）、Adagrad和随机梯度下降（SGD）、Momentum等策略，这一块暂时不做介绍。</p><h3 id="泛化-、方差、偏差和噪声"><a href="#泛化-、方差、偏差和噪声" class="headerlink" title="泛化 、方差、偏差和噪声"></a>泛化 、方差、偏差和噪声</h3><p>首先，泛化（Generalization）是指模型在经过一定的数据训练之后对现实数据进行测试，我们希望模型能够最小化测试误差（testing error），而训练数据集上的误差与测试数据集上的误差就是泛化误差（Generalization Error）。</p><p>而泛化误差分为方差（Variance）与偏差（Bias），通过这两个方面可以描述模型与现实模型的误差：</p><ul><li>Bias是模型预测与真实结果的差距，可以直观理解为训练误差（training error），表现了模型的拟合能力；</li><li>Variance则是“<strong>（大小相同的）不同训练数据集</strong>训练出的模型”的训练误差之间的差异，表现了数据扰动的影响。</li></ul><p>通常来说，模型越复杂（组成模型的参数越多），方差越大，偏差越小，这是因为模型的描述能力越强；模型越简单，偏差也容易大，很可能无法拟合训练数据。</p><p>通常模型复杂程度与方差/偏差的关系：</p><p><img src="/Machine-Learning-00-Overview/complexity.png" alt></p><p>在图中可以看到，随着模型变得复杂，训练误差/偏差变小，而方差（在图中可以看作测试误差与训练误差之间的差值）变大，训练误差在中间有一个较低值。</p><p>由此启发我们寻找一个复杂度的平衡点，使得模型具有较低的bias和variance；至于noise则是无法改变的。</p><p>此外，还有一个概念叫做噪声（noise）：噪声在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p><p>模型的误差主要来自三部分的总和。</p><h3 id="过拟合-欠拟合"><a href="#过拟合-欠拟合" class="headerlink" title="过拟合/欠拟合"></a>过拟合/欠拟合</h3><ul><li><p>欠拟合主要描述的是模型复杂度过低，难以拟合训练数据，此时偏差过大（上图左侧部分）</p></li><li><p>过拟合是指模型过于复杂，虽然在训练数据上能够较好拟合，但是在测试数据上误差极大，此时偏差较小而误差较大（上图右侧部分）</p></li></ul><p>需要注意的是，测试误差较大不能说明是过拟合还是欠拟合；需要看训练误差的大小以区分。</p><h2 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>交叉验证（Cross Validation）是一种避免过拟合的训练技巧。</p><p>具体思路在于将训练切分，每一次用不同的数据集来训练，优化平均的误差，从而降低不同数据集带来模型性能的变化，达到降低方差的目的。</p><p>主要有两种方法：</p><ul><li>K折验证（K-Fold）：指将数据切分为K份，每一份轮流作为验证集（Validation Set），其他数据作为训练数据，训练K轮次获得训练误差。</li><li>留一验证（Leave-One-Out）：是K=n的K折验证，通过每次取一个样本作为验证集进行交叉验证训练。</li></ul><h3 id="批量梯度下降-随机梯度下降"><a href="#批量梯度下降-随机梯度下降" class="headerlink" title="批量梯度下降/随机梯度下降"></a>批量梯度下降/随机梯度下降</h3><p>这是梯度下降的两种操作方式。</p><ul><li>随机梯度下降（Stochastic Gradient Descent）是指，对每一个训练的样本都计算一次梯度并且用梯度执行更新参数的操作。这种方法的好处是更新次数快，且存在一定的随机性不会陷入局部极小值；但是也因为随机性强，往往梯度的波动大，某一两个样本带来的参数变化太大，更新不稳定，甚至导致不收敛 。</li><li>批量梯度下降（Batch Gradient Descent）是指，每次对所有训练样本进行计算梯度并且只用所有梯度的平均值进行一次更新。这种方法的好处自然就是稳定更新；但是其更新太慢，在一定的时间里难以达到收敛，而且也容易陷入局部最小值，最终在较小的梯度下停止更新。</li></ul><p>一般来说现有的技巧在于折衷两种方案，进行小批量的梯度下降，并且打乱样本以获取随机性。</p><p>这样做的好处在于：</p><ol><li>利用了随机梯度下降的随机性，一般不会陷入局部极小值。</li><li>更新速度适中，保持较好的稳定性不会震荡，同时也能够较快达到收敛。</li><li>最重要的是，方便底层GPU优化。因为梯度计算的底层操作是矩阵运算，而GPU由于多核计算能够并行地计算某一行的计算结果，从而加速梯度更新过程。所以一般而言，小批量梯度下降的效率比随机梯度下降更高。</li></ol><hr><p>本篇完。后续将大致按照本篇的顺序，依次介绍主要的几种具体算法，而部分概念与技巧将在具体算法处介绍。</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;本文是”机器学不动了”系列的第一篇文章，内容包含了机器学习的理论综述、算法分类和一些概念解释。&lt;/p&gt;
&lt;p&gt;全系列推荐结合个人实现的代码食用：&lt;a href=&quot;https://github.com/Riroaki/LemonML/，欢迎star、fork和pr。&quot;&gt;https://github.com/Riroaki/LemonML/，欢迎star、fork和pr
        
      
    
    </summary>
    
      <category term="机器学不动了" scheme="http://riroaki.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B8%8D%E5%8A%A8%E4%BA%86/"/>
    
    
      <category term="Data Mining" scheme="http://riroaki.github.io/tags/Data-Mining/"/>
    
      <category term="Machine Learning" scheme="http://riroaki.github.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Restart</title>
    <link href="http://riroaki.github.io/Restart/"/>
    <id>http://riroaki.github.io/Restart/</id>
    <published>2019-05-28T01:52:55.000Z</published>
    <updated>2019-06-02T14:33:47.956Z</updated>
    
    <content type="html"><![CDATA[<p>今天把博客文章全都清空了。</p><p>主要是之前的文章太乱，缺乏整理；加上近期学了很多东西之后，回头看过去的内容觉得有些浅薄，决心从头开始写。</p><p>今后会在这里写一些机器学习，以及数据处理的东西。</p><p>当然还有一些工程向的内容，总之我会更加深思熟虑地推送文章。</p><p>（是不是也考虑一下换主题呢……哈哈还是算了估计又要挑很久）</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;今天把博客文章全都清空了。&lt;/p&gt;
&lt;p&gt;主要是之前的文章太乱，缺乏整理；加上近期学了很多东西之后，回头看过去的内容觉得有些浅薄，决心从头开始写。&lt;/p&gt;
&lt;p&gt;今后会在这里写一些机器学习，以及数据处理的东西。&lt;/p&gt;
&lt;p&gt;当然还有一些工程向的内容，总之我会更加深思熟虑地推送文章
        
      
    
    </summary>
    
    
      <category term="Hello, world!" scheme="http://riroaki.github.io/tags/Hello-world/"/>
    
  </entry>
  
</feed>
