{"meta":{"title":"Riroaki","subtitle":"Riroaki's home","description":"æˆ‘è¿˜è¦å»å®Œæˆåº”åšä¹‹äº‹ã€‚","author":"Riroaki","url":"http://riroaki.github.io","root":"/"},"pages":[{"title":"about","date":"2019-03-24T12:33:57.000Z","updated":"2019-04-09T12:06:40.449Z","comments":true,"path":"about/index.html","permalink":"http://riroaki.github.io/about/index.html","excerpt":"","text":"è¿™é‡Œæ˜¯Riroakiçš„ä¸ªäººå°ç«™ã€‚ ç”¨æ¥æ ‡è®°è‡ªå·±æ¥æ—¶çš„è·¯ã€‚"},{"title":"","date":"2019-03-28T12:22:57.198Z","updated":"2019-02-24T09:49:10.145Z","comments":true,"path":"voi/about.html","permalink":"http://riroaki.github.io/voi/about.html","excerpt":"","text":"VOI L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/koharu.model.json\"},\"display\":{\"position\":\"right\",\"width\":200,\"height\":600,\"hOffset\":0,\"vOffset\":-20},\"mobile\":{\"show\":true,\"scale\":0.5},\"log\":false});"},{"title":"","date":"2019-03-28T12:27:37.124Z","updated":"2019-02-24T16:30:40.702Z","comments":true,"path":"voi/README.html","permalink":"http://riroaki.github.io/voi/README.html","excerpt":"","text":"VOI A simple game still under construction. Inspired by VOI on iOS."},{"title":"","date":"2019-03-28T12:22:57.197Z","updated":"2019-02-24T09:48:57.432Z","comments":true,"path":"voi/contact.html","permalink":"http://riroaki.github.io/voi/contact.html","excerpt":"","text":"VOI L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/koharu.model.json\"},\"display\":{\"position\":\"right\",\"width\":200,\"height\":600,\"hOffset\":0,\"vOffset\":-20},\"mobile\":{\"show\":true,\"scale\":0.5},\"log\":false});"},{"title":"","date":"2019-03-28T15:25:31.653Z","updated":"2019-02-24T16:05:07.585Z","comments":true,"path":"voi/index.html","permalink":"http://riroaki.github.io/voi/index.html","excerpt":"","text":"voi å½“å‰æµè§ˆå™¨ä¸æ”¯æŒcanvasï¼Œè¯·æ›´æ¢æµè§ˆå™¨åå†è¯• VOI VOI Play Contact About &copy; Riroaki 2019 L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/koharu.model.json\"},\"display\":{\"position\":\"right\",\"width\":200,\"height\":600,\"hOffset\":0,\"vOffset\":-20},\"mobile\":{\"show\":true,\"scale\":0.5},\"log\":false});"},{"title":"","date":"2019-03-28T12:29:22.806Z","updated":"2019-02-24T13:07:24.493Z","comments":true,"path":"voi/play.html","permalink":"http://riroaki.github.io/voi/play.html","excerpt":"","text":"VOI å½“å‰æµè§ˆå™¨ä¸æ”¯æŒcanvasï¼Œè¯·æ›´æ¢æµè§ˆå™¨åå†è¯• L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/koharu.model.json\"},\"display\":{\"position\":\"right\",\"width\":200,\"height\":600,\"hOffset\":0,\"vOffset\":-20},\"mobile\":{\"show\":true,\"scale\":0.5},\"log\":false});"},{"title":"categories","date":"2019-03-24T12:31:34.000Z","updated":"2019-04-09T12:04:49.546Z","comments":true,"path":"categories/index.html","permalink":"http://riroaki.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-03-24T12:26:06.000Z","updated":"2019-04-09T12:05:24.696Z","comments":true,"path":"tags/index.html","permalink":"http://riroaki.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2019-03-28T12:22:57.192Z","updated":"2019-02-24T10:15:45.670Z","comments":true,"path":"voi/css/default.css","permalink":"http://riroaki.github.io/voi/css/default.css","excerpt":"","text":"html, body { height: 100%; width: 100%; overflow: hidden; background-color: black; font-family: 'Josefin Slab', 'Century Gothic', 'TeXGyreAdventor', \"STHeiti\", sans-serif; } #head { margin: 5% auto; display: block; } #menu { display: none; } a { text-decoration: none; } a:hover { text-decoration: none; } .blurMenu { padding: 0; margin: 0 0 10px 0; position: relative; } .blurMenu li a { font-size: 60px; white-space: nowrap; color: transparent; display: block; text-transform: uppercase; text-align: center; text-shadow: 0 0 6px #fff; letter-spacing: 1px; -webkit-transform: scale(0.75); transform: scale(0.75); transition: all 0.3s linear; margin: 3%; } .blurMenu:hover li a { text-shadow: 0 0 15px #fff; } .blurMenu li a:hover { text-shadow: 0 0 1px #fff; -webkit-transform: scale(1); transform: scale(1); } #foot { color: white; position: fixed; text-align: center; left: 0; right: 0; bottom: 20px; margin: auto; }"},{"title":"","date":"2019-03-28T12:22:57.194Z","updated":"2019-02-24T13:41:52.488Z","comments":true,"path":"voi/css/play.css","permalink":"http://riroaki.github.io/voi/css/play.css","excerpt":"","text":"* { margin: 0; padding: 0; } html, body { height: 100%; width: 100%; overflow: hidden; background-color: black;/*è¿™é‡ŒèƒŒæ™¯å¡«å……é»‘è‰²ï¼Œç„¶åç”»å¸ƒä¸€å¼€å§‹ç”»ä¸Šç™½è‰²ï¼Œå†æé»‘ç‚¹ï¼Œé¿å…å¼€å¤´é—ªä¸€ä¸‹é€ æˆä¸è¿è´¯çš„æ„Ÿè§‰*/ font-family: 'Josefin Slab', 'Century Gothic', 'TeXGyreAdventor', \"STHeiti\", sans-serif; } canvas { display: block; }"},{"title":"","date":"2019-03-28T12:22:57.194Z","updated":"2019-02-24T16:42:47.819Z","comments":true,"path":"voi/css/svg.css","permalink":"http://riroaki.github.io/voi/css/svg.css","excerpt":"","text":"/* VOIä¸‰ä¸ªå­—éœ€è¦çš„cssï¼š */ .text--transparent { fill: transparent; } .anim-shape { -webkit-transform-origin: 0 150px; transform-origin: 0 150px; -webkit-transform: scale(0, 1) translate(0, 0); transform: scale(0, 1) translate(0, 0); -webkit-animation: moving-panel 3s infinite alternate; animation: moving-panel 3s infinite alternate; } .colortext .anim-shape:nth-child(1) { fill: black; } .colortext .anim-shape:nth-child(2) { /*fill: #166973;*/ fill: gray; } .colortext .anim-shape:nth-child(3) { /*fill: #65bfa6;*/ fill: white; } .colortext .anim-shape:nth-child(4) { /*fill: #f2cd5c;*/ fill: gray; } .colortext .anim-shape:nth-child(5) { /*fill: #f26444;*/ fill: black; } .shadow { -webkit-transform: translate(10px, 10px); transform: translate(10px, 10px); } .anim-shape--shadow { fill: #000; fill-opacity: 0.2; } @-webkit-keyframes moving-panel { 100% { -webkit-transform: scale(1, 1) translate(20px, 0); transform: scale(1, 1) translate(20px, 0); } } @keyframes moving-panel { 100% { -webkit-transform: scale(1, 1) translate(20px, 0); transform: scale(1, 1) translate(20px, 0); } } /* Other stuff */ .content { font: 800 14.5em/1 'Open Sans', Impact; } svg { width: 100%; margin: -10% auto 100px; display: block; text-transform: uppercase; cursor: pointer; }"},{"title":"","date":"2019-03-28T12:47:47.703Z","updated":"2019-03-28T12:47:47.703Z","comments":true,"path":"voi/js/head.js","permalink":"http://riroaki.github.io/voi/js/head.js","excerpt":"","text":"const canvas = document.getElementById('head'); //å­˜å‚¨ç”»å¸ƒå®½é«˜ const H = canvas.height, W = canvas.width; const sqrt3 = Math.sqrt(3); //å­˜å‚¨å›¾å½¢ const NUM = 3; const graphs = []; // æ‰€æœ‰å›¾å½¢çš„å¤–æ¥åœ†åŠå¾„ const radius = H / 4; // ç»˜åˆ¶å›¾å½¢ getVOI(); let oTimer = null; clearInterval(oTimer); oTimer = setInterval(function () { //æ›´æ–°å°çƒè¿åŠ¨çŠ¶æ€ updateVOI(); //æ¸²æŸ“å°çƒ renderVOI(); }, 20); function getVOI() { let vx = Math.floor(Math.random() * 2 - 4), vy = Math.floor(Math.random() * 2 - 4); if (canvas.getContext) { for (let i = 0; i < NUM; i++) { const tempX = Math.floor(Math.random() * (W - radius) + radius); const tempY = Math.floor(Math.random() * (H - radius) + radius); vx += Math.floor(Math.random() - 2); vy += Math.floor(Math.random() - 2); const ball = { x: tempX, y: tempY, stepX: vx / 3, stepY: vy / 3, halfW: 0 }; graphs.push(ball); } graphs[0].halfW = radius * 2 / sqrt3; graphs[1].halfW = radius; graphs[2].halfW = radius / 2; } } function updateVOI() { for (let i = 0; i < graphs.length; i++) { graphs[i].x += graphs[i].stepX; graphs[i].y += graphs[i].stepY; bumpTest(graphs[i]); } } // ç¢°æ’æ£€æµ‹ function bumpTest(ele) { let w = ele.halfW; if (ele.x = W - w) { ele.x = W - w; ele.stepX = -ele.stepX; } if (ele.y = H - radius) { ele.y = H - radius; ele.stepY = -ele.stepY; } } function renderVOI() { //é‡ç½®ç”»å¸ƒé«˜åº¦ï¼Œè¾¾åˆ°æ¸…ç©ºç”»å¸ƒçš„æ•ˆæœ canvas.height = H; const color = 'rgb(' + 255 + ',' + 255 + ',' + 255 + ')'; if (canvas.getContext) { const ctx = canvas.getContext('2d'); // ç”» \"V\" ctx.beginPath(); let x0 = graphs[0].x - radius * 2 / sqrt3, y0 = graphs[0].y - radius; ctx.moveTo(x0, y0); ctx.lineTo(x0 + radius * 4 / sqrt3, y0); ctx.lineTo(graphs[0].x, y0 + radius * 2); ctx.lineTo(x0, y0); ctx.fillStyle = color; ctx.globalCompositeOperation = 'xor'; ctx.closePath(); ctx.fill(); // ç”» \"O\" ctx.beginPath(); ctx.arc(graphs[1].x, graphs[1].y, radius, 0, 2 * Math.PI); ctx.fillStyle = color; ctx.globalCompositeOperation = 'xor'; ctx.closePath(); ctx.fill(); // ç”» \"I\" ctx.beginPath(); let x = graphs[2].x - radius / 2, y = graphs[2].y - radius; ctx.moveTo(x, y); ctx.lineTo(x + radius, y); ctx.lineTo(x + radius, y + radius * 2); ctx.lineTo(x, y + radius * 2); ctx.lineTo(x, y); ctx.fillStyle = color; ctx.globalCompositeOperation = 'xor'; ctx.closePath(); ctx.fill(); } }"},{"title":"","date":"2019-03-28T12:22:57.177Z","updated":"2019-02-24T16:17:20.183Z","comments":true,"path":"voi/js/index.js","permalink":"http://riroaki.github.io/voi/js/index.js","excerpt":"","text":"// logoæ–‡å­—VOIæ¶ˆå¤± function hideLogo() { let svg = document.getElementById(\"svg\"), timer = null, alpha = 100; clearInterval(timer); // è®©VOIçš„logoæ¶ˆå¤± timer = setInterval(function () { if (alpha === 0) { clearInterval(timer); svg.style.display = \"none\"; showMenu(); } else { alpha -= 10; svg.style.opacity = alpha / 100; svg.style.filter = 'alpha(opacity:' + alpha + ')'; } }, 30); } // èœå•å‡ºç° function showMenu() { let menu = document.getElementById(\"menu\"), timer = null, alpha = 0; clearInterval(timer); // è®©èœå•å‡ºç° menu.style.display = \"block\"; menu.style.opacity = alpha / 100; timer = setInterval(function () { if (alpha === 100) { clearInterval(timer); } else { alpha += 10; menu.style.opacity = alpha / 100; menu.style.filter = 'alpha(opacity:' + alpha + ')'; } }, 30); } // è®¾ç½®é¡µé¢é‡å®šå‘é€»è¾‘ /** * @return {boolean} */ function IsPC() { const userAgentInfo = navigator.userAgent, Agents = [\"Android\", \"iPhone\", \"SymbianOS\", \"Windows Phone\", \"iPad\", \"iPod\"]; for (let v = 0; v < Agents.length; v++) if (userAgentInfo.indexOf(Agents[v]) > 0) return false; return true; } let isClicked = [0, 0, 0], links = ['play.html', 'contact.html', 'about.html']; function direct(dest) { let id = parseInt(dest); // å¦‚æœæ˜¯ç”µè„‘ï¼Œæ‚¬æµ®çš„æ—¶å€™æ–‡å­—å·²ç»æ”¾å¤§æ¸…æ™°ï¼Œåªéœ€è¦ç‚¹å‡»ä¸€æ¬¡ if (IsPC()) window.location.href = links[id]; else { // å¦‚æœæ˜¯æ‰‹æœºæ“ä½œï¼Œé‚£ä¹ˆç¬¬ä¸€æ¬¡ç‚¹å‡»æ”¾å¤§ï¼Œç¬¬äºŒæ¬¡å°±æ‰“å¼€é¡µé¢ for (let i = 0; i < isClicked.length; i++) { if (id !== i) isClicked[i] = 0; } if (++isClicked[id] === 2) { window.location.href = links[id]; isClicked[id] = 0; } } }"},{"title":"","date":"2019-03-28T12:36:45.864Z","updated":"2019-03-28T12:36:45.864Z","comments":true,"path":"voi/js/transition.js","permalink":"http://riroaki.github.io/voi/js/transition.js","excerpt":"","text":"const canvas = document.getElementById(\"head\"), ctx = canvas.getContext('2d'); const H = window.innerHeight, W = window.innerWidth, R = H / 20, diff = R / 20; let vertices = [], timer = null; for (let i = R / 2; i < W; i += R) { for (let j = R / 2; j < H; j += R) { vertices.push({ x: i, y: j, radius: 2 * R }); } } // console.log(vertices.length); clearInterval(timer); // å¼€åœºç‰¹æ•ˆï¼Œå±å¹•é»‘ç‚¹éå¸ƒï¼Œåº•è‰²ä¸ºç™½è‰² window.onload = function() { let dist = Math.floor(Math.sqrt((W / 2 - R / 2) ** 2 + (H / 2 - R / 2) ** 2)); timer = setInterval(function () { canvas.height = H; canvas.width = W; ctx.rect(0, 0, W, H); ctx.fillStyle = \"white\"; ctx.fill(); let continueDrawing = false; for (let i = 0; i < vertices.length; i++) { let currentDist = Math.floor(Math.sqrt((W / 2 - vertices[i].x) ** 2 + (H / 2 - vertices[i].y) ** 2)); if (dist 0) { ctx.beginPath(); ctx.arc(vertices[i].x, vertices[i].y, vertices[i].radius, 0, 2 * Math.PI); ctx.fillStyle = \"black\"; ctx.closePath(); ctx.fill(); continueDrawing = true; } } if (!continueDrawing) { clearInterval(timer); } dist -= R / 2; }, 20); }"}],"posts":[{"title":"å°é¸¡è¯å…¸ååçˆ¬äºŒä¸‰äº‹â€”â€”Jikipedia Crawler","slug":"Jikipedia-Crawler","date":"2019-07-08T14:28:17.000Z","updated":"2019-07-08T15:24:30.976Z","comments":true,"path":"Jikipedia-Crawler/","link":"","permalink":"http://riroaki.github.io/Jikipedia-Crawler/","excerpt":"","text":"è¯¾ç¨‹é¡¹ç›®åšä¸ªå‚ç›´æœç´¢å¼•æ“ï¼Œçˆ¬äº†ä¸€ä¸‹å°é¸¡è¯å…¸â€”â€”ä¸€ä¸ªå„ç§ç½‘ç»œçƒ­è¯çš„ç™¾ç§‘ï¼Œå¤§æ¦‚è¯æ¡æœ‰ä¸Šä¸‡ä¸ªå§ã€‚ æ²¡æƒ³åˆ°è¿™ä¸ªè¿‡ç¨‹è¿˜æŒºæ›²æŠ˜å¤æ‚çš„ï¼Œåœ¨è¿™é‡Œè®°å½•ä¸€ä¸‹è¿‡ç¨‹ç”¨åˆ°çš„å„ç§ååçˆ¬çš„æŠ€å·§ã€‚ ä¸»è¦ä½¿ç”¨pythonçš„Scrapyå’ŒSeleniumæ¡†æ¶ï¼Œä»£ç ï¼šhttps://github.com/Riroaki/Meme-Crawlerï¼Œé‡Œé¢è¿˜åŒ…æ‹¬ä¸€äº›å…¶ä»–çš„çˆ¬è™«ï¼ˆBç«™ã€å¾®åšç­‰ï¼‰ã€‚ ä»€ä¹ˆï¼Œè¿™æ ·ä¸€ä¸ªå°ç ´ç«™è¿˜ç©åçˆ¬ï¼Ÿä¸€å¼€å§‹æˆ‘çœ‹äº†ä¸€ä¸‹ç½‘é¡µç»“æ„ä¹Ÿä¸å¤æ‚ï¼Œé¡µé¢å°±ä¸€ç€‘å¸ƒæµï¼Œè¯æ¡ä¹Ÿå¾ˆè½»é‡çº§ã€‚ ç„¶åçœ‹äº†ä¸€ä¸‹urlï¼Œè¯æ¡æ˜¯æŒ‰åºå·æ’åˆ—çš„ï¼šhttps://jikipedia.com/definition/{id}è¿™æ ·ï¼Œidç›®æµ‹åœ¨0-10000ä¹‹é—´ã€‚ å¯æƒœæ²¡æ‰¾åˆ°è¯·æ±‚çš„APIï¼Œçœ‹æ¥åªèƒ½è§£æç½‘é¡µäº†ã€‚ å‘µå‘µï¼Œå°ç ´ç«™ä¼°è®¡å¾ˆå¿«å°±çˆ¬å®Œäº†ã€‚äºæ˜¯æˆ‘å¯åŠ¨Scrapyå°±å¼€å§‹æ’¸ä»£ç ã€‚ å‰æœŸæ€è·¯ æ„Ÿè§‰ç½‘é¡µä¿¡æ¯æŒºå°‘çš„ï¼Œå°±éœ€è¦è·å–ã€è¯æ¡åç§°+è¯æ¡æ–‡æœ¬+æµè§ˆç‚¹èµè¯„è®ºæ•°ç­‰ç­‰ã€‘ï¼Œæ‰“ç®—å…ˆå­˜åˆ°æ–‡æœ¬txtï¼Œå†æŒ‰éœ€æ”¾åˆ°æ•°æ®åº“ã€‚ ç”¨ä¸€ä¸ªå­—å…¸å­˜å·²ç»çˆ¬å–çš„idå’Œå¯¹åº”çš„è¯ï¼Œä¸ºäº†æ”¯æŒæ–­ç‚¹ç»­çˆ¬éœ€è¦ç”¨pickleå­˜åˆ°æ–‡ä»¶ï¼Œä¸‹æ¬¡çˆ¬å–çš„æ—¶å€™æ¢å¤ã€‚ æ²¡æƒ³å¤ªå¤šï¼Œidç”¨çš„æ˜¯çº¿æ€§å¢é•¿ï¼Œåˆ°10000çš„æ—¶å€™æˆªæ­¢ã€‚ å¯¹ç½‘é¡µå†…å®¹è§£æï¼Œæ­£åˆ™æå–å°±okäº† ã€‚å…·ä½“è§„åˆ™è¿˜è¯·çœ‹æºç jikipedia.pyã€‚ å½“ç„¶ï¼Œè¿™ä¸ªæ—¶å€™headersä¿¡æ¯è¯¥åšçš„ä¼ªè£…éƒ½åšäº†ï¼š # settings.py DEFAULT_REQUEST_HEADERS = { 'User-Agent': ('Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X)' ' AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0' ' Mobile/15A372 Safari/604.1'), 'Token': '81dca7415bd81f859fcdc968afd19be1d9015f01126142bb907181bd3dbd0098', 'Accept': 'application/json, text/plain, */*', } å†™çš„å·®ä¸å¤šäº†ï¼Œèµ°ä½ ã€‚çœ‹ç€æ•°æ®æ–‡ä»¶å¤¹ä¸‹æ–‡ä»¶æ•°è¹­è¹­ä¸Šæ¶¨ï¼Œæ„Ÿè§‰ç”šæ˜¯çˆ½å¿«â€”â€”ä»¿ä½›è‡ªå·±æŠŠè¿™ä¸ªç«™æ—¥äº†ä¸€éç„¶è€Œæˆ‘çš„æ„‰æ‚¦ç«‹åˆ»è¢«æ‰“æ–­äº†ï¼Œä»€ä¹ˆï¼Œè¢«shutdownäº†ï¼Ÿï¼Ÿ emmï¼Œæ‰“å¼€ç½‘é¡µåœ°å€ä¸€çœ‹ï¼š è¿™ä¹ˆæ½®çš„å—ï¼Œç»“æœè·³å‡ºä¸€ä¸ªéªŒè¯ç ã€‚è¿˜æ˜¯æ‹–åŠ¨æ‹¼å›¾å¼çš„â€¦â€¦å¥½å§æˆ‘æ€‚äº†ã€‚ ç»•é“é€šè¡Œå¥½å§ï¼Œå’±ä»¬æƒ³æƒ³è§£å†³æ–¹æ¡ˆï¼š é¦–å…ˆï¼Œå½“ç„¶æ˜¯ï¼š æ”¹UA çœ‹äº†ä¸€ä¸‹ç½‘ç«™çš„robots.txtï¼Œè²Œä¼¼å¯¹baidubotå’Œgooglebotæ˜¯æ¥è€…ä¸æ‹’å•Šã€‚ äºæ˜¯å°±å»æŠ„äº†ä¸€å †è¿™ä¸¤å®¶çš„UAï¼Œå¤§è‡´æ˜¯è¿™äº›ï¼š # settings.py # User-Agent to choose from UA_LIST = [ # Google-bot headers 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)', ('Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P)' ' AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.96' ' Mobile Safari/537.36 (compatible; Googlebot/2.1;' ' +http://www.google.com/bot.html)'), 'Googlebot/2.1 (+http://www.google.com/bot.html)', 'Mozilla/5.0 (compatible; Googlebot/2.1; http://www.google.com/bot.html)', # Baidu-bot headers ('Mozilla/5.0 (compatible; Baiduspider/2.0;' '+http://www.baidu.com/search/spider.htmlï¼‰'), ('Mozilla/5.0 (compatible;Baiduspider-render/2.0;' ' +http://www.baidu.com/search/spider.html)') ] å†åŠ ä¸€ä¸ªä¸­é—´ä»¶éšæœºé€‰å–ï¼Œä»£ç å¤§æ¦‚é•¿è¿™æ ·ï¼š # middlewares.py class RandomUserAgentMiddlware(object): \"\"\"Modify random user-agent each request.\"\"\" def __init__(self, _): super(RandomUserAgentMiddlware, self).__init__() @classmethod def from_crawler(cls, crawler): return cls(crawler) @staticmethod def process_request(request, spider): _ = spider # Use this to silent warning # Change User-Agent if len(UA_LIST) > 0: new_ua = random.choice(UA_LIST) request.headers['User-Agent'] = new_ua è®°å¾—æŠŠsettings.pyé‡Œé¢çš„ä¸­é—´ä»¶é…ç½®æ”¹æ‰ï¼š # settings.py DOWNLOADER_MIDDLEWARES = { 'MemeCrawler.middlewares.RandomUserAgentMiddlware': 543, 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None } ä¸‹è½½ç­‰å¾…æ„Ÿè§‰ä¸å¤ªæ”¾å¿ƒï¼ŒåŠ ç‚¹ç­‰å¾…æ—¶é—´å§ã€‚å’±ä»¬è¿™é‡Œçœ‹èµ·æ¥æ˜¯å›ºå®šç­‰å¾…ï¼Œå½“ç„¶Scrapyå†…éƒ¨è¿˜æ˜¯é‡‡ç”¨éšæœºç­‰å¾…çš„ï¼Œè¿™é‡Œçš„è®¾ç½®åªæ˜¯åŠ ä¸ªé™åˆ¶ã€‚ # settings.py # Configure a delay for requests for the same website (default: 0) # See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay # See also autothrottle settings and docs DOWNLOAD_DELAY = 3. å¥½ï¼Œç»§ç»­ã€‚ ç»“æœè¿™æ¬¡çˆ¬äº†ä¸€ä¼šï¼Œè¿ç»­åˆ°50ä¸ªçš„æ—¶å€™å°±å¾—å¼€ç½‘é¡µäººå·¥ç ´è§£ä¸€ä¸‹éªŒè¯ç ã€‚ æˆ‘å¯»æ€æ•ˆç‡è¿˜è¡Œå§ï¼Œå¶å°”æ‰“æ–­ä¸€ä¸‹æˆ‘çœ‹ç•ªçš„æ—¶é—´ã€‚ ç»“æœï¼Œå†åå¤è¿™æ ·ç©äº†3ï¼Œ4æ¬¡ä¹‹åï¼Œå½“æˆ‘åˆ’å¼€éªŒè¯ç è·³å‡ºæ¥çš„ä¸æ˜¯æˆåŠŸä»¥åæ¢å¤çš„ç•Œé¢ï¼Œè€Œæ˜¯â€¦â€¦ è¿™å°ç ´ç«™å¯çœŸä¼šç©ï¼Ÿï¼Ÿï¼Ÿä¸æ˜¯ï¼Œæˆ‘å¯»æ€è¿™ä¸ªç½‘ç«™ä¹Ÿä¸æ˜¯å¾ˆå¤§å§â€¦â€¦ å’‹åŠï¼Ÿéš¾é“è¿˜è¦æˆ‘ä¸åœåœ°æ¢ipï¼Œå¼€æ‰‹æœºçƒ­ç‚¹çˆ¬ï¼Œä¹°ä¸ªipæ± ï¼ˆç®—äº†ï¼Œæˆ‘ç©·ï¼‰ï¼Ÿ é“é«˜ä¸€å°ºï¼Œé­”é«˜ä¸€ä¸ˆï¼Ÿæƒ³äº†æƒ³å¯èƒ½è¿˜æ˜¯è¯·æ±‚çš„æ—¶å€™åªè¯·æ±‚ç½‘é¡µè€Œæ²¡æœ‰é¡ºå¸¦åœ°åŠ è½½cssæ ·å¼å’Œjsè„šæœ¬ï¼Œé‚£ä¹ˆç”¨æµè§ˆå™¨å¯èƒ½å¥½ç‚¹ã€‚ è¿™ä¹ˆä¸€è¯´ï¼Œé‚£Seleniumèµ°èµ·å•Šã€‚ åœ¨ç½‘ä¸Šæ‰¾äº†ä¸€äº›èµ„æ–™ï¼Œäºæ˜¯åŠ äº†ä¸€ä¸ªä¸‹è½½ä¸­é—´ä»¶ï¼ŒæŠŠåŸæ¥çš„requestæ‹¦æˆªåç”¨Seleniumè·å¾—responseå†è¿”å›ç»™spiderã€‚ åœ¨è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘åˆåŠ äº†ä¸€äº›å°trickï¼š åœ¨ç½‘é¡µåŠ è½½ä¸­å¢åŠ éšæœºç­‰å¾…ï¼ˆsleepå°±è¡Œï¼‰ï¼Œæ¨¡æ‹Ÿäººçš„é˜…è¯»è¿‡ç¨‹ åœ¨ç½‘é¡µåŠ è½½åéšæœºä¸‹åˆ’é¡µé¢ï¼Œæ¨¡æ‹Ÿäººçš„é˜…è¯»è¿‡ç¨‹ åœ¨ç½‘é¡µåŠ è½½åç‚¹å‡»æŸ¥çœ‹è¯„è®ºï¼Œç„¶åå†éšæœºç­‰å¾…ä¸€ä¼š åœ¨ç½‘é¡µåŠ è½½åéšæœºç‚¹èµï¼Œæˆ‘éƒ½ç‚¹èµäº†ï¼å¦‚æœè¿˜è§‰å¾—æˆ‘æ˜¯æœºå™¨äººï¼Œä½ æ˜¯ä¸æ˜¯ä¹Ÿå¤ªæ™ºèƒ½äº†ç‚¹ï¼Ÿ å¤§è‡´ä»£ç å¦‚ä¸‹ï¼š # middlewares.py class SeleniumMiddleware(object): \"\"\"Middleware of browsing pages by selenium.\"\"\" def __init__(self): driver = webdriver.Chrome(executable_path=DRIVER_PATH) # Set window size and position driver.set_window_position(0, 0) driver.set_window_size(1400, 1000) # Set timeout parameters driver.set_page_load_timeout(TIMEOUT) self.driver = driver self.wait = WebDriverWait(driver, timeout=TIMEOUT, poll_frequency=POLL_FREQUENCY) self.like_rate = 0.4 # Possibility of clicking `like` button logger.info('Selenium driver is starting...') def __del__(self): if self.driver is not None: self.driver.close() def process_request(self, request: scrapy.Request, spider: scrapy.Spider) -> HtmlResponse: _ = spider # Use this to silent warning try: self.driver.get(request.url) # Use random sleep sleep(random() * RANDOM_SLEEP_BASE) # 404 not found if self.driver.page_source.count('è¿™ä¸ªé¡µé¢æ‰¾ä¸åˆ°äº†') > 0: response = HtmlResponse(url=request.url, request=request, status=404) # 200 success # Moss CAPTCHA elif self.driver.page_source.count('hello moss') > 0: # You can try manually do the CAPTCHA sleep(10) # Jiki will be closed response = HtmlResponse(url=request.url, body=self.driver.page_source, request=request, encoding='utf-8', status=200) else: # Get item height card = self.wait.until( expected_conditions.presence_of_element_located( (By.CSS_SELECTOR, '.full-card'))) height = card.size['height'] # Scroll page scroll = ('var q=document.documentElement' '.scrollTop={};').format(height * random()) self.driver.execute_script(scroll) # Click comment button comment = self.wait.until( expected_conditions.element_to_be_clickable( (By.CSS_SELECTOR, '.comment'))) comment.click() # Randomly click like button if random() &lt; self.like_rate: like = self.wait.until( expected_conditions.element_to_be_clickable( (By.CSS_SELECTOR, '.like.button'))) like.click() # Form response response = HtmlResponse(url=request.url, body=self.driver.page_source, request=request, encoding='utf-8', status=200) except TimeoutException as e: logger.warning(e) response = HtmlResponse(url=request.url, request=request, status=500) except Exception as e: logger.warning(e) response = HtmlResponse(url=request.url, request=request, status=404) # Use random sleep after comments are shown sleep(random() * RANDOM_SLEEP_BASE) return response @classmethod def from_crawler(cls, crawler): _ = crawler # Use this line to silent warning return cls() å—¯ï¼Œè¿™æ ·æ•ˆæœå¥½å¤šäº†ã€‚ è¢«æŸ¥å°çš„æ¦‚ç‡å°äº†å¾ˆå¤šï¼Œç„¶è€Œâ€”â€”æ•ˆç‡ä¹Ÿè´¼ä½ã€‚ å¥½å§ï¼Œè‡³å°‘æˆ‘ç°åœ¨å¯ä»¥ä¸€è¾¹è‡ªå·±çœ‹ç€è¯æ¡ï¼Œä¸€è¾¹è®©å®ƒä¸€ç›´çˆ¬äº†ã€‚ å¥½åƒè¿˜æœ‰ç‚¹å¿«ä¹ï¼Ÿå“ˆå“ˆã€‚","categories":[{"name":"Web Crawler","slug":"Web-Crawler","permalink":"http://riroaki.github.io/categories/Web-Crawler/"}],"tags":[{"name":"scrapy","slug":"scrapy","permalink":"http://riroaki.github.io/tags/scrapy/"},{"name":"selenium","slug":"selenium","permalink":"http://riroaki.github.io/tags/selenium/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-08ï¼šKè¿‘é‚»","slug":"Machine-Learning-08-K-Nearest-Neighbor","date":"2019-07-07T16:00:00.000Z","updated":"2019-07-08T03:25:59.676Z","comments":true,"path":"Machine-Learning-08-K-Nearest-Neighbor/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-08-K-Nearest-Neighbor/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å…«ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†Kè¿‘é‚»ç®—æ³•çš„ç†è®ºå’Œå®ç°ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­è¿™ä¸€æ¬¡æˆ‘ä»¬ä»‹ç»çš„æ˜¯Kè¿‘é‚»ï¼ˆK Nearest Neighborï¼‰ç®—æ³•ï¼Œå®ƒå±äºæœ‰ç›‘ç£å­¦ä¹ ä¸­æ¯”è¾ƒç®€å•å’Œç›´è§‰çš„åˆ†ç±»ç®—æ³•ã€‚ å¤äººäº‘ï¼Œâ€œè¿‘æœ±è€…èµ¤ï¼Œè¿‘å¢¨è€…é»‘â€ï¼Œåˆæœ‰äº‘ï¼Œâ€œç‰©ä»¥ç±»èšï¼Œäººä»¥ç¾¤åˆ†â€ï¼Œå¤§æ„å°±æ˜¯è¯´æ€§è´¨ç›¸ä¼¼çš„äººå’Œäº‹å®¹æ˜“èšåœ¨ä¸€å—ã€‚ æ­£æ˜¯å› ä¸ºæœ‰ç›¸ä¼¼çš„ç‰¹å¾ï¼Œæ‰€ä»¥è¢«å½’ä¸ºä¸€ç±»ï¼Œè¿™åŒæ ·å¯ä»¥åº”ç”¨åœ¨åˆ†ç±»çš„æ€æƒ³ã€‚ äºæ˜¯å°±æœ‰äº†æˆ‘ä»¬çš„Kè¿‘é‚»ç®—æ³•ï¼Œå®ƒèƒ½å¤ŸæŠŠæ–°çš„æ ·æœ¬è¿…é€Ÿå½’ç±»åˆ°å’Œå®ƒæœ€ç›¸ä¼¼çš„é‚£äº›æ ·æœ¬é‡Œé¢å»ã€‚ Kè¿‘é‚»ç†è®ºæœ‰äº†åŸç†ï¼Œå…·ä½“æ“ä½œå°±æ˜¯é€‰å–Kä¸ªå’Œæ–°æ ·æœ¬æœ€è¿‘çš„æ ·æœ¬çš„ç±»åˆ«çš„ä¼—æ•°ä½œä¸ºæ–°æ ·æœ¬çš„ç±»ã€‚ æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ç»†åŒ–å®šä¹‰è¿™ä¸ªç®—æ³•ï¼š å¦‚ä½•å®šä¹‰æ ·æœ¬ä¹‹é—´çš„è·ç¦»è¿œè¿‘ï¼Ÿ å¦‚ä½•é€‰å–Kï¼Ÿ é¦–å…ˆå¾ˆç›´è§‰åœ°ï¼Œæˆ‘ä»¬é€‰å–æ¬§å¼è·ç¦»ä½œä¸ºè·ç¦»çš„è¡¡é‡æŒ‡æ ‡ï¼š$d(x_i,x_j)=||x_i-x_j||^2$ å¯¹äºKçš„é€‰å–ï¼Œæˆ‘ä»¬æ—¢ä¸èƒ½é€‰å¤ªå°‘ï¼Œä¹Ÿä¸èƒ½é€‰å¤ªå¤šï¼š å°‘äº†ï¼Œä¸è¶³ä»¥ä½œä¸ºå‚è€ƒï¼Œå¯èƒ½è¢«å¶ç„¶çš„å™ªå£°å½±å“ï¼Œæ ·æœ¬åˆ†ç±»å—æ‰°åŠ¨å½±å“å¤§ã€‚ å¤šäº†ï¼Œå¾’åŠ³å¢å¤§è®¡ç®—é‡ï¼Œè¿˜å®¹æ˜“æ”¶åˆ°å æ¯”æ¯”è¾ƒå¤šçš„æ ·æœ¬æ•°é‡å½±å“ã€‚ å½“ç„¶æ ·æœ¬ä¸å‡è¡¡çš„å½±å“åœ¨å“ªé‡Œéƒ½æœ‰ï¼Œåªæ˜¯è¿™é‡Œé—®é¢˜æ¯”è¾ƒæ˜æ˜¾ å¦å¤–ï¼Œåº”å½“é€‰å–Kä¸ºå¥‡æ•°ã€‚è¿™æ ·ä¸€æ¥å°±æœç»äº†æ¨¡æ£±ä¸¤å¯çš„å¯èƒ½æ€§â€”â€”å› ä¸ºä¸€å®šæœ‰ä¸€ä¸ªç±»æ ‡ç­¾æ˜¯å‡ºç°äº†æœ€å¤šæ¬¡çš„ã€‚ è‡³äºå…·ä½“é€‰æ‹©å°±è§ä»è§æ™ºï¼Œä¸€èˆ¬å¯ä»¥å¤šæ¬¡é€‰å–Kï¼Œæ‰¾åˆ°åˆ†ç±»é¢æ¯”è¾ƒå…‰æ»‘ï¼ˆå¯¹æ‰°åŠ¨å½±å“ä¸å¤§ï¼‰è€Œåˆ†ç±»å‡†ç¡®ç‡è¾ƒé«˜çš„é‚£ä¸ªå€¼ã€‚ ä»£ç å®ç°import numpy as np import scipy.stats from ._base import SupervisedModel class KNearest(SupervisedModel): \"\"\"K-Nearest-Neighbor model, multi-class classifier.\"\"\" def __init__(self): self.__data = None self.__label = None def fit(self, x: np.ndarray, label: np.ndarray, **kwargs) -> np.int: # Lazy training for knn, no computations self.__data = x self.__label = label class_count = len(np.unique(label)) return class_count def predict(self, x: np.ndarray, **kwargs) -> np.ndarray: assert self.__data is not None and self.__label is not None assert 'k' in kwargs and kwargs['k'] &lt; self.__data.shape[0] k = kwargs['k'] pred_label = np.zeros(x.shape[0]) for i, xi in enumerate(x): dist = np.power(self.__data - xi, 2).sum(axis=1) top_idx = np.argsort(dist)[: k] top_label = self.__label[top_idx] pred_label[i] = scipy.stats.mode(top_label)[0][0] return pred_label def evaluate(self, x: np.ndarray, label: np.ndarray, **kwargs) -> tuple: pred_label = self.predict(x, **kwargs) # Use 0-1 loss loss = np.count_nonzero(pred_label != label) precision = 1 - loss / x.shape[0] return precision, loss æœ‰æ•ˆå‚æ•°è¿™ä¸ªç®—æ³•å¾ˆç‰¹åˆ«ï¼Œå®ƒå®é™…ä¸Šä¸å­˜åœ¨â€œè®­ç»ƒâ€çš„è¿‡ç¨‹ï¼Œåªæ˜¯æŠŠæ‰€æœ‰çš„æ ·æœ¬ï¼Œä»¥åŠKä½œä¸ºå‚æ•°ã€‚ é‚£ä¹ˆç®—æ³•çš„å‚æ•°é‡å°±æ˜¯$N+1$å—ï¼Ÿå¥½åƒä¹Ÿä¸æ˜¯ã€‚ å¯¹äºæ¯”è¾ƒå°çš„Kï¼Œåˆ†ç±»é¢å¯ä»¥æå…¶å¤æ‚ï¼š è€Œæ¯”è¾ƒå¤§çš„Kä¼šä½¿å¾—åˆ†ç±»é¢æ¯”è¾ƒå…‰æ»‘ï¼š æˆ‘ä»¬çŸ¥é“ï¼Œåˆ†ç±»é¢è¶Šå¤æ‚éœ€è¦æè¿°å®ƒçš„å‚æ•°é‡è¶Šå¤§ã€‚ å¯ä»¥çœ‹å‡ºKçš„å¤§å°å’Œæ¨¡å‹å‚æ•°çš„å…³ç³»ï¼šKè¶Šå°ï¼Œå‚æ•°é‡è¶Šå¤šã€‚ äºæ˜¯ï¼Œåˆæ­¥åˆ¤æ–­æ¨¡å‹çš„å‚æ•°é‡ï¼ˆè¿™é‡Œï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ä¸ªæ¨¡ç³Šçš„è¯´æ³•ï¼Œå®é™…ä¸Šåº”è¯¥å«åšâ€œæœ‰æ•ˆå‚æ•°é‡â€ï¼‰$p=\\frac{N}{K}$ æœ‰æ•ˆå‚æ•°é‡ï¼ˆEffective number of parametersï¼‰çš„è¯æ˜åœ¨æ­¤çœç•¥ã€‚ äºæ˜¯æœ¬ä¸“æ æœ€çŸ­çš„ä¸€ç¯‡æ–‡ç« å°±å®Œæˆäº†ï¼šï¼‰","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-06ï¼šæ ¸æ–¹æ³•â€”â€”éçº¿æ€§SVM","slug":"Machine-Learning-06-Kernel-Method","date":"2019-06-30T16:00:00.000Z","updated":"2019-07-07T07:35:01.702Z","comments":true,"path":"Machine-Learning-06-Kernel-Method/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-06-Kernel-Method/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å…­ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ ¸æ–¹æ³•çš„åŸºæœ¬ç†è®ºã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­ä¸Šä¸€ç¯‡æ–‡ç« ä»‹ç»SVMï¼Œå¹¶æ€»ç»“äº†çº¿æ€§åˆ†ç±»å™¨çš„ç‰¹å¾ã€‚ ç°åœ¨æˆ‘ä»¬è¦æ¢ç©¶SVMçš„æé™â€”â€”æ˜¯å¦å¯ä»¥å¯¹éçº¿æ€§ä½†å¯åˆ†çš„æ•°æ®è¿›è¡Œåˆ†ç±»ï¼Ÿ ï¼ˆè¯´åˆ°æé™â€¦â€¦æˆ‘ä¸åšäººç±»äº†ï¼ŒJoJoï¼ï¼‰ æˆ‘ä»¬çœ‹ä¸€ä¸ªäºŒæ¬¡å¯åˆ†çš„é—®é¢˜ï¼š å¯¹ä¸Šé¢è¿™ä¸ªå›¾ï¼Œå½¢ä¼¼åœ†ç¯çš„ä¸¤ä¸ªç±»åˆ«çš„æ•°æ®åˆ†å¸ƒï¼Œæ˜¾ç„¶ä¸æ˜¯çº¿æ€§å¯åˆ†çš„ã€‚é‚£ä¹ˆæ‰€æœ‰çš„çº¿æ€§åˆ†ç±»å™¨ï¼ˆé€»è¾‘å›å½’ã€SVMï¼Œä»¥åŠä¹‹åä»‹ç»çš„Perceptronï¼‰éƒ½ä¼šå¤±æ•ˆã€‚ å¦‚æœæ‰‹åŠ¨åšçš„è¯ï¼Œæˆ‘ä»¬ä»¥å†…åœ†çš„åœ†å¿ƒä¸ºåŸç‚¹ï¼Œè§†æ¨ªåæ ‡ï¼Œçºµåæ ‡çš„è¡¨ç¤ºä¸º$[x_1,x_2]$ï¼Œæ‰¾åˆ°ä»‹äºä¸¤ä¸ªåœ†åŠå¾„ä¹‹é—´çš„é•¿åº¦$r$ï¼Œé‚£ä¹ˆæ»¡è¶³$x_1^2+x_2^2-r^2\\le0$ä¸º1ç±»ï¼Œåä¹‹åˆ™ä¸º2ç±»ï¼Œå¦‚æ­¤ä¾¿å¯å®ç°åŒºåˆ†ã€‚ å¯¹äºä¸€ä¸ªäºŒç»´çš„å¹³é¢ï¼Œæˆ‘ä»¬å£ç®—å°šå¯ä¸€æˆ˜ï¼›ç„¶è€Œå¯¹é—®é¢˜ç¨åšå˜æ¢ï¼Œæƒ…å†µåˆå¦‚ä½•å‘¢ï¼Ÿ è®¾æƒ³ä¸€ä¸ªæ˜ å°„å°†åŸå›¾æ”¾å…¥ä¸‰ç»´ç©ºé—´ï¼š è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•æå®šå‘¢ï¼Ÿæˆ–è€…æƒ…å†µä¸æ˜¯åœ†â€¦â€¦ è¿™æ—¶å€™æˆ‘ä»¬éœ€è¦å›è¿‡å¤´æŠŠæˆ‘ä»¬åœ¨äºŒç»´åšçš„äº‹æƒ…è¿›è¡Œæ³›åŒ–â€”â€”æ‰¾åˆ°æ›´ä¸ºä¸€èˆ¬å’Œé€šç”¨çš„å½¢å¼ï¼Œä»¥ä¸å˜åº”ä¸‡å˜å˜›ã€‚ æ³¨æ„åˆšæ‰çš„ä¸ç­‰å¼$x_1^2+x_2^2 - r^2$çš„å½¢å¼ï¼Œæœ¬è´¨è¿˜æ˜¯å¯ä»¥çœ‹ä½œä¸€ä¸ªçº¿æ€§ç»„åˆâ€”â€”å¦‚æœä»¤$z_0=1,z_1=x_1^2,z_2=x_2^2$é‚£ä¹ˆæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥ç”¨çº¿æ€§å¯åˆ†çš„åˆ†ç±»å™¨å»åˆ’åˆ†ï¼Œå­¦ä¹ å¾—åˆ°$w=[-r^2,1,1]^T$çš„å‚æ•°ä½¿å¾—æ•°æ®å¯ä»¥è¢«$w^Tz=$åˆ’åˆ†ã€‚ æœ¬è´¨ä¸Šï¼Œæˆ‘ä»¬åˆšæ‰åšäº†ä¸€æ¬¡åæ ‡å˜æ¢ï¼Œä»è€ŒæŠŠåŸæ¥ç±»çš„æ•°æ®è½¬æ¢åˆ°ä¸€ä¸ªç©ºé—´ï¼Œåœ¨é‚£ä¸ªç©ºé—´é‡Œå„ä¸ªç±»çš„åˆ†å¸ƒæ˜¯çº¿æ€§å¯åˆ†çš„ã€‚ æ›´ä¸ºä¸€èˆ¬çš„å½¢å¼æ˜¯åŒ…å«ä¸€æ¬¡é¡¹å’Œå…¶ä»–äºŒæ¬¡é¡¹çš„ï¼ˆæ¯•ç«Ÿä½ ä¸ä¼šæ€»æ˜¯å¯¹è¿™ç§åœ†è¿›è¡Œåˆ†ç±»ï¼Œåœ†å¿ƒä¹Ÿæœªå¿…åœ¨åŸç‚¹ï¼‰ï¼š å˜æ¢å‰ï¼š$x=[1,x_1,x_2,â€¦,x_n]$ å˜æ¢åï¼š$z=\\begin{bmatrix} 1&amp;x_1&amp;x_2&amp;â€¦&amp;x_n\\x_1&amp;x_1x_1&amp;x_1x_2&amp;â€¦&amp;x_1x_n\\â€¦\\x_n&amp;x_nx_1&amp;x_nx_2&amp;â€¦&amp;x_nx_n\\end{bmatrix}$ å°±è·å¾—äº†è¿™æ ·çš„æ–°åæ ‡ï¼Œè¿™ä¸ªæ–°åæ ‡çš„ç»´åº¦ä¸º$x_ix_j,i&amp;j\\in[0,n]$ï¼Œæ‰€ä»¥æ–°çš„åæ ‡æœ‰$((n+1)^2-(n+1))/2=\\frac{n(n+1)}{2}$ä¸ªä¸åŒçš„ç»´åº¦ã€‚ ç„¶åæˆ‘ä»¬å°†å˜æ¢åçš„åæ ‡å˜ä¸ºæ–°çš„$x$ï¼Œè¿™æ ·ä¸€æ¥è®­ç»ƒä¸€ä¸ª$w\\in \\R^{n(n+1)/2\\times1}$æ¥é¢„æµ‹ï¼Œå°±æŠŠé—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§çš„åˆ†ç±»å·¥ä½œã€‚ å…¶å®åœ¨ä¹‹å‰çº¿æ€§å›å½’è®²æ­£åˆ™åŒ–çš„æ—¶å€™å°±å·²ç»åšè¿‡ç±»ä¼¼çš„å·¥ä½œäº†ï¼Œåªä¸è¿‡é‚£ä¸ªæ—¶å€™çš„åæ ‡å˜æ¢æ˜¯ä¸€ä¸ªé¢„å¤„ç†çš„å·¥ä½œï¼Œå³æ”¹å˜æ•°æ®é›†çš„ç»´åº¦ï¼Œè€Œä¸æ˜¯æ¨¡å‹çš„å·¥ä½œã€‚ é‚£ä¹ˆç°åœ¨ï¼Œæˆ‘ä»¬å¦‚ä½•æŠŠè¿™ç§å˜æ¢åŠ å…¥çº¿æ€§çš„åˆ†ç±»å™¨ï¼Œè®©å®ƒèƒ½å¤Ÿè‡ªåŠ¨å¸®æˆ‘ä»¬æå®šéçº¿æ€§çš„æƒ…å†µå‘¢ï¼Ÿ æ ¸å‡½æ•°æˆ‘ä»¬æŠŠä¸Šé¢è¿™ç§ä»åŸfeatureåˆ°æ–°featureçš„æ˜ å°„å«åšæ ¸å‡½æ•°$\\kappa$ã€‚ å¯¹ä¸Šé¢çš„å˜æ¢ï¼Œæˆ‘ä»¬æœ‰$\\hat f(x)=w^Tx=\\Sigma_{i=1}^n\\alpha_ix_i^Tx=\\Sigma_{i=1}^n\\alpha_i\\kappa(x_i, x)$ ä»è€Œ$\\kappa(x_i,x)=x_i^Tx$ æŠŠå®ƒåº”ç”¨åœ¨SVMä¸­ï¼Œå¾—åˆ°æ–°çš„å…¬å¼ï¼š $y=sgn(w^Tx+b)=sgn(\\Sigma_{i=1}^n\\alpha_iy_i&lt;x_i,x&gt;+b), w=\\Sigma_{i=1}^n\\alpha_iy_ix_i$ åœ¨SVMä¸­ï¼Œå¯¹éæ”¯æŒå‘é‡çš„ç‚¹ï¼Œ$\\alpha_i$çš„å€¼ä¸º0ã€‚ æ ¸å‡½æ•°æ›´ä¸ºä¸€èˆ¬çš„å®šä¹‰æ˜¯ï¼š æ ¸å‡½æ•°æ˜¯ç”¨äºè¡¡é‡ä¸¤ä¸ªå¯¹è±¡$x,xâ€™$çš„ç›¸ä¼¼æ€§å…³ç³»çš„å‡½æ•°ï¼Œé€šå¸¸å®ƒæ˜¯ï¼š éè´Ÿçš„ï¼Œå³$\\kappa(x,xâ€™)\\ge0$ å¯¹ç§°çš„ï¼Œå³$\\kappa(x,xâ€™)=\\kappa(xâ€™,x)$ é€šå¸¸çš„æ ¸å‡½æ•°æœ‰å¦‚ä¸‹å‡ ç§ï¼š Linear kernel:$\\kappa(x,xâ€™)=x^Txâ€™$ Polynomial kernel:$\\kappa(x,xâ€™)=(x^Txâ€™+1)^d$ RBF kernel:$\\kappa(x,xâ€™)=exp(-\\frac{||x-xâ€™||^2}{2\\sigma^2})$ é€šè¿‡å¼•å…¥æ ¸å‡½æ•°ï¼Œæˆ‘ä»¬å°†åŸæ¥çš„çº¿æ€§SVMåˆ†ç±»å™¨æ¨å¹¿åˆ°äº†éçº¿æ€§çš„åˆ†ç±»ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰string kernelå’Œgraph kernelï¼Œè¿™ä¸¤ä¸ªæ ¸å‡½æ•°çš„ä½œç”¨ä¸æ˜¯æŠŠè¾“å…¥æŠ•å½±åˆ°æ–°çš„ç»´åº¦ä¸Šï¼Œè€Œæ˜¯å•çº¯è·å–ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç›¸ä¼¼ç¨‹åº¦ã€‚ ç¼ºé™·ä½¿ç”¨æ ¸æ–¹æ³•æ„å‘³ç€ä½ å·²ç»çŸ¥é“äº†æ•°æ®åˆ†å¸ƒçš„å¤§è‡´æƒ…å†µï¼ˆæ¯”å¦‚äºŒæ¬¡å‹ï¼‰ï¼Œä»è€Œèƒ½å¤Ÿé€‰å–æ ¸çš„å½¢å¼ã€‚ å¹¶ä¸æ˜¯ä¸€åŠ³æ°¸é€¸çš„æ–¹æ³•ã€‚å“ˆå“ˆï¼Œç…§è¿™ä¸ªç»“è®ºï¼Œæˆ‘å¯ä»¥è¯´â€œæœºå™¨å­¦ä¹ æ²¡æœ‰é“¶å¼¹â€å’¯ï¼Ÿ è¯´æ˜è¿™ä¸€ç« å†…å®¹å…¶å®æˆ‘ä¹Ÿä¸€çŸ¥åŠè§£ï¼Œå¯ä»¥çœ‹ä½œæ˜¯å¯¹SVMçš„ä¸€ç§è¡¥å……å§ï¼ˆç„¶è€Œå¹¶æ²¡æœ‰ä»£ç å®ç°ï¼‰ã€‚ ç­‰åˆ°æœ‰æ›´æ¸…æ¥šçš„è¯´æ³•æˆ‘ä¼šè¡¥å……ï¼Œæœ‰é—®é¢˜æˆ–è€…æ„è§å¯ä»¥åœ¨è¯„è®ºåŒºç•™è¨€ï¼Œå…±åŒè®¨è®ºã€‚","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-07ï¼šæ„ŸçŸ¥æœºä¸ç¥ç»ç½‘ç»œ","slug":"Machine-Learning-07-Perceptron-and-Neural-Network","date":"2019-06-30T16:00:00.000Z","updated":"2019-07-08T02:54:57.233Z","comments":true,"path":"Machine-Learning-07-Perceptron-and-Neural-Network/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-07-Perceptron-and-Neural-Network/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸ƒç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ„ŸçŸ¥æœºçš„è¯¦ç»†ç†è®ºå’Œå®ç°ï¼Œä»¥åŠæ„ŸçŸ¥æœºå‘æ·±åº¦å­¦ä¹ çš„æ¨å¹¿ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­è¿™åº”è¯¥æ˜¯æˆ‘ä»¬è¦ä»‹ç»çš„æœ€åä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨äº†ã€‚ è¿™ç©æ„æ˜¯60å¹´å‰æå‡ºçš„ï¼ˆFrank Rosenblattï¼Œ1957ï¼‰ï¼Œä¸€åº¦é£é¡è®¡ç®—æœºç§‘å­¦ç•Œã€‚ å½“æ—¶äººå·¥æ™ºèƒ½çš„æ¦‚å¿µå°±å¼€å§‹ğŸ”¥äº†ã€‚ä¸è¿‡è¿™è‚¡çƒ­æƒ…è¿…é€Ÿè¢«1969å¹´çš„ä¸€ç¯‡è®ºæ–‡æµ‡ç­ã€‚ é—®é¢˜åœ¨äºï¼Œè¿™ç©æ„æ ¹æœ¬å°±æ˜¯ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œæ²¡åŠæ³•æ‹Ÿåˆéçº¿æ€§çš„å‡½æ•°ï¼ˆè®ºæ–‡é‡Œç”¨å¼‚æˆ–è¿ç®—æ‰“è„¸ï¼Œä¹Ÿå°±æ˜¯è¯´å®ƒè¿å¼‚æˆ–éƒ½ä¸èƒ½æ‹Ÿåˆï¼‰ã€‚å¦å¤–ï¼Œç›¸å¯¹å½“æ—¶çš„è®¡ç®—èƒ½åŠ›ï¼Œè¿™ä¸ªç®—æ³•è¿˜æ˜¯å¤ªå¤æ‚ã€‚ äºæ˜¯è¿æ¥æ•°åå¹´çš„AIå¯’å†¬ï¼Œç›´åˆ°SVMçš„å‡ºç°å¸¦æ¥AIçš„å¤å…´â€”â€”åªä¸è¿‡Rosenblattæœ¬äººåœ¨1971å¹´æ„å¤–ç¦»ä¸–ï¼Œçœ‹ä¸åˆ°åæ¥çš„æ•…äº‹äº†ã€‚ å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ1970å¹´backpropagationçš„ç®—æ³•å°±å·²ç»æå‡ºäº†ï¼Œåªä¸è¿‡å½“æ—¶æ²¡æœ‰å¾—åˆ°æ³¨æ„ï¼Œç›´åˆ°1984å¹´è¢«é‡æ–°å‘æ˜ã€‚è¿™ä¸ªå¯æ˜¯ç°ä»£ç¥ç»ç½‘ç»œçš„åŸºçŸ³å•Šã€‚åªèƒ½è¯´ï¼Œå†å²æ€»æ˜¯èºæ—‹å¼ä¸Šå‡ã€æ›²æŠ˜å‘å±•çš„å§ã€‚ æ„ŸçŸ¥æœºç†è®ºæ„ŸçŸ¥æœºæ˜¯ä¸€ä¸ªçº¿æ€§äºŒåˆ†ç±»å™¨ã€‚å®ƒçš„ç®—æ³•å’Œä¹‹å‰çš„é€»è¾‘å›å½’ã€SVMç±»ä¼¼ï¼š $f(x)=w^Tx+b$ï¼Œ$f(x)\\ge0$è¡¨ç¤ºæ­£ç±»ï¼Œåä¹‹è¡¨ç¤ºè´Ÿç±»ã€‚ è€Œå®ƒçš„å­¦ä¹ è¿‡ç¨‹ï¼Œäº‹å®ä¸Šæœ‰ç‚¹åƒæ˜¯ä¸ªæ‹è„‘è¢‹çš„ç®—æ³•ï¼š å¯¹äº$x_i$å¦‚æœé¢„æµ‹æ­£ç¡®ï¼Œé‚£å°±ä¸åšå¤„ç†ï¼› å¦‚æœé¢„æµ‹é”™è¯¯ï¼Œé‚£å°±æ‰§è¡Œ$w_t=w_{t-1}+x_iy_i$çš„æ“ä½œã€‚ æˆ‘ä»¬å…ˆä»ç›´è§‚è§’åº¦ç†è§£ä¸€ä¸‹è¿™ä¸€æ“ä½œçš„åˆç†æ€§ï¼š $y_i=\\pm1$ï¼Œå¦‚æœé¢„æµ‹é”™è¯¯ï¼Œé‚£ä¹ˆ$w_{t-1}x_iy_i&lt;0$ï¼ˆé¢„æµ‹å’ŒçœŸå®å€¼å¼‚å·ï¼‰ å‡å¦‚æˆ‘ä»¬é‡æ–°é¢„æµ‹è¿™ä¸ªå€¼ï¼Œä¼šå‘ç°$w_t^Tx_i=(w_{t-1}^Tx_i+(x_iy_i)^Tx_i)=w_{t-1}^T+y_ix_i^Tx_i$ ç”±äº$x_i^Tx_i&gt;0$ï¼Œè¿™æ ·æ“ä½œç›¸å½“äºå¼•å…¥çœŸå®æ ‡ç­¾ä¿¡æ¯ï¼Œä½¿å¾—é¢„æµ‹ç»“æœå‘çœŸå®æƒ…å†µ$y_i$é è¿‘ã€‚ é‚£ä¹ˆæŒ‰ç…§ä¹‹å‰çš„æƒ¯ä¾‹ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªå½¢å¼åŒ–çš„æŸå¤±å‡½æ•°ï¼š æŸå¤±å‡½æ•°è¿™å°±æœ‰ç‚¹å…ˆå°„ç®­ï¼Œåç”»é¶å­çš„æ„Ÿè§‰ğŸ¯ã€‚ å®šä¹‰æŸå¤±å‡½æ•°ï¼š$J(w)=-\\Sigma_{i\\in I_M}w^Tx_iy_i$ ç»“åˆæ¢¯åº¦ä¸‹é™ç†è®ºï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºæ¢¯åº¦$\\nabla J=\\Sigma_{i\\in I_M}-x_iy_i$ æ‰€ä»¥$w_t=w_{t-1}+\\alpha(t)\\Sigma_{i\\in I_M}x_iy_i$ï¼Œä¸è¿‡ä¸€èˆ¬å°±è®©$\\alpha(t)=1$ã€‚ å¯¹äº$b$çš„æ¢¯åº¦å°±ä½¿ç”¨$b_t=b_{t-1}+\\Sigma_{i\\in I_M}y_i$ã€‚ è¿™æ ·æˆ‘ä»¬å°±å¾—åˆ°äº†æ„ŸçŸ¥æœºçš„æŸå¤±å‡½æ•°å’Œå‚æ•°ä¼°è®¡æ–¹æ³•ã€‚ å‚æ•°ä¼°è®¡æ„ŸçŸ¥æœºçš„å‚æ•°ä¼°è®¡å°±å¦‚ä¸Šæ–‡æ‰€è¿°ï¼š $w_t=w_{t-1}+\\Sigma_{i\\in I_M}x_iy_i$ $b_t=b_{t-1}+\\Sigma_{i\\in I_M}y_i$ è¿™æ ·ä¸€æ¥ï¼Œå²‚ä¸æ˜¯å¾ˆå®¹æ˜“ä¸æ”¶æ•›ï¼Ÿä¼šä¸ä¼šå› ä¸ºæ ·æœ¬çš„å€¼æ¯”è¾ƒå¤§ï¼Œåœ¨æ”¶æ•›çš„è¾¹ç¼˜åå¤æ¨ªè·³æŒ¯è¡ä¹‹ç±»çš„â€¦â€¦ ä¸è¿‡å·²ç»æœ‰å·¥ä½œè¯æ˜äº†å®ƒçš„æ”¶æ•›æ€§â€”â€”æˆ–è€…è¯´ï¼Œæ„ŸçŸ¥æœºå¯¹åˆ†ç±»å­˜åœ¨è¯¯å·®çš„ä¸Šç•Œã€‚è¿™é‡Œå°±ç›´æ¥è´´å›¾äº†ï¼š ä»£ç å®ç°ç»ˆäºåˆ°äº†ä¸‡ä¼—ç©ç›®çš„ä»£ç å®ç°ç¯èŠ‚ã€‚ æœ¬æ¬¡ä»£ç ä¸å¤šè¯´ï¼Œå’Œçº¿æ€§å›å½’ç±»ä¼¼ã€‚æœ‰é—®é¢˜è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚ class Perceptron(LinearModel): \"\"\"Perceptron model, binary classifier.\"\"\" def __init__(self): super().__init__() def fit(self, x: np.ndarray, label: np.ndarray, **kwargs) -> np.float: assert np.array_equal(np.unique(label), np.array([-1, 1])) assert x.shape[0] == label.shape[0] n, p = x.shape if self._w is None or self._b is None or self._w.shape[0] != p: # Initialize weights using random values self._init_model(p) if kwargs is not None: # Update parameters of training self._update_params(kwargs) iters, loss = 0, 0. # Iterates till converge or iterating times exceed bound while iters &lt; self._iter_bound: iters += 1 # Update weights using mini-batch gradient desent for batch_x, batch_label in batch(x, label, self._batch_size): pred_val = self._predict_value(batch_x, self._w, self._b) loss += self._loss(pred_val, batch_label) * batch_x.shape[0] pred_label = self._predict_label(pred_val) grad_w, grad_b = self._grad(batch_x, pred_label, batch_label) self._w -= grad_w self._b -= grad_b loss /= x.shape[0] # Break if model converges. if loss &lt;= self._loss_tol: break self._update_model(loss) return loss def predict(self, x: np.ndarray, **kwargs) -> np.ndarray: assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) pred_label = self._predict_label(pred_val) return pred_label def evaluate(self, x: np.ndarray, label: np.ndarray, **kwargs) -> tuple: assert x.shape[0] == label.shape[0] assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) pred_label = self._predict_label(pred_val) precision = 1 - np.count_nonzero(pred_label - label) / x.shape[0] loss = self._loss(pred_val, label) return precision, loss @staticmethod def _predict_value(x: np.ndarray, w: np.ndarray, b: np.float) -> np.ndarray: pred_val = np.matmul(x, w) + b return pred_val @staticmethod def _predict_label(pred_val: np.ndarray) -> np.ndarray: pred_label = np.sign(pred_val) pred_label[pred_label == 0] = 1 return pred_label @staticmethod def _loss(pred_val: np.ndarray, true_label: np.ndarray) -> np.float: loss = -np.float(np.sum(pred_val * true_label)) / true_label.shape[0] return loss def _grad(self, x: np.ndarray, pred_label: np.ndarray, true_label: np.ndarray) -> tuple: grad_w = -(true_label.reshape((-1, 1)) * x)[pred_label != true_label] grad_b = -true_label[pred_label != true_label] grad_w = grad_w.sum(axis=0) / x.shape[0] grad_b = grad_b.sum() / x.shape[0] return grad_w, grad_b ç¥ç»ç½‘ç»œå…¶å®ä¸Šæ–‡æåˆ°çš„å¼‚æˆ–è¿ç®—å¯ä»¥ç”¨å¤šå±‚çš„æ„ŸçŸ¥æœºç»„åˆè§£å†³ï¼Œå¦‚ä¸‹æ˜¯ä¸€ç§å¼‚æˆ–æ¨¡å‹ï¼š åœ¨è¿™ä¸ªå›¾ä¸­ï¼Œæ¯ä¸€ä¸ªåœ†éƒ½æ˜¯ä¸€ä¸ªç¥ç»å…ƒï¼Œè¿™é‡Œæœ‰è¾“å…¥ç¥ç»å…ƒå’Œæ„ŸçŸ¥æœºç¥ç»å…ƒä¹‹åˆ†ã€‚ åˆä»£çš„ç¥ç»ç½‘ç»œå°±æ˜¯é€šè¿‡æ„ŸçŸ¥æœºç»„åˆå¾—åˆ°çš„ã€‚ ç„¶è€Œâ€¦â€¦æ€ä¹ˆå¾—åˆ°è¿™ä¹ˆä¸€ä¸ªæ¨¡å‹å‘¢ï¼Ÿæ€»ä¸èƒ½å¯¹æ¯ä¸€ä¸ªé—®é¢˜ï¼Œéƒ½äººå·¥å»å‡‘å‡ºä¸€ä¸ªæ¨¡å‹å§ï¼Ÿ ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥åå‘ä¼ æ’­ï¼ˆBackpropagationï¼‰ç®—æ³•ã€‚ åå‘ä¼ æ’­åå‘ä¼ æ’­ï¼Œå…¶å®å°±æ˜¯æ¢¯åº¦ä¸‹é™ç»“åˆæ±‚å¯¼çš„é“¾å¼æ³•åˆ™ï¼Œå¯¹ç½‘ç»œçš„æ¯ä¸€å±‚è¿›è¡Œæ¢¯åº¦ä¸‹é™çš„å‚æ•°ä¼°è®¡ã€‚ æ¯”å¦‚è¯´ï¼Œä¸€ä¸ªç¥ç»ç½‘ç»œçš„ç»“æ„æ˜¯$p_1(in)=out_1,p_2(out_1)=out_2,p_3(out_2)-&gt;out_3$ï¼ˆè™½ç„¶ä¸å¯èƒ½æ˜¯å•é“¾æ¡è¿™ä¹ˆç®€å•ï¼Œä½†æ˜¯è¶³å¤Ÿè¯´æ˜é—®é¢˜ï¼‰ï¼Œå¦‚æœè¯´æŸå¤±å‡½æ•°æ˜¯$J(out_3)$ï¼Œé‚£ä¹ˆå¯¹ä¸‰ä¸ªç¥ç»å…ƒï¼ˆæ„ŸçŸ¥æœºï¼‰çš„æ¢¯åº¦åˆ†åˆ«æ˜¯ï¼š å¯¹3å·æ„ŸçŸ¥æœºï¼š$\\frac{\\partial J}{\\partial w_3}=\\frac{\\partial J}{\\partial out_3}\\frac{\\partial out_3}{\\partial w_3}$ 2å·ï¼š$\\frac{\\partial J}{\\partial w_2}=\\frac{\\partial J}{\\partial out_3}\\frac{\\partial out_3}{\\partial w_2}=\\frac{\\partial J}{\\partial out_3}w_3\\frac{\\partial out_2}{\\partial w_2}$ 1å·ï¼š$\\frac{\\partial J}{\\partial w_1}=\\frac{\\partial J}{\\partial out_3}\\frac{\\partial out_3}{\\partial out_2}\\frac{\\partial out_2}{\\partial out_1}\\frac{\\partial out_1}{\\partial w_1}=\\frac{\\partial J}{\\partial out_3}w_3w_2\\frac{\\partial out_1}{\\partial w_1}$ ç»“æœä¸ä¸€å®šå‡†ç¡®ï¼Œä½†æ˜¯è¿‡ç¨‹å°±æ˜¯è¿™ä¸ªæ ·å­ã€‚ å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ˜¯ç›¸å¯¹çš„æ¦‚å¿µï¼Œå‰å‘è¡¨ç¤ºä»è¾“å…¥å±‚å±‚æ¨è¿›åˆ°è¾“å‡ºç»“æœçš„è¿‡ç¨‹ï¼Œåå‘å°±æ˜¯å‚æ•°ä¼°è®¡çš„è¿‡ç¨‹ã€‚ ç„¶åï¼Œä¸ºäº†æ‘†è„±æ„ŸçŸ¥æœºçš„çº¿æ€§æ€§ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªéçº¿æ€§çš„æ¿€æ´»å‡½æ•°ï¼Œæ¯”å¦‚$sigmoid$ï¼Œ$ReLU$ç­‰ç­‰ã€‚äºæ˜¯å°±å˜æˆäº†æ·±åº¦å­¦ä¹ çš„æ¨¡å‹ï¼š æ·±åº¦å­¦ä¹ ç”¨ä¸€ä¸ªå›¾æ¥è¯´æ˜æ·±åº¦å­¦ä¹ çš„ç½‘ç»œç»“æ„ä¸å®ƒçš„åå‘ä¼ æ’­ç®—æ³•ï¼š æ¯”èµ·æœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ çš„ä¸€å¤§ä¼˜åŠ¿åœ¨äºä¸å¤ªéœ€è¦å‰æœŸçš„ç‰¹å¾å·¥ç¨‹ã€‚ åœ¨æœºå™¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è§‚å¯Ÿæ•°æ®ï¼Œé€‰å–åˆé€‚çš„åˆ†ç±»å™¨ï¼ˆé€»è¾‘å›å½’ã€SVMã€è´å¶æ–¯ç­‰ç­‰ï¼‰ï¼Œå¹¶ä¸”æœ€é‡è¦çš„æ˜¯ï¼šæå–å‡ºä¸€äº›æœ‰æ•ˆåˆ†ç±»çš„featureï¼Œå¹¶è¿›è¡Œéçº¿æ€§çš„å˜æ¢ã€é™ç»´ã€å‡ç»´ç­‰ç­‰æ“ä½œã€‚è¿™ä¸€ä¸ªå¤æ‚çš„è¿‡ç¨‹å°±æ˜¯ç‰¹å¾å·¥ç¨‹ï¼Œæ˜¯ä¸€ä¸ªéå¸¸ä¾èµ–ç»éªŒå’ŒäººåŠ›çš„æ´»ã€‚ åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œæƒ³è¦è·å¾—ä¸€ä¸ªå¥½çš„ç»“æœï¼Œå¥½çš„ç‰¹å¾æ¯”æ¨¡å‹è®¾è®¡ã€è®­ç»ƒè¿‡ç¨‹ç­‰ç­‰éƒ½è¦é‡è¦ã€‚ è€Œæ·±åº¦å­¦ä¹ ï¼Œä½ åªéœ€è¦æŠŠæ•°æ®å–‚è¿›å»ï¼Œé€‰å¥½ç½‘ç»œç»“æ„ï¼Œå‰©ä¸‹æ¥çš„äº‹æƒ…äº¤ç»™æ¨¡å‹è‡ªå·±å»å­¦å§â€”â€”è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆå®ƒçš„è§£é‡Šæ€§å·®ï¼Œæ¨¡å‹é åå‘ä¼ æ’­å­¦å‡ºæ¥çš„ä¸œè¥¿èƒ½ç”¨ä»€ä¹ˆé€»è¾‘è§£é‡Šå—ï¼Ÿ å‡è®¾ç©ºé—´å›åˆ°ä¸€å¼€å§‹çš„æ¦‚å¿µï¼Œæ·±åº¦å­¦ä¹ æœ€å¤§çš„ä¼˜åŠ¿åœ¨äºå®ƒå¹¿é˜”çš„å‡è®¾ç©ºé—´ã€‚ æœ‰è¯æ˜æŒ‡å‡ºï¼Œä»…éœ€è¦åƒä¸Šå›¾ä¸€æ ·çš„ä¸‰å±‚ç½‘ç»œï¼ˆè¾“å…¥ã€éšå«å±‚ã€è¾“å‡ºï¼‰ï¼Œå°±å¯ä»¥æ‹Ÿåˆä»»æ„ï¼ˆarbitraryï¼‰çš„å‡½æ•°ã€‚ è¿™è¿˜æ˜¯åœ¨å‡è®¾ä½¿ç”¨åŒä¸€ä¸ªæ¿€æ´»å‡½æ•°çš„å‰æä¸‹ï¼š ç”¨å½¢å¼åŒ–çš„è¯­è¨€æè¿°ï¼Œå°±æ˜¯è¯´ï¼š Any continuous function from input to output can be implemented in a threeâ€layer net, given sufficient number of hidden units $n_H$, proper nonlinearities, and weights. è¿™æ˜¯ç”±A. Kolmogorovè¯æ˜çš„ï¼Œæœ‰å…´è¶£å¯ä»¥è‡ªè¡Œäº†è§£ï½ è¦ç´ ç¥ç»ç½‘ç»œçš„ä¸‰è¦ç´ æœ‰ï¼š ç½‘ç»œç»“æ„ï¼ˆnet topologyï¼‰ï¼ˆå…¨è¿æ¥å±‚ã€æ± åŒ–å±‚ç­‰ç­‰ç»„æˆçš„å±‚æ¬¡ç»“æ„ï¼‰ èŠ‚ç‚¹æ€§è´¨ï¼ˆprocessor characteristicsï¼‰ï¼ˆä¸€èˆ¬èŠ‚ç‚¹éƒ½æ˜¯çº¿æ€§å•å…ƒï¼Œè¿™é‡Œçš„æ€§è´¨ä¸»è¦æ˜¯æ¿€æ´»å‡½æ•°çš„é€‰å–ï¼‰ è®­ç»ƒæ³•åˆ™ï¼ˆtraining rulesï¼‰ï¼ˆä¸€èˆ¬ç‰¹æŒ‡åå‘ä¼ æ’­çš„è®¡ç®—æ³•åˆ™ï¼‰ å¸¸è§çš„ç¥ç»ç½‘ç»œæœ‰CNNã€RNNã€LSTMç­‰ã€‚ å…³äºç¥ç»ç½‘ç»œçš„å†…å®¹ï¼Œåœ¨ç»“æŸæœºå™¨å­¦ä¹ éƒ¨åˆ†åä¼šæ›´æ–°ï¼Œè¯·æ‹­ç›®ä»¥å¾…ã€‚","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-05ï¼šæ”¯æŒå‘é‡æœº","slug":"Machine-Learning-05-Support-Vector-Machine","date":"2019-06-25T04:00:00.000Z","updated":"2019-07-02T16:44:31.425Z","comments":true,"path":"Machine-Learning-05-Support-Vector-Machine/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-05-Support-Vector-Machine/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬äº”ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†æ”¯æŒå‘é‡æœºçš„è¯¦ç»†ç†è®ºå’Œå®ç°ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­ä¸Šä¸€ç¯‡å†…å®¹ä¸­ä»‹ç»äº†é€»è¾‘å›å½’çš„å†…å®¹ï¼Œå¹¶ä»¥æ­¤å±•ç¤ºäº†çº¿æ€§åˆ†ç±»å™¨æœ€åŸºæœ¬çš„å½¢å¼ã€‚ æœ¬æ–‡ä»‹ç»çš„æ”¯æŒå‘é‡æœºä¹Ÿæ˜¯ä¸€ç§çº¿æ€§åˆ†ç±»å™¨ï¼Œåªä¸è¿‡è·å¾—æ¨¡å‹çš„æ–¹å¼æœ‰æ‰€ä¸åŒã€‚ ä½œä¸ºå¤ä¹ ï¼Œæˆ‘ä»¬é‡æ–°å›é¡¾ä¸€ä¸‹é€»è¾‘å›å½’çš„åˆ†ç±»æ–¹å¼ï¼š $y=a^Tx$ï¼Œåœ¨$y&gt;0$çš„æ—¶å€™è¢«æŠ•å½±åˆ°åŒºé—´$(0.5,1)$ï¼Œæ‰€ä»¥åˆ†ç±»ä¸ºæ­£ç±»ï¼› åœ¨$y&lt;0$çš„æ—¶å€™è¢«æŠ•å½±åˆ°åŒºé—´$(0,0.5)$æ‰€ä»¥åˆ†ç±»ä¸ºè´Ÿç±»ã€‚ $a$è¢«ç§°ä¸ºåˆ†å‰²å‘é‡ï¼Œæˆ–è€…è§£å‘é‡ï¼Œè€Œæ¯ä¸€ä¸ªåˆ†ç±»å‘é‡éƒ½å¯¹åº”ç€ä¸€ä¸ªåˆ†ç±»å¹³é¢ï¼ŒæŠŠæŠ•å½±åˆ°ç©ºé—´ä¸­çš„æ‰€æœ‰ç‚¹$X_i$åˆ†ä¸ºä¸¤ç±»ã€‚ ä¸‹å›¾ç”¨äºè§£é‡Šåˆ†ç±»å¹³é¢ä¸å‚æ•°$a$ï¼ˆ$a=[w,b]$ï¼‰çš„å…³ç³»ï¼š é‚£ä¹ˆï¼Œè¿™ä¸ªå‘é‡æ˜¯å”¯ä¸€çš„å—ï¼Ÿ ç­”æ¡ˆæ˜¯ï¼Œåœ¨æœ‰é™ä¸”çº¿æ€§å¯åˆ†çš„æ•°æ®é›†ä¸Šï¼Œä¸€èˆ¬æ˜¯å­˜åœ¨æ— æ•°å¯è¡Œçš„åˆ†ç±»é¢/åˆ†ç±»å‘é‡çš„ï¼Œå¦‚ä¸‹å›¾ï¼š é‚£ä¹ˆå¾ˆè‡ªç„¶çš„æˆ‘ä»¬å°±ä¼šæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæ€æ ·åˆ†ç±»æ‰æ˜¯æœ€ä¼˜çš„å‘¢ï¼Ÿ è¿™ä¸ªæœ€ä¼˜çš„å¹³é¢ï¼Œç†åº”æ˜¯èƒ½å¤Ÿå¸®åŠ©æˆ‘ä»¬åœ¨æµ‹è¯•æ•°æ®ä¸Šæœ‰æœ€å¥½çš„åˆ†ç±»æ•ˆæœçš„ï¼š ç›´è§‰ä¸Šæ¥çœ‹ï¼Œè¿™ä¸ªåˆ†ç±»é¢ä¸åº”è¯¥è¿‡äºé è¿‘æŸä¸€ç±»ç‚¹ï¼ˆæˆ–è€…ç”šè‡³æ’å…¥äº†åŒä¸€ç±»ç‚¹ä¹‹é—´ï¼‰ï¼Œè€Œæ˜¯è®©ä¸¤ç±»ç‚¹å°½é‡ç¦»åˆ†ç±»å¹³é¢è¾ƒè¿œã€‚å› ä¸ºè·ç¦»è¿‘è¡¨ç¤ºæ¥è¿‘è¾¹ç•Œï¼Œé‚£ä¹ˆè¿™äº›ç‚¹æ˜¯æœ€å®¹æ˜“è¢«è¯¯åˆ†ç±»çš„ï¼Œæˆ‘ä»¬å¸Œæœ›è¿™æ ·çš„ç‚¹è¶Šå°‘è¶Šå¥½â€”â€”ä¹Ÿå°±æ˜¯ï¼Œå¸Œæœ›æˆ‘ä»¬çš„åˆ†ç±»å™¨çš„åˆ†ç±»ç»“æœéƒ½æ˜¯æç«¯ä¸€ç‚¹ï¼Œæ¨¡æ£±ä¸¤å¯çš„ç»“æœå°½é‡å°‘ä¸€äº›ã€‚ æ¢å¥è¯è¯´ï¼Œæ¯ä¸€ä¸ªç‚¹åˆ°è¶…å¹³é¢çš„è·ç¦»éƒ½åº”å½“å°½é‡çš„å¤§ï¼Œåº”å¯¹æ–°æ•°æ®ç†åº”æœ‰å¥½çš„è¡¨ç°ã€‚ è€Œäº‹å®ä¸Šè¶…å¹³é¢ç¨å¾®æ”¹å˜ï¼Œå½±å“çš„ä¸»è¦æ˜¯å’Œå¹³é¢è¿‘é‚»çš„ç‚¹ï¼Œæ‰€ä»¥æˆ‘ä»¬å®šä¹‰æ¦‚å¿µï¼š Marginï¼šåˆ†ç±»å¹³é¢åˆ°ç‚¹é›†çš„æœ€å°è·ç¦»ã€‚ ç”¨æ•°å­¦åŒ–çš„è¯­è¨€æè¿°ï¼Œæˆ‘ä»¬æ‰€è¿½æ±‚çš„ç›®æ ‡å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªåˆ†ç±»é¢å¯ä»¥æœ€å¤§åŒ–marginã€‚ ç­”æ¡ˆå·²ç»å‘¼ä¹‹æ¬²å‡ºäº†ï¼Œé‚£å°±æ˜¯ä»Šå¤©çš„ä¸»è§’â€”â€”æ”¯æŒå‘é‡æœºï¼ˆSupport Vector Machineï¼‰ã€‚ æ”¯æŒå‘é‡æœºç†è®ºé¦–å…ˆå¤ä¹ ä¸€ä¸‹ç‚¹åˆ°å¹³é¢è·ç¦»å…¬å¼ï¼š å¯¹å¹³é¢$C:y=a_0+a_1x_1+a_2x_2+â€¦+a_nx_n$ï¼Œä»»æ„ä¸€ä¸ªç‚¹$x=[x_1,x_2,â€¦,x_n]$åˆ°å¹³é¢çš„è·ç¦»ä¸ºï¼š $d=\\frac{|a_0+a_1x_1+a_2x_2+â€¦+a_nx_n|}{\\sqrt{a_0^2+a_1^2+a_2^2+â€¦+a_n^2}}=\\frac{|y(x)|}{||a||_2-a_0^2}$ å› è€Œï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°çš„ç”±$a$å†³å®šçš„åˆ†ç±»å¹³é¢åº”å½“æ˜¯ï¼š $w,b=\\arg \\max \\min \\frac{|w^Tx+b|}{||w||_2}$ åŒæ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›å®ƒæ˜¯åˆ†ç±»æ­£ç¡®çš„ã€‚è™½ç„¶è·ç¦»è¶³å¤Ÿå¤§ï¼Œä½†æ˜¯ä¸ä¿è¯åˆ†ç±»æ­£ç¡®é‚£ä¸å°±æœ¬æœ«å€’ç½®äº†å—ï¼ æ‰€ä»¥åœ¨è¿™ä¸ªè¡¨è¾¾å¼ä¸­åŠ å…¥åˆ†ç±»çš„ä¿¡æ¯ï¼š $w,b=\\arg \\max \\min \\frac{y_i(w^Tx_i+b)}{||w||_2}$ è¿™é‡Œçš„$y_i\\in {-1,1}$ï¼Œè¡¨ç¤ºæ­£ç±»å’Œè´Ÿç±»ã€‚ç”±æ­¤å¯è§SVMä¹Ÿæ˜¯ä¸€ç§äºŒåˆ†ç±»ç®—æ³•ã€‚ è§‚å¯Ÿè¿™ä¸ªè¡¨è¾¾å¼ï¼Œå¦‚æœåˆ†ç±»æ­£ç¡®ï¼Œé‚£ä¹ˆ$w^Tx_i+b$å’Œ$y_i$åº”è¯¥æ˜¯åŒå·çš„ï¼Œåä¹‹æ˜¯å¼‚å·ã€‚ å› è€Œè¿™ä¸ªè¡¨è¾¾å¼æ˜¯åˆç†çš„ï¼Œå®ƒåŒæ—¶åŒ…å«äº†â€œåˆ†ç±»æ­£ç¡®â€å’Œâ€œç‚¹åˆ°å¹³é¢è·ç¦»æœ€å¤§â€çš„ç›®æ ‡ã€‚ å˜æ¢å¦‚æœè¯´åˆ°æ­¤ä¸ºæ­¢ï¼Œé‚£å°±å¤ªç®€å•äº†ï¼Œç„¶è€Œæ”¯æŒå‘é‡æœºè¿™åå­—è¿˜æ²¡å‡ºæ¥å‘¢ï¼ æ¥ç€æ¨å‘—ã€‚ å›åˆ°ä¸Šé¢è¿™ä¸ªå¼å­ï¼šæœ€å¤§åŒ–$\\frac{y_i(w^Tx_i+b)}{||w||_2}$ï¼Œæ˜¯ä¸æ˜¯å•çº¯æœ€å¤§åŒ–åˆ†å­&amp;æœ€å°åŒ–åˆ†æ¯å°±å¯ä»¥äº†ï¼Ÿ å½“ç„¶ä¸æ˜¯ã€‚å› ä¸ºä¸Šä¸‹éƒ½æœ‰$w$è¿™ä¸€é¡¹ã€‚ ä½†æ˜¯æ³¨æ„åˆ°$a$å†³å®šäº†å¹³é¢ä¹‹åï¼Œç­‰æ¯”ä¾‹åœ°ç¼©æ”¾$a$ä¸ä¼šæ”¹å˜å¹³é¢ï¼Œä½†æ˜¯å´æ”¹å˜äº†åˆ†å­åˆ†æ¯çš„å€¼ï¼Œå¯¹æˆ‘ä»¬çš„è®¡ç®—å¸¦æ¥å›°æ‰°ã€‚æˆ‘ä»¬å½“ç„¶å¸Œæœ›æ§åˆ¶çš„å˜é‡è¶Šå°‘è¶Šå¥½ï¼Œå¸Œæœ›åˆ†å­å’Œåˆ†æ¯ä¸è¦å­˜åœ¨å…³è”ï¼Œè¿™æ ·æˆ‘ä»¬åªéœ€è¦è€ƒè™‘ä¸€è¾¹å°±å¯ä»¥ã€‚ æ‰€ä»¥æˆ‘ä»¬ä»¤$y_i(w^Tx_i+b)=1$ï¼Œè¿™æ ·é—®é¢˜å°±è½¬å˜ä¸ºæ±‚$\\frac{1}{||w||_2}$çš„æœ€å¤§å€¼ï¼Œä¹Ÿå°±æ˜¯æ±‚$||w||_2$çš„æœ€å°å€¼ã€‚ ç¨å¾®ä¿®æ•´è¡¨è¾¾ï¼Œé—®é¢˜è¢«æ”¹å†™ä¸ºï¼š $\\min\\frac{1}{2}||w||_2^2$ $s.t. y_i(w^Tx_i+b)\\ge1$ å¹³æ–¹å’Œç³»æ•°$\\frac{1}{2}$æ˜¯ä¸ºäº†æ±‚å¯¼æ–¹ä¾¿å’Œå¯¼æ•°å½¢å¼æ‰€ç¡®å®šçš„ï¼Œä¸ä¼šå¯¹ç»“æœæœ‰å½±å“ã€‚ æ”¯æŒå‘é‡è¯´äº†è¿™ä¹ˆå¤šï¼Œæ”¯æŒå‘é‡åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ ç¨å¾®æŠ½è±¡åŒ–åœ°æƒ³ä¸€æƒ³ï¼šæˆ‘ä»¬çš„å¹³é¢æ˜¯è¢«ç©ºé—´ä¸­çš„ç‚¹â€œæ”¯æ’‘â€èµ·æ¥çš„ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ä¿æŒä¸€å®šçš„è·ç¦»ã€‚å°±åƒç£é“çš„ä¸¤æç›¸æ–¥ä¸€æ ·ï¼Œå¹³é¢å—åˆ°äº†ç‚¹çš„æ–¥åŠ›è€Œæ ‘ç«‹èµ·æ¥ã€‚ æ‰€ä»¥ï¼Œè¿™äº›ç‚¹å°±å«åšâ€œæ”¯æŒå‘é‡â€ è€Œå› ä¸ºæˆ‘ä»¬åªè€ƒè™‘æœ€è¿‘çš„ç‚¹æ¥è®¡ç®—ç‚¹åˆ°å¹³é¢çš„è·ç¦»æœ€å°å€¼ï¼Œæ‰€ä»¥æ”¯æŒå‘é‡æŒ‡çš„æ˜¯é è¿‘å¹³é¢çš„é‚£äº›ç‚¹ã€‚ æ‰€ä»¥é€‰å–ç‚¹çš„ä¸ªæ•°ä¹Ÿæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œå®ƒå‡å°‘äº†è®¡ç®—é‡ï¼ˆåŸæœ¬æ˜¯å¯¹æ¯ä¸€ä¸ªç‚¹éƒ½è¿›è¡Œè®¡ç®—ï¼‰ã€‚ è½¯é—´éš”è¯´å®Œäº†åŸºæœ¬çš„ç†è®ºéƒ¨åˆ†ï¼Œæ¥ä¸‹æ¥è¦å¯¹ç®—æ³•è¿›è¡Œæ‰¹åˆ¤äº†ã€‚ è®¾æƒ³ä¸€ä¸‹ï¼Œç›®å‰çš„æ”¯æŒå‘é‡æœºç®—æ³•æ˜¯å»ºç«‹åœ¨â€œæ•°æ®çº¿æ€§å¯åˆ†â€çš„åŸºç¡€ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰çš„ç‚¹éƒ½èƒ½å¤Ÿåˆ†ç±»åœ¨å¹³é¢ä¸¤ä¾§ã€‚ å‡å¦‚å› ä¸ºæ ‡æ³¨é”™è¯¯æˆ–è€…åˆ«çš„ç‰¹æ®Šæƒ…å†µï¼Œæ•°æ®ä¸­æœ‰é‚£ä¹ˆå‡ ä¸ªç‚¹ä¸å°å¿ƒåˆ†é”™äº†ï¼Œè·‘åˆ°å¹³é¢çš„å¦ä¸€ä¾§å»äº†å‘¢ï¼Ÿ å¯¹è¿™äº›ç‚¹ï¼Œæˆ‘ä»¬çš„ç®—æ³•ç¼ºå°‘ä¸€å®šçš„å®¹å¿æ€§ï¼ˆé²æ£’æ€§ï¼‰ï¼Œä¼šè¢«è¿™äº›ç‚¹ï¼ˆå¦‚æœå®ƒä»¬åˆåˆšå¥½è¶³å¤Ÿè¿‘ï¼Œä¼šè¢«é€‰æ‹©æˆä¸ºæ”¯æŒå‘é‡ï¼‰ï¼Œé‚£ä¹ˆå°±ä¼šè¢«å®ƒä»¬å¸¦åâ€”â€”æ‰€ä»¥è¯´ï¼Œä¸€é¢—è€é¼ å±åäº†ä¸€é”…ç²¥å•Šã€‚ ä¸‹é¢å°±ä»‹ç»ä¸€ä¸ªè¡¥æ•‘æªæ–½ï¼š æ¾å¼›å˜é‡åœ¨åº”å¯¹è¿‘ä¼¼çº¿æ€§å¯åˆ†çš„é—®é¢˜çš„æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦ç¨å¾®æ”¾æ¾è¦æ±‚ï¼Œå…è®¸æ”¯æŒå‘é‡çš„ç‚¹åˆ°å¹³é¢çš„è·ç¦»ç¨å¾®è¿‘ä¸€ç‚¹ã€‚ åœ¨å…¬å¼ä¸Šæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå˜é‡ï¼Œå«åšæ¾å¼›å˜é‡ï¼ˆSlack variableï¼‰ï¼š $min\\frac{1}{2}||w||2^2+C\\Sigma{i=1}^n\\epsilon_i$$ $s.t.y(w^Tx_i+b)\\ge 1-\\epsilon_i,$$ $\\epsilon_i\\ge0$ è¿™é‡Œï¼Œ$C$æ˜¯ç”¨æ¥æ§åˆ¶åŸç›®æ ‡ï¼ˆæœ€å°åŒ–$w$ï¼‰å’Œæ–°ç›®æ ‡ä¹‹é—´ï¼ˆä¿è¯å°½é‡å¤šçš„marginå¤§äºç­‰äº1ï¼‰çš„æƒé‡çš„ï¼Œ ä¸è¿™ä¸ªåšæ³•ç›¸å¯¹çš„ï¼Œæˆ‘ä»¬åŸæ¥çš„åšæ³•å°±å«åšç¡¬é—´éš”ï¼ˆHard marginï¼‰ã€‚ ä»£ç å®ç°æ”¯æŒå‘é‡æœºçš„ç†è®ºè¿˜ä¸æ­¢è¿™äº›å†…å®¹ï¼Œä½†æ˜¯ç›®å‰æŒæ¡çš„çŸ¥è¯†è¶³å¤Ÿæˆ‘ä»¬å®ç°ä¸€ä¸ªç®€æ˜“çš„æ”¯æŒå‘é‡æœºäº†ã€‚ æœ¬æ¬¡å®ç°äº†ç®€åŒ–çš„SVMç®—æ³•ï¼Œç”¨åˆ°scipyåº“çš„ä¼˜åŒ–å‡½æ•°å–æœ€å°ç‚¹æ¥å®ŒæˆäºŒæ¬¡è§„åˆ’çš„éƒ¨åˆ†ã€‚ ä»£ç ä¸­å·²ç»ç»™å‡ºéƒ¨åˆ†æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚å…¶ä»–è¯¦æƒ…è¯·è§æˆ‘çš„repoã€‚ import numpy as np from supervised._base import LinearModel from scipy.optimize import minimize class SVM(LinearModel): \"\"\"Support vector machine model, binary classifier.\"\"\" def __init__(self): super().__init__() def fit(self, x: np.ndarray, label: np.ndarray, **kwargs) -> np.float: # Target and constraint functions def target(w): return w[1:].dot(w[1:]) def get_func(i): return lambda w: w.dot(x_ext[i]) * label[i] - 1 # Target and constraint functions with slack variables def target_slack(w_e): w = w_e[: (p + 1)] eps = w_e[(p + 1):] return 0.5 * w[1:].dot(w[1:]) + c * np.sum(eps) def get_func_slack_w(i): return lambda w_e: w_e[: (p + 1)].dot(x_ext[:, i]) \\ * label[0][i] - 1 + w_e[p + i] def get_func_slack_e(i): return lambda w_e: w_e[p + i] assert np.array_equal(np.unique(label), np.array([-1, 1])) assert x.shape[0] == label.shape[0] n, p = x.shape if self._w is None or self._b is None or self._w.shape[0] != p: # Initialize weights using random values self._init_model(p) # No slack parameters unless explicitly stated slack = False if kwargs is not None: # Update parameters of training self._update_params(kwargs) # Whether to use slack variables if 'slack' in kwargs: assert isinstance(kwargs['slack'], bool) slack = kwargs['slack'] w_ext = np.hstack((self._w, self._b)) x_ext = np.hstack((x, np.ones((n, 1)))) # Find optimum w and b for both condition if not slack: # SVM without slack # Optimize 1/2 w^T * w # s.t. yi * (w^T * xi + b) - 1 >= 0 cons = [{'type': 'ineq', 'fun': get_func(i)} for i in range(n)] # Find optimized w w_ext = minimize(target, w_ext, constraints=cons).x else: # SVM with slack # Optimize 1/2 w^T * w + C * sum(eps_i) # s.t. yi * (w^T * xi + b) - 1 + eps_i >= 0, eps_i >= 0 c, w_and_eps = 1000, np.hstack((w_ext, np.random.randn(n))) cons = [] for idx in range(n): cons.append({'type': 'ineq', 'fun': get_func_slack_w(idx)}) cons.append({'type': 'ineq', 'fun': get_func_slack_e(idx)}) cons = tuple(cons) w_and_eps = minimize(target_slack, w_and_eps, constraints=cons).x w_ext = w_and_eps[: (p + 1)] # Update and save optimal weights &amp; bias self._w = w_ext[:-1] self._b = w_ext[-1] # Calculate loss pred_val = self._predict_value(x, self._w, self._b) loss = self._loss(pred_val, label) self._update_model(loss) return loss def predict(self, x: np.ndarray, **kwargs) -> np.ndarray: assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) pred_label = self._predict_label(pred_val) return pred_label def evaluate(self, x: np.ndarray, label: np.ndarray, **kwargs) -> tuple: assert x.shape[0] == label.shape[0] assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) pred_label = self._predict_label(pred_val) precision = 1 - np.count_nonzero(pred_label - label) / x.shape[0] loss = self._loss(pred_val, label) return precision, loss @staticmethod def _predict_value(x: np.ndarray, w: np.ndarray, b: np.float) -> np.ndarray: pred_val = np.matmul(x, w) + b return pred_val @staticmethod def _predict_label(pred_val: np.ndarray) -> np.ndarray: pred_label = np.sign(pred_val) pred_label[pred_label == 0] = 1 return pred_label @staticmethod def _loss(pred_val: np.ndarray, true_label: np.ndarray) -> np.float: # Hinge loss loss = 1 - pred_val * true_label loss[loss &lt; 0] = 0 loss = loss.mean() return loss def _grad(self, x: np.ndarray, pred_val: np.ndarray, true_val: np.ndarray) -> None: # Use scipy.optmize to find best w and b # Not grad-base method return Go beyond SVMä¸ºäº†è¯´æ˜é—®é¢˜çš„æœ¬è´¨ï¼Œæˆ‘ä»¬éœ€è¦æŠŠSVMè½¬æ¢ä¸ºæ›´ä¸€èˆ¬çš„å½¢å¼ã€‚ ä¼˜åŒ–é—®é¢˜å¾€å¾€éœ€è¦æŠŠé—®é¢˜çš„é™åˆ¶å»é™¤æˆ–è€…è½¬åŒ–ä¸ºå¯è®¡ç®—çš„å½¢å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¹ä¸Šé¢çš„é—®é¢˜è¡¨è¿°å†åšè½¬åŒ–ï¼š $\\epsilon_i\\ge1-y_i(w^Tx_i+b)\\\\epsilon_i=max[1-y_i(w^Tx_i+b),0]$ æ‰€ä»¥ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºï¼š$\\min{\\Sigma_{i=1}^n\\max[1-y_i(w^Tx_i+b),0]+\\frac{1}{2C}||w||_2^2}$ è¿™ä¸ªå½¢å¼ï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹åƒæ­£åˆ™åŒ–çš„çº¿æ€§å›å½’ï¼Ÿ å·¦ä¾§çœ‹ä½œç›®æ ‡å‡½æ•°ï¼Œå³ä¾§çœ‹ä½œRidgeæ­£åˆ™é¡¹ï¼Œåˆ™ç›®æ ‡å‡½æ•°$l(f)=\\max[1-yf,0]$ çº¿æ€§å›å½’çš„ç›®æ ‡ï¼š$l(f)=(y-f)^2=(1-yf)^2$ é€»è¾‘å›å½’çš„ç›®æ ‡ï¼š$l(f)=log(1+e^{-yf})$ çº¿æ€§åˆ†ç±»å™¨çš„ä¸€èˆ¬å½¢å¼ç”±ä¸Šè¿°è¡¨ç¤ºæˆ‘ä»¬å¯ä»¥å½’çº³å‡ºçº¿æ€§åˆ†ç±»å™¨çš„é—®é¢˜ä¸€èˆ¬å½¢å¼ï¼š $\\min{\\Sigma_{i=1}^nl(f)+\\lambda R(f)}$ å…¶ä¸­$l(f)$ä¸ºæŸå¤±å‡½æ•°ï¼Œ$R(f)$ä¸ºæ­£åˆ™é¡¹ã€‚ ä¸Šè¿°æ¨¡å‹åˆ†åˆ«å¯¹åº”ä»¥ä¸‹ï¼š æŸå¤±å‡½æ•° çº¿æ€§å›å½’ï¼šSquare loss é€»è¾‘å›å½’ï¼šLogistic loss SVMï¼šHinge loss æ­£åˆ™é¡¹ Ridgeï¼šL2-regularizer Lassoï¼šL1-regularizer ä¸åŒæŸå¤±å‡½æ•°å…³äº$yf$çš„å›¾åƒï¼š BTWï¼ŒHinge losså«åšåˆå¶å‡½æ•°ï¼Œæ­£æ˜¯å› ä¸ºå®ƒçš„å½¢çŠ¶å°±åƒæ‰“å¼€çš„åˆå¶ã€‚ éçº¿æ€§SVMï¼šæ ¸å‡½æ•°åˆšæ‰æˆ‘ä»¬è§£å†³çº¿æ€§é—®é¢˜ï¼Œé‚£ä¹ˆSVMçš„èƒ½åŠ›å°±ä»…æ­¤è€Œå·²äº†å˜›ï¼Ÿ èƒ½ä¸èƒ½å¯¹éçº¿æ€§æ•°æ®ä¹Ÿåšæ‹Ÿåˆï¼Ÿ To be continuedâ€¦","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-04ï¼šé€»è¾‘å›å½’","slug":"Machine-Learning-04-Logistic-Regression","date":"2019-06-24T16:00:00.000Z","updated":"2019-07-08T14:24:15.865Z","comments":true,"path":"Machine-Learning-04-Logistic-Regression/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-04-Logistic-Regression/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬å››ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†é€»è¾‘åˆ†ç±»çš„è¯¦ç»†ç†è®ºå’Œå®ç°ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­ä¸Šå›è¯´åˆ°çº¿æ€§å›å½’ç›¸å…³çš„ç†è®ºï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥å°±é¡ºç€çº¿æ€§å›å½’è®²è§£çº¿æ€§åˆ†ç±»å™¨ã€‚ çº¿æ€§åˆ†ç±»å™¨æ˜¯æŒ‡åˆ†ç±»å‡½æ•°ç¬¦åˆ$y=w^Tx+b$å½¢å¼çš„ä¸€ç³»åˆ—åˆ¤åˆ«æ¨¡å‹ï¼Œä¸»è¦åŒ…æ‹¬é€»è¾‘å›å½’ã€æ”¯æŒå‘é‡æœºã€æ„ŸçŸ¥æœºç­‰ï¼Œæ¥ä¸‹æ¥ä¼šé¦–å…ˆä»‹ç»ä¸‰ä¸ªçº¿æ€§åˆ†ç±»å™¨æœ¬èº«ï¼Œå†ä¼šä»‹ç»çº¿æ€§åˆ†ç±»å™¨æ›´ä¸ºä¸€èˆ¬çš„å½¢å¼å’Œå¹¿æ³›çš„è”ç³»ã€‚ é€»è¾‘å›å½’ç†è®ºé€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰è™½ç„¶æ˜¯å«å›å½’ï¼Œä½†æ˜¯å®é™…ä¸Šæ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ã€‚ é€»è¾‘å›å½’å¾—åäºé€»è¾‘å‡½æ•°ï¼ˆLogistic Funtionï¼‰ï¼Œä¹Ÿå«åšSå‡½æ•°ï¼ˆSigmoid Functionï¼‰ã€‚ é€»è¾‘å‡½æ•°$\\sigma(t)=\\frac{e^t}{1+e^t}=\\frac{1}{1+e^{-t}}$ è¿™ä¸ªå‡½æ•°å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š å¯ä»¥å°†$(-\\infty,+\\infty)$ä¹‹é—´çš„è¾“å…¥å€¼æ˜ å°„åˆ°$(0,1)$åŒºé—´ å‘ˆç°Så½¢ï¼Œå•è°ƒé€’å¢ï¼šè¾“å…¥å€¼ä¸ºè´Ÿæ—¶è¾“å‡ºåœ¨$(0,0.5)$ä¹‹é—´ï¼Œéè´Ÿè¾“å‡ºä¸º$[0.5,1)$ã€‚ ä¸€å›¾èƒœåƒè¨€ï¼š è¿™ä¸ªå‡½æ•°ä¹Ÿæ˜¯é€»è¾‘åˆ†å¸ƒçš„ç´¯è®¡åˆ†å¸ƒå‡½æ•°ã€‚ é€»è¾‘å›å½’ä½¿ç”¨é€»è¾‘å‡½æ•°ä¼°è®¡è¾“å…¥å‚æ•°ä¸ç±»å˜é‡çš„æ¦‚ç‡ï¼Œæœ€ä¸€èˆ¬çš„å½¢å¼ä¸ºäºŒåˆ†ç±»ï¼š $P(y_i=1|x_i,a)=\\sigma(a^Tx_i)=\\frac{1}{1+e^{-a^Tx_i}}$ $P(y_i=0|x_i,a)=1-\\sigma(a^Tx_i)=\\frac{1}{1+e^{a^Tx_i}}$ åˆå¹¶äºŒå¼ï¼Œæœ‰ï¼š$P(y_i|x_i,a)=\\sigma(y_ia^Tx_i)=\\frac{1}{1+e^{-y_ia^Tx_i}}$ æˆ–è€…ï¼š$P(y_i|x_i,a)=y_i\\sigma(a^Tx_i)+(1-y_i)(1-\\sigma(a^Tx_i))=y_i\\frac{1}{1+e^{-a^Tx_i}}+(1-y_i)(1-\\frac{1}{1+e^{-a^Tx_i}})$ï¼Œ æˆ–è€…ï¼š$P(y_i|x_i,a)=\\sigma(a^Tx_i)^{y_i}(1-\\sigma(a^Tx_i))^{1-y_i}=â€¦$ P.S.å…¶å®åˆå¹¶å¾—åˆ°çš„å¼å­æˆ‘æ„Ÿè§‰æ˜¯å‡‘å‡ºæ¥çš„â€¦â€¦ è¿™å°±æ˜¯æœ€åŸºæœ¬çš„é€»è¾‘å›å½’çš„å½¢å¼ã€‚ è¿™ä¸ªå¼å­ä¹Ÿéšå«ç€ï¼šåˆ¤æ–­æ˜¯ç±»1çš„æ¦‚ç‡å’Œç±»2çš„æ¦‚ç‡ä¹‹å’Œä¸º1ã€‚ å¦å¤–ï¼Œè¿™ä¸¤ä¸ªå¼å­è¿˜å…·æœ‰ä¸€ä¸ªè§„å¾‹ï¼š $\\frac{P(y_i=1|x_i,a)}{P(y_i=0|x_i,a)}\\ln\\frac{\\sigma(a^Tx_i)}{1-\\sigma(a^Tx_i)}=a^Tx_i$ï¼Œæ‰€ä»¥é€»è¾‘å›å½’ä¹Ÿå«åšå¯¹æ•°å‡ ç‡å›å½’ã€‚ å®é™…åˆ¤æ–­çš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¼šæŠŠè¾“å‡ºå¤§äº0.5çš„åˆ†ç±»ä½œä¸ºæ­£ç±»ï¼Œè¾“å‡ºå°äº0.5çš„å€¼çš„åˆ†ç±»ä½œä¸ºè´Ÿç±»ï¼Œä»è€Œå­¦ä¹ åˆ°ä¸€ä¸ªå‚æ•°ä¸º$w,b$çš„æ¨¡å‹ã€‚ ç›®æ ‡å‡½æ•°å¦‚ä½•è¯„ä»·æ¨¡å‹ï¼Œå†³å®šäº†æˆ‘ä»¬è·å–å‚æ•°çš„æ–¹å¼ã€‚ åœ¨è¿™é‡Œï¼Œå¯¹äºé€»è¾‘å›å½’è¿™ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ä½œä¸ºç›®æ ‡å‡½æ•°ï¼š æˆ‘ä»¬æœ‰å¯¹å•ä¸ªè¾“å…¥çš„æ¦‚ç‡ä¼°è®¡$P(y_i|x_i,a)$ï¼ˆè¿™é‡Œä½¿ç”¨ä¸Šé¢çš„ç¬¬ä¸‰ä¸ªå¼å­ï¼‰ï¼Œé‚£ä¹ˆå¯¹å…¨ä½“çš„æ•°æ®é›†$D$ï¼Œæ€»çš„æ¦‚ç‡ä¼°è®¡ä¸ºï¼š $P(D)=\\prod_{i\\in I}P(y_i|x_i,a)=\\prod_{i\\in I}(\\sigma(a^Tx_i)^{y_i}(1-\\sigma(a^Tx_i))^{1-y_i})$ è¿™æ˜¯ä¸€ä¸ªå…³äº$a$çš„å‡½æ•°,æˆ‘ä»¬å¸Œæœ›$P(D)$å–æå¤§ï¼Œä¹Ÿå°±æ˜¯ä¼°è®¡æ­£ç¡®çš„æ¦‚ç‡è¾¾åˆ°æœ€å¤§ã€‚ å› è€Œï¼Œéœ€è¦å¯¹$P(D)$å…³äº$a$æ±‚å¯¼ã€‚ä½†æ˜¯ï¼Œè¿ä¹˜çš„å½¢å¼éš¾ä»¥æ±‚å¯¼ï¼Œæ‰€ä»¥æˆ‘ä»¬é€šè¿‡å–å¯¹æ•°æŠŠå‡½æ•°å½¢å¼è½¬åŒ–ä¸ºè¿åŠ â€”â€”è¿™åœ¨ä¹‹å‰çš„å†…å®¹ä¹ŸæåŠäº†ã€‚ $l(P(D))=\\Sigma_{i\\in I}y_ilog(\\sigma(a^Tx_i))+(1-y_i)log(1-\\sigma(a^Tx_i))$ å› ä¸ºè¿™ä¸ªå‡½æ•°æ˜¯å‡¹çš„ï¼Œæˆ–è€…è¯´æ˜¯ä¸Šå‡¸çš„ï¼Œæˆ‘ä»¬å†è¿›è¡Œä¸€æ¬¡è½¬æ¢ï¼š$E(a)=-\\frac{1}{m}l(P(D))$ï¼Œå¯ä»¥è¯æ˜ï¼Œ$E(a)$æ˜¯ä¸€ä¸ªå¯å¯¼çš„å‡¸å‡½æ•°ã€‚ é‚£ä¹ˆç›®æ ‡å‡½æ•°å°±å˜ä¸º$E(a)$ï¼Œæˆ‘ä»¬è¦æ±‚å…¶æœ€å°å€¼ã€‚ æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰åœ¨ä¹‹å‰çš„å†…å®¹å·²ç»å‡ºç°è¿‡ï¼Œä¸è¿‡è¿™é‡Œçš„å½¢å¼ä¸è´å¶æ–¯åˆ†ç±»å™¨ä¸­çš„æå¤§ä¼¼ç„¶ä¼°è®¡ç¨æœ‰ä¸åŒï¼Œå› ä¸ºè¿™é‡Œçš„ä¼°è®¡ä¸­ï¼Œæ¦‚ç‡å°±æ˜¯ä¼¼ç„¶ï¼Œæå¤§ä¼¼ç„¶ä¼°è®¡æ˜¯å¯¹æ¦‚ç‡ä¸å®é™…åˆ†å¸ƒå…³ç³»ä½œåˆ†æï¼›è€Œè´å¶æ–¯åˆ†ç±»å™¨ä¸­ï¼Œæå¤§ä¼¼ç„¶ä¼°è®¡å°±æ˜¯å¯¹ä¼¼ç„¶ä¸å®é™…åˆ†å¸ƒçš„å…³ç³»ä½œåˆ†æï¼ˆå½“ç„¶ï¼Œä»å¦ä¸€ä¸ªè§’åº¦ï¼Œä¼¼ç„¶å°±æ˜¯åéªŒæ¦‚ç‡ï¼‰ã€‚ å‚æ•°ä¼°è®¡é¦–å…ˆå¯¹$E(a)$è¿›è¡Œå˜æ¢ï¼š $E(a)=-\\frac{1}{m}\\sum_{i=1}^{m}[y_ilog(\\frac{e^{a^Tx_i}}{1+e^{^{a^Tx_i}}})+(1-y_i)log(\\frac{1}{1+e^{a^Tx_i}})]$ $=-\\frac{1}{m}\\Sigma_{i=1}^m[y_ia^Tx_i+log(1+e^{a^Tx_i})]$ æ¥ä¸‹æ¥æ±‚æ¢¯åº¦ï¼š $\\frac{\\partial E(a)}{\\partial a}=-\\frac{1}{m}\\Sigma_{i=1}^m[y_ix_i-\\frac{e^{a^Tx_i}}{1+e^{a^Tx_i}}x_i]$ $=-\\frac{1}{m}\\Sigma_{i=1}^m[y_ix_i-\\sigma(a^Tx_i)x_i]$ è®°$\\sigma(a^Tx_i)$ä¸º$h_a(x_i)$ï¼Œé‚£ä¹ˆä¸Šå¼åˆå¯ä»¥è¡¨ç¤ºä¸ºï¼š$-\\frac{1}{m}\\Sigma_{i=1}^m[(y_i-h_a(x_i))x_i]$ è”æƒ³ä¸€ä¸‹çº¿æ€§å›å½’çš„æ¢¯åº¦ï¼š$\\frac{\\partial E(a)}{\\partial a}=-\\frac{1}{m}\\Sigma_{i=1}^m[(y_i-wx_i+b)x_i]$ï¼Œ å¯ä»¥è¯´å½¢å¼éå¸¸ç›¸ä¼¼äº†ã€‚ é‚£ä¹ˆå’Œçº¿æ€§å›å½’ç›¸ä¼¼çš„ï¼Œæˆ‘ä»¬è¯•ç€ç”¨ä¸¤ç§æ–¹å¼æ±‚è§£ï¼š æ­£è§„æ–¹ç¨‹è®©æ¢¯åº¦ä¸º0ï¼Œæˆ‘ä»¬æœ‰ï¼š$y_i=\\frac{1}{1+e^{-a^Tx_i}}$ é¦–å…ˆä»¤$z_i=a^Tx_i$ï¼Œæˆ‘ä»¬æœ‰ï¼š$y_i=\\frac{1}{1+e^{-z_i}}$ æ‰€ä»¥$z_i=-log(\\frac{1}{y_i}-1)=log(y_i)-log(1-y_i)$ é‚£ä¹ˆæˆ‘ä»¬æœ‰$a^Tx_i=log(y_i)-log(1-y_i)$ çœ‹èµ·æ¥æ˜¯æ²¡é”™ï¼Œé‚£ä¹ˆèƒ½ä¸èƒ½ä»£å…¥ï¼Œé€šè¿‡æ±‚è§£æ–¹ç¨‹ç»„å¾—åˆ°$a$å‘¢ï¼Ÿ å¾ˆé—æ†¾ï¼Œä¸èƒ½ã€‚ æˆ‘ä»¬å¾ˆå¿«å°±ä¼šæ³¨æ„åˆ°ï¼Œå¯¹äº$y_i=0,1$ï¼Œä¸Šé¢è¿™ä¸ªå¼å­æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚ é‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½ç”¨è¿™ä¸ªæ–¹å¼æ±‚è§£å‘¢ï¼Ÿå› ä¸ºæ¢¯åº¦æ˜¯ä¸ä¼šç­‰äº0çš„ï¼š$\\sigma(z_i)$æ˜¯ä¸å¯èƒ½è¾¾åˆ°$0,1$çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è‡³å¤šæ˜¯æŠŠæ¢¯åº¦é™ä½ï¼Œæ°¸è¿œä¸ä¼šå‡ºç°$y_i=\\frac{1}{1+e^{-a^Tx_i}}$çš„ç»“æœã€‚ æ‰€ä»¥ï¼Œæ­£è§„æ–¹ç¨‹è§£æ˜¯ä¸å­˜åœ¨çš„ã€‚ æ¢¯åº¦ä¸‹é™é‚£ä¹ˆå¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ±‚è§£ã€‚ æ¢¯åº¦ä»£å…¥å³å¯ï¼Œç±»ä¼¼çº¿æ€§å›å½’çš„è§£ï¼š $grad = \\alpha * -\\frac{1}{m}\\Sigma_{i=1}^m[(y_i-wx_i+b)x_i]$ $a-=grad$ æ­£åˆ™åŒ–å†…å®¹ç›¸ä¼¼ï¼Œå‚è§ä¸Šä¸€ç¯‡æ–‡ç« ï¼ˆçº¿æ€§å›å½’ï¼‰çš„æœ‰å…³å†…å®¹ã€‚ ä»£ç å®ç°åˆåˆ°äº†ä»£ç å®ç°ç¯èŠ‚ã€‚ è¿™é‡Œå®ç°äº†æœ€åŸºæœ¬çš„é€»è¾‘å›å½’LogisticRegressionç±»ï¼ˆä¸åŒ…å«æ­£åˆ™åŒ–éƒ¨åˆ†ï¼‰ã€‚ ä»£ç ä¸­åŒ…å«éƒ¨åˆ†æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚å…¶ä»–è¯¦æƒ…è§æˆ‘çš„repoã€‚ import numpy as np from supervised._base import LinearModel from utils import batch class LogisticRegression(LinearModel): \"\"\"Logistic regression model, binary classifier.\"\"\" def __init__(self): super().__init__() def fit(self, x: np.ndarray, label: np.ndarray, **kwargs) -> np.float: # Check labels: only containing 1 and 0 assert np.array_equal(np.unique(label), np.array([0, 1])) assert x.shape[0] == label.shape[0] n, p = x.shape if self._w is None or self._b is None or self._w.shape[0] != p: # Initialize weights using random values self._init_model(p) if kwargs is not None: # Update parameters of training self._update_params(kwargs) iters, loss = 0, 0. # Iterates till converge or iterating times exceed bound while iters &lt; self._iter_bound: iters += 1 # Update weights using mini-batch gradient desent for batch_x, batch_label in batch(x, label, self._batch_size): pred_val = self._predict_value(batch_x, self._w, self._b) loss += self._loss(pred_val, batch_label) * batch_x.shape[0] grad_w, grad_b = self._grad(batch_x, pred_val, batch_label) self._w -= grad_w self._b -= grad_b loss /= n # Break if model converges. if loss &lt;= self._loss_tol: break self._update_model(loss) return loss def predict(self, x: np.ndarray, **kwargs): assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) pred_label = self._predict_label(pred_val) return pred_label def evaluate(self, x: np.ndarray, label: np.ndarray, **kwargs) -> tuple: assert x.shape[0] == label.shape[0] assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) pred_label = self._predict_label(pred_val) precision = 1 - np.count_nonzero(pred_label - label) / x.shape[0] loss = self._loss(pred_val, label) return precision, loss @staticmethod def _predict_value(x: np.ndarray, w: np.ndarray, b: np.float) -> np.ndarray: def __sigmoid(raw: np.ndarray) -> np.ndarray: res = 1 / (1 + np.exp(-raw)) return res prob = np.matmul(x, w) + b pred_val = __sigmoid(prob) return pred_val @staticmethod def _predict_label(pred_val: np.ndarray) -> np.ndarray: pred_label = np.sign(pred_val - 0.5) pred_label[pred_label == 0] = 1 pred_label[pred_label &lt; 0] = 0 return pred_label @staticmethod def _loss(pred_val: np.ndarray, true_label: np.ndarray) -> np.float: # Use maximum likelihood (log-likelihood loss) # loss = 1 / n * (-y * log(wx + b) - (1 - y) * log(wx + b)) # Here we need to care about the log zero and overflow warning... mask_val = pred_val.copy() mask_val[mask_val == 0] = 1e-6 mask_val[mask_val == 1] = 1 - 1e-6 class1_loss = -true_label * np.log(mask_val) class0_loss = (1 - true_label) * np.log(1 - mask_val) loss = np.sum(class0_loss + class1_loss) / true_label.shape[0] return loss def _grad(self, x: np.ndarray, pred_val: np.ndarray, true_label: np.ndarray) -> tuple: # dc / dw = x * (pred_val - true_label) grad_w = (x * (pred_val - true_label).reshape((-1, 1))).mean(axis=0) grad_b = (pred_val - true_label).mean() # Use simple gradient by multiplying learning rate and grad. grad_w *= self._learn_rate grad_b *= self._learn_rate return grad_w, grad_b æ¨å¹¿ï¼šä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»è§æœ¬ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« ï¼ˆæœºå™¨å­¦ä¹ æ¦‚å¿µï¼‰","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-03ï¼šçº¿æ€§å›å½’","slug":"Machine-Learning-03-Linear-Regression","date":"2019-06-22T04:00:00.000Z","updated":"2019-07-07T17:11:04.877Z","comments":true,"path":"Machine-Learning-03-Linear-Regression/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-03-Linear-Regression/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸‰ç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†çº¿æ€§å›å½’çš„è¯¦ç»†ç†è®ºå’Œç®€å•çº¿æ€§å›å½’çš„å®ç°ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­ä¸Šå›è®¨è®ºäº†è´å¶æ–¯æ¨¡å‹ï¼Œè¿™ä¸€æ¨¡å‹å±äºç”Ÿæˆæ¨¡å‹ï¼ˆGenerative Modelï¼‰ï¼ŒåŸºäºä¸€å®šçš„å‡è®¾ï¼Œè®¤ä¸ºæ ·æœ¬æ˜¯ç”±ç±»æŒ‰ç…§ä¸€å®šæ¦‚ç‡æ¨¡å‹äº§ç”Ÿçš„ï¼Œç„¶åæ ¹æ®æ ·æœ¬å­¦ä¹ æ•°æ®ã€‚ åŒæ—¶æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œåœ¨é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨ä¸­ï¼Œå¦‚æœæ‰€æœ‰ç±»åˆ«å…±äº«æƒé‡ï¼Œé‚£ä¹ˆæ¨¡å‹å°±è½¬åŒ–ä¸ºçº¿æ€§çš„è¡¨è¾¾å¼ï¼Œä»è€Œå¯ä»¥ä½¿ç”¨å½¢å¦‚$y=w^Tx+b$çš„ç®€æ´å½¢å¼å»ºæ¨¡ï¼Œç›´æ¥æ±‚å‡ºæè¿°åˆ†ç±»é¢çš„è¡¨è¾¾å¼ï¼ˆè¯¦è§ä¸Šæ¬¡é™„å½•çš„è¯æ˜ï¼‰ï¼Œè¿™å°±æ˜¯åˆ¤åˆ«æ¨¡å‹ï¼ˆDiscriminant Modelï¼‰çš„æ€è·¯ã€‚ é‚£ä¹ˆæ¥ä¸‹æ¥æˆ‘ä»¬å°†æ·±å…¥è®¨è®ºåˆ¤åˆ«æ¨¡å‹ï¼Œè¿™æ˜¯ç›´æ¥æ ¹æ®æ•°æ®å­¦ä¹ å¾—åˆ°çš„æ›´åŠ ç›´æ¥çš„è§„å¾‹ã€‚ çº¿æ€§æ¨¡å‹å°±æ˜¯ä¸€ç§åˆ¤åˆ«æ¨¡å‹ï¼Œè¿™ä¸€æ¬¡æˆ‘ä»¬è®¨è®ºå®ƒåœ¨å›å½’ä»»åŠ¡ä¸Šçš„åº”ç”¨ï¼Œä¹Ÿå°±æ˜¯çº¿æ€§å›å½’ã€‚ çº¿æ€§å›å½’ç†è®ºå¯¹$x=[x_1,x_2,x_3,â€¦,x_d]^T\\in R^d$ï¼Œçº¿æ€§å‡½æ•°çš„å½¢å¼ä¸º$y=w^Tx+b$ï¼Œå…¶ä¸­$w=[w_1, w_2,â€¦, w_d]\\in R^d$ï¼Œ$b\\in R$ã€‚ è¿™ä¸€è¡¨è¾¾å¼è¿˜æœ‰ä¸€ç§è¡¨è¿°ï¼Œé‚£å°±æ˜¯å°†$b$è¿™ä¸€é¡¹åŠ å…¥$w$ä¸­ï¼Œå˜æˆï¼š $x=[x_1,x_2,â€¦,x_d,1]^T\\in R^{d+1},w=[w_1,w_2,â€¦,w_d,b]^T\\in R^{d+1}$ ç®€å•çš„æ¨¡å‹è•´å«ç€ä¸å¯å°è§†çš„åŠ›é‡ã€‚ä»»æ„æ¨¡å‹çš„è¡¨è¾¾å¼éƒ½å¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§ç»„åˆï¼Œæ•…ä¹Ÿå¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§æ¨¡å‹ã€‚ æ¯”å¦‚ï¼Œå¤šé¡¹å¼å¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§ç»„åˆçš„å½¢å¼ï¼š $f(x,a)=a_0+a_1x+a_2x^2+â€¦+a_Mx^M=\\Sigma_{i=0}^Ma_ix^i$ å¯ä»¥è½¬åŒ–ä¸ºï¼š$f(x,a)=A^TX$ï¼Œå…¶ä¸­ï¼š $X=[1,x,x^2,x^3,â€¦,x^M]^T,a=[a_0,a_1,a_2,â€¦,a_M]^T$ åŸºæœ¬ç†è®ºéƒ¨åˆ†ååˆ†ç®€æ´æ˜äº†ã€‚ ç›®æ ‡å‡½æ•°è¿™é‡Œç›®æ ‡å‡½æ•°é€šå¸¸ä½¿ç”¨æœ€å°äºŒä¹˜è¯¯å·®ï¼ˆMean Square Errorï¼‰ï¼š $J_n(a)=\\frac{1}{N}\\Sigma_{i=1}^N(y_i-a^Tx_i)^2=(y-X^Ta)^T(y-X^Ta)$ å½“ç„¶ï¼Œä½¿ç”¨å¹³æ–¹æ®‹å·®ï¼ˆResidual Sum of Squaresï¼‰ä¹Ÿæ˜¯å¯ä»¥çš„ï¼ŒåŒºåˆ«åœ¨äºæ¯”æœ€å°äºŒä¹˜è¯¯å·®å°‘äº†ç³»æ•°$\\frac{1}{N}$ã€‚ ä½ å¯èƒ½ä¼šé—®ï¼Œä¸ºä»€ä¹ˆä¸ä½¿ç”¨å¹³å‡ç»å¯¹å€¼è¯¯å·®ï¼ˆMean Absolute Errorï¼‰ï¼š$J_n(a)=\\frac{1}{N}\\Sigma_{i=1}^N|y_i-a^Tx_i|$ï¼Œä½†æ˜¯å®ƒå­˜åœ¨ä¸€äº›ç¼ºé™·ï¼š åœ¨é›¶ç‚¹å¤„ä¸å¯å¯¼ã€‚ å…¶å¯¼å‡ºçš„æ¢¯åº¦æ˜¯å¸¸æ•°ï¼ˆ+1æˆ–è€…-1ï¼‰ï¼Œæ¢¯åº¦æ±‚è§£å®¹æ˜“å¯¼è‡´ä¸æ”¶æ•›ã€‚ æ¥ä¸‹æ¥æˆ‘ä»¬æŠ±ç€è®©ç›®æ ‡å‡½æ•°æœ€å°åŒ–çš„ç›®æ ‡ï¼Œå¯¹å®ƒæ±‚æ¢¯åº¦ï¼š $\\nabla J_n=-\\frac{2}{N}X(y-X^Ta)$ äº‹å®ä¸Šï¼Œå…³äºæœ€å°äºŒä¹˜è¯¯å·®ä¹Ÿå¯ä»¥ç”¨ç”Ÿæˆå¼çš„æ€è·¯å¾—åˆ°ï¼ˆå¯¹ç†è®ºä¸æ„Ÿå†’çš„å¯ä»¥è·³è¿‡è¿™ä¸€éƒ¨åˆ†ï¼‰ï¼š ç„¶åå°±å¯ä»¥å¼€å§‹æ„‰å¿«åœ°å‚æ•°ä¼°è®¡å•¦ï¼ˆï¼¾âˆ‡ï¼¾ï¼‰ å‚æ•°ä¼°è®¡è¿™é‡Œæˆ‘ä»¬æœ‰ä¸¤ç§ä¼°è®¡æ–¹æ³•ï¼šåŸºäºæ­£è§„çŸ©é˜µï¼ˆNormal Equationï¼‰çš„ç›´æ¥æ±‚è§£ï¼Œæˆ–è€…ç»™äºˆæ¢¯åº¦ä¸‹é™çš„è¿­ä»£æ³•ã€‚ æ­£è§„çŸ©é˜µç”±ä¸Šé¢çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬ç›´æ¥ä»¤æ¢¯åº¦ä¸º0ï¼š $a=(XX^T)^{-1}Xy$ï¼Œè¿™å°±æ˜¯ç†è®ºæœ€ä¼˜è§£â€”â€”å› ä¸ºæ¢¯åº¦ä¸º0ï¼Œç›®æ ‡å‡½æ•°æ˜¯å®Œå…¨å‡¸çš„ï¼Œæ‰€ä»¥å¯ä»¥è®¤ä¸ºè®­ç»ƒæ•°æ®çš„ç›®æ ‡å‡½æ•°è¾¾åˆ°äº†æœ€å°å€¼ã€‚ å¦‚æœ$XX^T$éå¥‡å¼‚ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è·å¾—å”¯ä¸€è§£ï¼ˆå¥‡å¼‚æƒ…å†µä¸‹ä½¿ç”¨ä¼ªé€†ï¼Œç†è®ºä¸Šåº”è¯¥æ˜¯æœ‰æ— æ•°ç»„è§£ï¼‰ã€‚ ç‰¹åˆ«åœ°ï¼Œå¦‚æœ$X$æ˜¯æ–¹é˜µï¼ˆä¸€èˆ¬ä¸æ˜¯ï¼‰ï¼Œé‚£ä¹ˆ$a=X^{-T}X^{-1}Xy=X^{-T}y$ã€‚ å¥½ï¼Œç„¶åæˆ‘ä»¬çœ‹ä¸€ä¸‹æ¢¯åº¦æ±‚è§£çš„åšæ³•ï¼š æ¢¯åº¦ä¸‹é™å¦‚æœä½ è¿˜ä¸çŸ¥é“æ¢¯åº¦ä¸‹é™æ˜¯ä»€ä¹ˆçš„è¯ï¼Œæˆ‘åœ¨ç¬¬ä¸€ç¯‡æ–‡ç« é‡Œå·²ç»å†™è¿‡æ¢¯åº¦ä¸‹é™ã€æ‰¹é‡æ¢¯åº¦ä¸‹é™/éšæœºæ¢¯åº¦ä¸‹é™è¿™äº›æ¦‚å¿µã€‚ é€šè¿‡è¿­ä»£çš„æ–¹å¼æ›´æ–°å‚æ•°ï¼Œåªéœ€è¦æŠŠæ¢¯åº¦ä¹˜ä¸Šä¸€ä¸ªå­¦ä¹ ç‡$\\alpha$å°±å¯ä»¥ï¼š $grad=\\alpha * -\\frac{2}{N}X(y-X^Ta)$ $a-=grad$ é€šå¸¸ï¼Œå¸¸æ•°é¡¹$\\frac{2}{N}$ä¼šçœå»ï¼Œå› ä¸ºå­¦ä¹ ç‡æ˜¯ä¸€ä¸ªå¯ä»¥ç¼©æ”¾çš„å€¼ã€‚ å¥½äº†ï¼Œè¿™é‡Œå†æ¬¡æå‡ºç¬¬ä¸€ç¯‡æ–‡ç« çš„é—®é¢˜ï¼Œä¸ºä»€ä¹ˆç¬¬ä¸€ç§æ–¹æ³•çœ‹èµ·æ¥ç®€å•ç›´æ¥ï¼Œè€Œä¸”èƒ½å¤Ÿå¾—åˆ°ç¡®å®šçš„â€œç²¾ç¡®è§£â€ï¼Œè€Œå®é™…æ“ä½œå¾€å¾€ä½¿ç”¨åŸºäºæ¢¯åº¦çš„åšæ³•å‘¢ï¼Ÿçœ‹èµ·æ¥ç¬¬äºŒç§åšæ³•å¾ˆä¸ç²¾ç¡®ï¼Œè€Œä¸”ä¼¼ä¹æœªå¿…æ”¶æ•›åˆ°æ­£ç¡®çš„è§£ã€‚ ç†ç”±å°±æ˜¯ï¼Œç¬¬ä¸€ä¸ªæ–¹æ³•çš„å®è´¨æ˜¯è®¡ç®—æ–¹ç¨‹ç»„çš„è§£ï¼Œæ¶‰åŠæ±‚é€†çŸ©é˜µçš„è¿‡ç¨‹ï¼Œä½†æ˜¯ä¸€æ¥è®¡ç®—é‡å¤§ï¼ŒäºŒæ¥éš¾ä»¥ä¿è¯çŸ©é˜µéå¥‡å¼‚æˆ–è€…éç—…æ€çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—è¿‡ç¨‹å¯¹æ–¹ç¨‹ç»„å€¼çš„æ‰°åŠ¨éå¸¸æ•æ„Ÿï¼Œå™ªå£°å¸¦æ¥çš„è¯¯å·®è¾ƒå¤§å¯¼è‡´ç»“æœåç¦»ç†è®ºè§£ã€‚ ä»£ç å®ç°åˆåˆ°äº†åŠ¨æ‰‹å®è·µçš„æ—¶é—´äº†ã€‚è¿™ä¸€æ¬¡å®ç°äº†LinearRegressionç±»åŸºäºLinearModelåŸºç±»ï¼Œå¹¶å®ç°äº†å…¶æŠ½è±¡æ–¹æ³•ã€‚åœ¨è¿™ä¸€ä»½ä»£ç ä¸­ä¸ä½†å®ç°äº†åŸºäºæ¢¯åº¦ä¸‹é™çš„è¿­ä»£æ–¹æ³•ï¼Œä¹Ÿå®ç°äº†åŸºäºnormal equationçš„ç›´æ¥æ±‚è§£æ³•ã€‚ æš‚æ—¶æ²¡æœ‰å®ç°Ridgeå’ŒLassoçš„æ­£åˆ™éƒ¨åˆ†ï¼Œä¸»è¦æ˜¯å¸Œæœ›å’Œå…¶ä»–çº¿æ€§åˆ†ç±»å™¨ä¸€åŒæ„æ€å®ç°ï¼ŒæŠŠæ­£åˆ™åŒ–åšä¸€ä¸ªæ›´ä½³æ³›ç”¨å‹çš„æ¨¡å—ã€‚ ä»£ç ä¸­å·²ç»ç»™å‡ºéƒ¨åˆ†æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®è¯·åœ¨è¯„è®ºåŒºç•™è¨€ã€‚å…¶ä»–è¯¦æƒ…è¯·è§æˆ‘çš„repoã€‚ import numpy as np from supervised._base import LinearModel from utils import batch class LinearRegression(LinearModel): \"\"\"Linear regression model.\"\"\" def __init__(self): super().__init__() def fit(self, x: np.ndarray, y: np.ndarray, **kwargs) -> np.float: assert x.shape[0] == y.shape[0] n, p = x.shape if self._w is None or self._b is None or self._w.shape[0] != p: # Initialize weights using random values self._init_model(p) if kwargs is not None: # Update parameters of training self._update_params(kwargs) iters, loss = 0, 0. # Iterates till converge or iterating times exceed bound while iters &lt; self._iter_bound: iters += 1 # Update weights using mini-batch gradient desent for batch_x, batch_y in batch(x, y, self._batch_size): pred_val = self._predict_value(batch_x, self._w, self._b) loss += self._loss(pred_val, batch_y) * batch_x.shape[0] grad_w, grad_b = self._grad(batch_x, pred_val, batch_y) self._w -= grad_w self._b -= grad_b loss /= n # Break if model converges. if loss &lt;= self._loss_tol: break # Update model with current weight and bias self._update_model(loss) return loss def fit_norm_eq(self, x: np.ndarray, y: np.ndarray) -> np.float: # Fit x using normal equation assert x.shape[0] == y.shape[0] n, p = x.shape if self._w is None or self._b is None or self._w.shape[0] != p: # Initialize weights using random values self._init_model(p) x_ext = np.hstack((np.ones((n, 1)), x)) w_ext = np.linalg.pinv(np.matmul(x_ext.T, x_ext)) w_ext = np.matmul(np.matmul(w_ext, x_ext.T), y) self._w, self._b = w_ext[1:], w_ext[0] # Calculate training loss pred_val = self._predict_value(x, self._w, self._b) loss = self._loss(pred_val, y) self._update_model(loss) return loss def predict(self, x: np.ndarray, **kwargs) -> np.ndarray: assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) return pred_val def evaluate(self, x: np.ndarray, y: np.ndarray, **kwargs) -> tuple: assert x.shape[0] == y.shape[0] assert not np.isinf(self._optimum['loss']) assert self._optimum['w'].shape[0] == x.shape[1] pred_val = self._predict_value(x, self._optimum['w'], self._optimum['b']) # The precision part of regression is None precision = None loss = self._loss(pred_val, y) return precision, loss @staticmethod def _predict_value(x: np.ndarray, w: np.ndarray, b: np.float) -> np.ndarray: pred_val = np.matmul(x, w) + b return pred_val @staticmethod def _predict_label(pred_val: np.ndarray) -> np.ndarray: # NO labeling in regression. pass @staticmethod def _loss(pred_val: np.ndarray, true_val: np.ndarray) -> np.float: # Use MSE loss loss = float(np.sum(np.power(pred_val - true_val, 2))) loss /= 2 * true_val.shape[0] return loss def _grad(self, x: np.ndarray, pred_val: np.ndarray, true_val: np.ndarray) -> tuple: # Use MSE loss grad_w = (x * (pred_val - true_val).reshape((-1, 1))).mean(axis=0) grad_b = (pred_val - true_val).mean() # Use simple gradient by multiplying learning rate and grad. grad_w *= self._learn_rate grad_b *= self._learn_rate return grad_w, grad_b æ­£åˆ™åŒ–å¥½äº†ï¼Œæˆ‘ä»¬çš„æ¨¡å‹çœ‹èµ·æ¥å¾ˆå®Œç¾ä¸æ˜¯å—ï¼Ÿ ç°åœ¨æˆ‘ä»¬è¯•ç€ç”¨çº¿æ€§æ¨¡å‹å»æ‹Ÿåˆå¼€å¤´æåˆ°çš„å¤šé¡¹å¼æ›²çº¿$f(x,a)=a_0+a_1x+a_2x^2+â€¦+a_Mx^M=\\Sigma_{i=0}^Ma_ix^i$ å‡å¦‚å›¾çº¿é•¿è¿™æ ·ï¼Œ$y=sin(x)$ï¼š è¿™ç§å›¾çº¿ï¼Œ0é˜¶ã€1é˜¶éƒ½æ˜¯å•è°ƒï¼Œ2é˜¶åˆä¸èƒ½å…ˆå‡¹åå‡¸ï¼Œçœ‹èµ·æ¥éƒ½æ‹Ÿåˆä¸äº†å•Šã€‚ ç›´æ¥ä¸Šä¸‰é˜¶è¯•è¯•ï¼š çœ‹èµ·æ¥è¿˜è¡Œï¼Œä½†æ˜¯æ²¡åŠæ³•åšåˆ°å®Œç¾è´´åˆã€‚ æˆ‘ä»¬è¯•è¯•æ›´å‰å®³çš„ï¼Œè®©M=9ï¼š åš¯ï¼Œå‰å®³äº†ï¼Œè¦ä¸æ˜¯èƒŒæ™¯æŠŠçœŸå®æ›²çº¿ç”»å‡ºæ¥æˆ‘è¿˜çœŸå°±ä¿¡äº†ã€‚ è™½ç„¶åšåˆ°è®­ç»ƒè¯¯å·®ä¸º0ï¼Œä½†æ˜¯æˆ‘ä»¬æœ‰ç†ç”±ç›¸ä¿¡ï¼Œåœ¨çœŸå®æ•°æ®ä¸Šæµ‹è¯•ç»“æœä¸€å®šæƒ¨ä¸å¿ç¹ã€‚ ç»“æœå¦‚ä¸‹ï¼š å¾ˆæ˜æ˜¾ï¼Œæ¨¡å‹è¿‡æ‹Ÿåˆäº†ã€‚äºæ˜¯å¯ä»¥å¤ä¹ ä¸€ä¸‹ç¬¬ä¸€ç¯‡æ–‡ç« å…³äºåå·®ä¸æ–¹å·®çš„ç†è§£ï¼š æ¨¡å‹è¶Šå¤æ‚ï¼ˆç»„æˆæ¨¡å‹çš„å‚æ•°è¶Šå¤šï¼‰ï¼Œæ–¹å·®è¶Šå¤§ï¼Œåå·®è¶Šå°ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹çš„æè¿°èƒ½åŠ›è¶Šå¼ºï¼›æ¨¡å‹è¶Šç®€å•ï¼Œåå·®ä¹Ÿå®¹æ˜“å¤§ï¼Œå¾ˆå¯èƒ½æ— æ³•æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚ æˆ‘ä»¬è¿˜å‘ç°ä¸€ä¸ªç‰¹å¾ï¼Œé‚£å°±æ˜¯è¶Šé«˜é˜¶çš„é‚£ä¸ªç³»æ•°ç»å¯¹å€¼è¶Šå¤§ï¼š ä¸ºäº†é¿å…è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ç§å«åšæ­£è§„åŒ–ï¼ˆRegularizationï¼‰çš„æŠ€å·§ã€‚ ä¸‹é¢ä»‹ç»ä¸¤ç§æ­£è§„åŒ–æŠ€å·§ï¼ŒRidgeä¸Lassoã€‚ Ridgeæˆ‘ä»¬ä½¿ç”¨äºŒé˜¶æ®‹å·®ä½œä¸ºç›®æ ‡å‡½æ•°ï¼Œå¹¶å¼•å…¥ä¸€ä¸ªæƒ©ç½šé¡¹ï¼Œå˜ä¸ºï¼š $a^*=argmin\\Sigma_{i=1}^N(y_i-x_i^Ta)^2+\\lambda\\Sigma_{j=1}^pa_j^2=(y-X^Ta)^T(y-X^Ta)+\\lambda a^Ta$ è®¡ç®—æ¢¯åº¦å¾—åˆ°ï¼š$\\nabla a=-2X(y-X^Ta)+2\\lambda a$ ç”¨æ­£è§„æ–¹ç¨‹çš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š$a^*=(XX^T+\\lambda I)^{-1}Xy$ï¼Œå…¶ä¸­$\\lambda$æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚ å†æ¬¡æ±‚è§£ï¼Œæˆ‘ä»¬æƒŠå¥‡çš„å‘ç°ï¼Œé«˜é˜¶çš„ç³»æ•°å˜å°äº†ï¼š è¿™å°±æ¯”è¾ƒè€äººå¯»å‘³äº†ã€‚ä»ç†è®ºè§’åº¦åˆ†æä¸€ä¸‹è¿™ä¸ªäº‹å®ï¼š å²­å›å½’ä»¥å¢å¤§åå·®ä¸ºä»£ä»·ï¼Œæ¢å–æ›´å°çš„æ–¹å·®â€”â€”è¿™æ˜¯éšç€$\\lambda$å¢å¤§ï¼Œæ¨¡å‹å‘ç”Ÿçš„å˜åŒ–ã€‚ åœ¨è¿™ä¸ªå¤šé¡¹å¼ä¸­ï¼Œå› ä¸ºå¾ˆæ˜æ˜¾åœ°çœ‹åˆ°éšç€æ¨¡å‹å˜å¾—å¤æ‚ï¼Œæ¨¡å‹çš„æ–¹å·®è¶Šæ¥è¶Šå¤§ï¼Œå²­å›å½’æ­£æ˜¯é™ä½æ–¹å·®çš„æ‰‹æ®µã€‚ ä¸ä»…å¦‚æ­¤ï¼Œå²­å›å½’æ›´å¤§çš„ç”¨å¤„åœ¨äºã€‚å½“æˆ‘ä»¬çš„ç‰¹å¾å­˜åœ¨è¾ƒå¼ºçš„çº¿æ€§ç›¸å…³æ€§çš„æ—¶å€™ï¼ˆå¯ä»¥è¯´åœ¨ç‰¹å¾æ–¹é¢ä¸æ»¡ç§©ï¼‰ï¼Œä¼šå¯¼è‡´$XX^T$çš„å€¼å¾ˆå°ï¼Œç”šè‡³è¶‹äºå¥‡å¼‚ã€‚è€Œå²­å›å½’ä¼šå¸®æˆ‘ä»¬é™åˆ¶å‚æ•°ç»å¯¹å€¼çš„å¤§å°ï¼ŒæŠ‘åˆ¶ç›¸å…³æ€§è¾ƒå¼ºçš„å±æ€§ç³»æ•°ã€‚ æ‰€ä»¥ï¼Œå²­å›å½’å®é™…ä¸Šå¹¶ä¸åªæ˜¯ç”¨åœ¨åˆšæ‰çš„å¤šé¡¹å¼æ‹Ÿåˆä¸Šï¼Œè€Œæ˜¯å¯¹æ‰€æœ‰å­˜åœ¨è¾ƒå¤šçº¿æ€§ç›¸å…³å±æ€§æ—¶çš„é€šç”¨è§£å†³æ–¹å¼ã€‚ä¸ªäººç†è§£æœ‰ç‚¹ç±»ä¼¼â€œé™ç»´â€çš„æ“ä½œï¼Œä½†æ˜¯ç¨æœ‰ä¸åŒã€‚æ•°å­¦ä¸Šä½¿ç”¨æœ¯è¯­å‹ç¼©ä¼°è®¡ï¼ˆshinkageï¼‰æè¿°è¿™ä¸€æ“ä½œã€‚ Lassoå’ŒRidgeç›¸ä¼¼ï¼Œå”¯ä¸€çš„ä¸åŒåœ¨äºæƒ©ç½šé¡¹çš„é˜¶æ•°ï¼š $a^*=argmin\\Sigma_{i=1}^N(y_i-x_i^Ta)^2+\\lambda\\Sigma_{j=1}^p|a_j|=(y-X^Ta)^T(y-X^Ta)+\\lambda ||a||_1$ å®ƒå¸¦æ¥çš„å½±å“ä¹Ÿç¨æœ‰ä¸åŒï¼Œä¼šå¯¼è‡´æ¨¡å‹çš„å‚æ•°å¤§å¤šå˜æˆ0ï¼Œä¹Ÿå°±æ˜¯å¾—åˆ°ç¨€ç–åŒ–çš„å‚æ•°ã€‚ ç”¨ä¸€å¹…å›¾ç›´è§‚ç†è§£ï¼š çº¢è‰²çš„æ¤­åœ†å’Œè“è‰²çš„åŒºåŸŸçš„åˆ‡ç‚¹å°±æ˜¯ç›®æ ‡å‡½æ•°çš„æœ€ä¼˜è§£ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¦‚æœæ˜¯åœ†ï¼Œåˆ™å¾ˆå®¹æ˜“åˆ‡åˆ°åœ†å‘¨çš„ä»»æ„ä¸€ç‚¹ï¼Œä½†æ˜¯å¾ˆéš¾åˆ‡åˆ°åæ ‡è½´ä¸Šï¼Œå› æ­¤æ²¡æœ‰ç¨€ç–ï¼›ä½†æ˜¯å¦‚æœæ˜¯è±å½¢æˆ–è€…å¤šè¾¹å½¢ï¼Œåˆ™å¾ˆå®¹æ˜“åˆ‡åˆ°åæ ‡è½´ä¸Šï¼Œå› æ­¤å¾ˆå®¹æ˜“äº§ç”Ÿç¨€ç–çš„ç»“æœã€‚è¿™ä¹Ÿè¯´æ˜äº†ä¸ºä»€ä¹ˆLassoä¼šæ˜¯ç¨€ç–çš„ã€‚ ä»è´å¶æ–¯è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–è¿™ä¸€éƒ¨åˆ†éå¸¸è€äººå¯»å‘³ï¼Œå®ƒæ­ç¤ºäº†è´å¶æ–¯æ¦‚ç‡ä¸çº¿æ€§æ¨¡å‹ä¹‹é—´å­˜åœ¨ä¸€å®šçš„è”ç³»ã€‚ æˆ‘ä»¬å‡å®šä¸€ä¸ªç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºæ˜¯è¿™æ ·çš„ï¼š$y=f(x,a)+\\epsilon$ï¼Œå…¶ä¸­ï¼š $f(x,a)$ä¸ºåˆ¤åˆ«å‡½æ•° $\\epsilon$ä¸ºéšæœºå™ªéŸ³ï¼Œæ˜¯æˆ‘ä»¬ä¸èƒ½ç›´æ¥è·å–çš„ï¼Œæˆ‘ä»¬å‡å®šå®ƒæœä»é«˜æ–¯åˆ†å¸ƒï¼š$\\epsilon\\sim N(0,\\sigma)$ é‚£ä¹ˆæ ¹æ®é«˜æ–¯æ¦‚ç‡å¯†åº¦å…¬å¼ï¼Œ$p(y|x,a,\\sigma)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp(-\\frac{1}{2\\sigma^2}(y-f(x,a))^2)$ è€Œæ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬æœ‰$p(a|D)=\\frac{p(D|a)p(a)}{p(D)}$ï¼Œå…¶ä¸­ï¼š $p(D|a)=p(y|x,a,\\sigma)$ä¸ºä¼¼ç„¶æ¦‚ç‡ $p(a)$ä¸ºå…ˆéªŒæ¦‚ç‡ $p(a|D)$ä¸ºåéªŒæ¦‚ç‡ å¯¹äºè¿™ä¸ªå…ˆéªŒï¼Œæˆ‘ä»¬é€‰å–$p(a)=N(a|0,\\lambda^{-1}I)=\\frac{1}{(2\\pi)^{d/2}|\\lambda^{-1}I|^{1/2}}\\exp(-\\frac{1}{2}(a-0)^T(\\lambda^{-1}I)^{-1}(a-0))$ å–å¯¹æ•°æœ‰ï¼š$\\ln(p(a))=-\\frac{\\lambda}{2}a^Ta+c$ï¼Œ$c$ä¸ºå¸¸æ•° å¯¹ä¼¼ç„¶ï¼Œ$p(D|a)=\\prod_{i=1}^np(y_i|x_i,a,\\sigma)$ æˆ‘ä»¬é‡‡ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡çš„log-likelihoodæ–¹æ³•ï¼š$\\ln(p(D|a))=-\\frac{1}{2\\sigma^2}(y_i-f(x_i,a)^2))+c(\\sigma)$ è€ŒåéªŒæ¦‚ç‡æ­£æ¯”äºå…ˆéªŒå’Œä¼¼ç„¶ä¹˜ç§¯ï¼š$p(a|D)\\propto p(D|a)p(a)$ å–å¯¹æ•°ï¼Œæˆ‘ä»¬æœ‰ï¼š$\\ln(p(a|D))\\propto\\ln(p(D|a))+\\ln(p(a))$ï¼Œç­”æ¡ˆå‘¼ä¹‹æ¬²å‡º äºæ˜¯ï¼Œæˆ‘ä»¬æŠŠä¸¤é¡¹åŠ èµ·æ¥å¾—åˆ°ï¼š$ln(p(a|D))\\propto -\\frac{1}{2\\sigma^2}(y_i-f(x_i,a)^2)-\\frac{\\lambda}{2}a^Ta$ æˆ‘ä»¬å¸Œæœ›è¿™ä¸€é¡¹æœ€å¤§ï¼ˆå³æœ€å¤§åéªŒæ¦‚ç‡ï¼‰ï¼Œå°±æ˜¯å¸Œæœ›å…¶ç›¸åæ•°æœ€å°ï¼Œä¹Ÿå°±æ˜¯ï¼š $a=argmin \\frac{1}{2\\sigma^2}(y_i-f(x_i,a)^2)+\\frac{\\lambda}{2}a^Ta$ çœ‹ï¼Œè¿™ä¸å°±æ˜¯Ridgeæ­£åˆ™åŒ–çš„æŸå¤±å‡½æ•°ï¼Ÿ ä»é‡åŒ–çš„åå·®ã€æ–¹å·®ä¸å™ªéŸ³çš„è§’åº¦çœ‹å¾…æ­£åˆ™åŒ–ï¼ˆå¾…è¡¥å……è¯´æ˜ï¼‰åˆ°è¿™é‡Œæˆ‘ä»¬ä»é‡åŒ–çš„è§’åº¦æ¥çœ‹è¿™ä¸‰ä¸ªæ¦‚å¿µï¼š æˆ‘ä»¬ç”¨ä¸€ä¸ªæ¦‚å¿µæ¥ä»£è¡¨æ¨¡å‹çš„æ€»è¯¯å·®ï¼šExpected Prediction Errorï¼ŒEPEã€‚ é‡åŒ–çš„è®¡ç®—å¦‚ä¸‹ï¼ˆç›®å‰æˆ‘å¯¹è¿™éƒ¨åˆ†ç†è§£ä¸æ·±ï¼Œè¿™ä¸€éƒ¨åˆ†å¾…è¡¥å……ï¼‰ï¼š $EPE(f)=\\int\\int(y-f(x))^2p(x,y)dxdy$ $EPE=var+bias^2+noise$ $bias^2=\\int{E_D(f(x;D))-E(y|x)}^2p(x)dx$ $variance=\\int E_D{[f(x;D)-E_D(f(x;D))]^2}p(x)dx$ $noise=\\int var(y|x)p(x)dx$ è¿™é‡Œè´´å‡ºä¸åŒ$\\lambda$å‚æ•°å¯¹åå·®ä¸æ–¹å·®çš„å½±å“ï¼š å¯ä»¥å¾ˆæ˜æ˜¾çš„çœ‹å‡ºï¼Œæ­£åˆ™é¡¹é™ä½äº†å›¾çº¿çš„æ‹Ÿåˆç¨‹åº¦ï¼Œä½†æ˜¯ä¹Ÿé™ä½äº†æ–¹å·®ï¼ˆå³ä¸åŒé¢„æµ‹çº¿çš„å˜åŒ–å¹…åº¦ï¼‰ã€‚ ä»è€Œï¼Œæˆ‘ä»¬å¯¹Bias-Varianceçš„Trade-offæœ‰äº†æ›´æ·±çš„ç†è§£ï¼š","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-02ï¼šè´å¶æ–¯åˆ†ç±»","slug":"Machine-Learning-02-Bayes","date":"2019-06-21T04:00:00.000Z","updated":"2019-07-08T14:23:44.932Z","comments":true,"path":"Machine-Learning-02-Bayes/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-02-Bayes/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬äºŒç¯‡æ–‡ç« ï¼Œå†…å®¹åŒ…å«äº†è´å¶æ–¯åˆ†ç±»çš„è¯¦ç»†ç†è®ºå’Œç®€å•é«˜æ–¯è´å¶æ–¯åˆ†ç±»å™¨çš„å®ç°ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkä¸prã€‚ å¼•å­è´å¶æ–¯åˆ†ç±»çš„æ ¸å¿ƒæ˜¯è´å¶æ–¯å…¬å¼ï¼š $P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$ $P(A) = \\Sigma_{i=1}^n{P(B|A_i)P(A_i)}$ è´å¶æ–¯å…¬å¼å¯¹å¤šå…ƒå˜é‡åŒæ ·é€‚ç”¨ï¼Œä¸å˜é‡æ˜¯å¦ç‹¬ç«‹ä¹Ÿæ— å…³ï¼Œæ˜¯æ™®é€‚çš„å…¬å¼ã€‚ ä¸ºäº†ä»‹ç»è¿™ä¸ªå…¬å¼ï¼Œæˆ‘ä»¬é¦–å…ˆæ¥çœ‹ä¸€é“æ¦‚ç‡é¢˜ï¼š ç°åˆ†åˆ«æœ‰ Aã€B ä¸¤ä¸ªå®¹å™¨ï¼Œåœ¨å®¹å™¨ A é‡Œåˆ†åˆ«æœ‰ 7 ä¸ªçº¢çƒå’Œ 3 ä¸ªç™½çƒï¼Œåœ¨å®¹å™¨ B é‡Œæœ‰ 1 ä¸ªçº¢çƒå’Œ 9 ä¸ªç™½çƒï¼Œè€Œè®¾å®šä»Aä¸­æŠ½å–çš„æ¦‚ç‡å’ŒBä¸­æŠ½å–çš„æ¦‚ç‡ä¸º1:2ã€‚ ç°å·²çŸ¥ä»è¿™ä¸¤ä¸ªå®¹å™¨é‡Œä»»æ„æŠ½å‡ºäº†ä¸€ä¸ªçº¢çƒï¼Œé—®è¿™ä¸ªçƒæ¥è‡ªå®¹å™¨ A çš„æ¦‚ç‡æ˜¯å¤šå°‘? è®°æŠ½ä¸­çº¢çƒçš„äº‹ä»¶ä¸º$P(B)$ï¼Œè®°ä»å®¹å™¨AæŠ½çƒçš„æ¦‚ç‡ä¸º$P(A)$ã€‚ æ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬æœ‰ï¼š$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$ã€‚å…¶ä¸­$P(B|A)$è¡¨ç¤ºä»å®¹å™¨Aä¸­æŠ½çƒï¼ŒæŠ½åˆ°çº¢çƒçš„æ¦‚ç‡ã€‚ åœ¨è¿™ä¸ªå…¬å¼ä¸­ï¼š $P(A|B)$æ˜¯å·²çŸ¥Bå‘ç”ŸåAçš„æ¡ä»¶æ¦‚ç‡ï¼Œä¹Ÿå«åšAçš„åéªŒæ¦‚ç‡ï¼ˆposterior probabilityï¼‰ã€‚ $P(B|A)$æ˜¯å·²çŸ¥Aå‘ç”ŸåBçš„æ¡ä»¶æ¦‚ç‡ï¼Œæ˜¯Bçš„åéªŒæ¦‚ç‡ï¼Œåœ¨è¿™é‡Œå«Açš„ä¼¼ç„¶æ¦‚ç‡ï¼ˆlikelihoodï¼‰ã€‚ $P(A)$æ˜¯äº‹ä»¶å‘ç”Ÿä¹‹å‰æˆ‘ä»¬å¯¹Açš„ç»éªŒçŸ¥è¯†ï¼Œä¸Bæ— å…³ï¼Œå«åšAçš„å…ˆéªŒæ¦‚ç‡ï¼ˆprior probabilityï¼‰ã€‚ $P(B)$æ˜¯Bçš„å…ˆéªŒæ¦‚ç‡ï¼Œåœ¨è¿™é‡Œå«åšæ ‡å‡†åŒ–å¸¸é‡ï¼ˆnormalized constantï¼‰ã€‚ æ ¹æ®è¿™ä¸ªå…³ç³»ï¼ŒåéªŒ$P(A|B)$ä¹Ÿå¯ä»¥å«åšæ ‡å‡†åŒ–çš„ä¼¼ç„¶ï¼›ä¼¼ç„¶å’ŒåéªŒæ˜¯å¯ä»¥ç›¸äº’è½¬åŒ–çš„ã€‚ è´å¶æ–¯åˆ†ç±»ç†è®ºä»è¿™ä¸ªå…¬å¼å¼•ç”³å¼€ï¼Œæˆ‘ä»¬å¯ä»¥å¥—ç”¨åœ¨åˆ†ç±»ç†è®ºä¸Šï¼š æˆ‘ä»¬å¯ä»¥ç±»æ¯”è®¤ä¸ºæ¯ä¸€ä¸ªç±»å¯¹åº”ä¸€ä¸ªå®¹å™¨ï¼Œæ ·æœ¬éƒ½æ˜¯è¿™ä¸ªç±»ä¸­ç”Ÿæˆï¼ˆå–å‡ºï¼‰çš„ã€‚ åˆ†ç±»é—®é¢˜å¯ä»¥é‡‡ç”¨è¿™æ ·çš„è¡¨è¿°ï¼šå·²çŸ¥ä¸€ä¸ªå¾…å½’ç±»æ ·æœ¬$X_i$çš„ç‰¹å¾ï¼Œé‚£ä¹ˆæ±‚$X_i$å±äºç¬¬jä¸ªç±»çš„æ¦‚ç‡ï¼Œå°±å˜æˆäº†ä¸€ä¸ªåéªŒæ¦‚ç‡ã€‚ æŠŠæ ·æœ¬å±äºç¬¬jä¸ªç±»çš„æ¦‚ç‡è®°ä½œäº‹ä»¶$w_j$ï¼Œè¿™ä¸ªåéªŒæ¦‚ç‡å¯ä»¥è¡¨è¿°ä¸ºï¼š$P(w_j|x=X_i)$ï¼Œç®€è®°ä½œ$P(w_j|X_i)$ã€‚ é‚£ä¹ˆï¼Œæ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œæˆ‘ä»¬æœ‰ï¼š$P(w_j|X_i)=\\frac{P(X_i|w_j)P(w_j)}{P(X_i)}$ã€‚ è¿™é‡Œçš„ä¼¼ç„¶æ˜¯$P(X_i|w_j)$ï¼Œå…ˆéªŒæ¦‚ç‡æ˜¯$P(w_j)$ï¼Œæ ‡å‡†åŒ–å¸¸é‡ä¸º$P(X_i)$ã€‚ é‚£ä¹ˆï¼Œæœ‰äº†æŸä¸ªæ ·æœ¬å±äºå„ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œå¦‚ä½•åˆ†ç±»å‘¢ï¼Ÿ å¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬é€‰æ‹©åéªŒæ¦‚ç‡æ¯”è¾ƒå¤§çš„é‚£ä¸€ä¸ªæ¦‚ç‡å¯¹åº”çš„ç±»åˆ«ä½œä¸º$X_i$çš„åˆ†ç±»ã€‚ è¡¥å……1ï¼šå½“æˆ‘ä»¬åªæœ‰å…ˆéªŒæ¦‚ç‡çš„æ—¶å€™ï¼Œæˆ‘ä»¬é€‰æ‹©å…ˆéªŒæ¦‚ç‡è¾ƒå¤§çš„é‚£ä¸€ä¸ªç±»åˆ«ä½œä¸ºåˆ†ç±»ã€‚ç”¨å…ˆéªŒæ¦‚ç‡ç›´æ¥ä¼°è®¡çš„åå¤„åœ¨äºâ€é©¬å¤ªæ•ˆåº”â€ï¼Œå› ä¸ºå®ƒæ€»æ˜¯æŠŠæ–°æ ·æœ¬å½’ç±»åˆ°åŸæœ¬å å¤šæ•°çš„é‚£ä¸€ä¸ªç±»ã€‚ è¡¥å……2ï¼šå½“é‡‡ç”¨é£é™©çŸ©é˜µï¼ˆrisk matrixï¼‰è¿›è¡Œè¯„ä¼°çš„æ—¶å€™ï¼Œåˆ†ç±»è§„åˆ™ä¼šæ›´å¤æ‚ä¸€äº›ã€‚ å‚æ•°ä¼°è®¡æˆ‘ä»¬å·²ç»æœ‰äº†æ¦‚ç‡çš„å…¬å¼å’Œå†³ç­–ç†è®ºï¼Œå¦‚ä½•ä¼°è®¡æ¦‚ç‡å…¬å¼ä¸­çš„å„ä¸ªæ¦‚ç‡ï¼Ÿ ç­”æ¡ˆæ˜¯ï¼šä»æœ‰ç±»æ ‡ç­¾çš„æ•°æ®ï¼ˆè®­ç»ƒæ•°æ®ï¼‰ä¸­æ€»ç»“æå–ã€‚ å…ˆéªŒæ¦‚ç‡çš„ä¼°è®¡è¿™é‡Œçš„å…ˆéªŒæ¦‚ç‡ï¼Œå°±æ˜¯åœ¨æ²¡æœ‰è®­ç»ƒæ ·æœ¬å…·ä½“ç‰¹å¾çš„å€¼çš„åˆ†å¸ƒæƒ…å†µä¸‹ï¼ŒæŸä¸ªç±»åŸå§‹çš„ä¿¡æ¯ã€‚ å¾ˆè‡ªç„¶çš„ï¼Œæˆ‘ä»¬ä¼šæŠŠè¿™ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°å å…¨éƒ¨æœ‰æ ‡ç­¾çš„æ ·æœ¬çš„æ¯”é‡å½“ä½œå…ˆéªŒæ¦‚ç‡ï¼Œ å³ï¼š$P(w_j)=\\Sigma_{i=1}^N{I(y_i=c_j)}/N$ ä¼¼ç„¶æ¦‚ç‡çš„ä¼°è®¡è¿™é‡Œæˆ‘ä»¬éœ€è¦åˆ†ä¸ºè¿ç»­å˜é‡å’Œç¦»æ•£å˜é‡ä¸¤ç§æƒ…å†µè®¨è®ºï¼š è¿ç»­å˜é‡æˆ‘ä»¬æœ‰ä¸åŒçš„å‡è®¾å¯ä»¥åšå‡ºä¸åŒçš„ä¼°è®¡ã€‚å¸¸ç”¨çš„æœ‰é«˜æ–¯åˆ†å¸ƒå‡è®¾ã€äºŒé¡¹åˆ†å¸ƒå‡è®¾ã€ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚ è¿™é‡Œåªä»‹ç»é«˜æ–¯åˆ†å¸ƒå‡è®¾å¯¹åº”çš„å‚æ•°ä¼°è®¡æ–¹æ³•ã€‚ é«˜æ–¯åˆ†å¸ƒçš„å…·ä½“å‡è®¾ï¼šå¯¹äºæŸä¸€ä¸ªç±»$c_i$ï¼Œå…¶ç”Ÿæˆçš„æ ·æœ¬æ»¡è¶³é«˜æ–¯åˆ†å¸ƒï¼Œå³ï¼š$X\\sim N(\\mu, \\Sigma)$ï¼Œå…¶äº§ç”Ÿçš„æ¯ä¸€ä¸ªæ ·æœ¬ä¹‹é—´çš„æ¦‚ç‡æ˜¯äº’ç›¸ç‹¬ç«‹ä¸”åŒåˆ†å¸ƒçš„ï¼ˆi.i.dï¼ŒIndependent and identically distributedï¼‰ åœ¨è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨æå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMaximum Likelihood Estimationï¼‰çš„åšæ³•æ¥é€‰å–å‚æ•°ï¼š ç›®æ ‡å‡½æ•°æ˜¯$L(\\mu_j,\\Sigma_j)=\\prod_{i=1}^N{P(X_i|w_j)}$ã€‚ ç”±äºä¸æ–¹ä¾¿å¯¹ç›®æ ‡å‡½æ•°æ±‚å¯¼ï¼Œæˆ‘ä»¬é‡‡ç”¨å–å¯¹æ•°çš„æŠ€å·§ï¼Œå°†è¿ä¹˜è½¬åŒ–ä¸ºè¿åŠ ï¼š$l(\\mu_j,\\Sigma_j)=log(L)=\\Sigma_{i=1}^NP(X_i|w_j)$ å¯¹å¯¹æ•°ä¼¼ç„¶æ±‚å¯¼ï¼Œä»¤å¯¼æ•°ä¸º0æ±‚å‡º$\\mu,\\Sigma$ã€‚ç”±äºæ ·æœ¬æ˜¯å¤šç»´ï¼Œæ±‚å¯¼è¿‡ç¨‹æ¯”è¾ƒå¤æ‚ï¼Œè¯¦æƒ…å‚è€ƒé™„å½•ã€‚ æ€»ä¹‹ï¼Œæœ€ç»ˆæ±‚å‡ºçš„ç»“æœå’Œæ ‡é‡å½¢å¼çš„æƒŠäººä¸€è‡´ï¼š $\\hat\\mu_j=\\frac{1}{N_j}\\Sigma_{i=0}^{N_j}X_i=\\bar{x}$ $\\hat\\Sigma_j=\\frac{1}{N_j}\\Sigma_{i=1}^{N_j}(X_i-\\hat\\mu)(X_i-\\hat\\mu)^T=cov(X_i), where\\ y_i = w_j$ å¾ˆå®¹æ˜“è”æƒ³åˆ°æ ‡é‡æƒ…å†µä¸‹ï¼Œ$\\hat\\mu=\\bar{X}, \\hat\\sigma=var(X)$ æœ‰äº†ä¼°è®¡çš„å‚æ•°ä»¥åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é«˜æ–¯æ¦‚ç‡å¯†åº¦å…¬å¼æ±‚ä¼¼ç„¶æ¦‚ç‡ï¼š$P(X; \\mu, \\Sigma)=\\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}}exp(-\\frac{1}{2}(X-\\mu)^T\\Sigma^{-1}(X-\\mu))$ P.S.å…¶å®æˆ‘æœ‰ä¸€ç‚¹ç–‘é—®ğŸ¤”ï¸ï¼Œä¸ºä»€ä¹ˆè¿™é‡Œä¸èƒ½ä½¿ç”¨æ¢¯åº¦æ±‚è§£è€Œæ˜¯ç›´æ¥ä»¤æ¢¯åº¦ä¸º0æ±‚è§£è¯æ˜çš„å‘¢ï¼Œæœ‰æ²¡æœ‰å¤§ä½¬èƒ½å¤Ÿåœ¨è¯„è®ºåŒºè¯´ä¸€è¯´è‡ªå·±çš„æƒ³æ³•â€¦â€¦ 2019.07.08æ›´æ–°ï¼šå’Œè¯„è®ºåŒºåŒå­¦è®¨è®ºäº†ä¸€ä¸‹ï¼Œè¿™é‡Œåº”è¯¥æ˜¯æ²¡æœ‰å¿…è¦æ¢¯åº¦æ±‚è§£å“ˆå“ˆã€‚å®åœ¨æ— æ³•æ±‚å‡ºé—­å¼è§£ä¹Ÿè¯¥ç”¨EMç®—æ³•ï¼ˆè§æ— ç›‘ç£å­¦ä¹ éƒ¨åˆ†ï¼‰ã€‚ PSï¼šä¸Šæ–‡â€œæœ€ä½³ä¼°è®¡â€ä¸å‡†ç¡®ï¼Œå·²ç»ä¿®æ”¹ã€‚æå¤§ä¼¼ç„¶ä¼°è®¡åªæ˜¯æŸä¸€ç§ä¼°è®¡æ–¹æ³•è€Œå·²ï¼Œè¿˜æœ‰çŸ©ä¼°è®¡ç­‰æ— åçš„ä¼°è®¡æ–¹æ³•ï¼Œåªæ˜¯æ²¡æœ‰MLEæµä¼ å¹¿ã€‚ ç¦»æ•£å˜é‡å¯¹äºç¦»æ•£å˜é‡çš„ä¼°è®¡åˆ™è¾ƒä¸ºç®€å•ï¼Œæˆ‘ä»¬é€‰å–ä»¥å‰è¿™ä¸€ç‰¹å¾å‡ºç°è¿‡çš„å€¼çš„åˆ†å¸ƒæƒ…å†µä½œä¸ºä¼°è®¡ï¼Œå³ï¼š $P(X_i^k|w_j)=\\frac{|X_i^k|}{N_{w_j}}$ æ¯”å¦‚åœ¨æŸä¸ªç±»çš„æ€§åˆ«ç‰¹å¾ä¸­ï¼Œç”·æ€§å‡ºç°äº†100æ¬¡ï¼Œå¥³æ€§å‡ºç°äº†200æ¬¡ï¼Œæˆ‘ä»¬å°±ä¼°è®¡ä¸€ä¸ªè¿™ä¸ªå±æ€§ä¸ºç”·æ€§çš„ä¼¼ç„¶æ¦‚ç‡ä¸º100/300=0.33333â€¦ï¼Œå¯¹å¥³æ€§åŒç†ã€‚ æ ‡å‡†åŒ–å¸¸é‡ å¯¹äºè¿ç»­å˜é‡æ¥è¯´ï¼Œç†è®ºä¸Šæ˜¯é€šè¿‡$P(X_i)=\\Sigma_{j=1}^cP(X_i|w_j)P(w_j)$æ±‚å‡ºæ¦‚ç‡å¯†åº¦ï¼Œä¹Ÿå°±æ˜¯è¯´å¾—ç®—å‡ºå¯¹æ ·æœ¬å¯¹æ¯ä¸€ä¸ªç±»çš„å…ˆéªŒæ¦‚ç‡å’Œä¼¼ç„¶çš„ä¹˜ç§¯ä¹‹å’Œï¼Œæ‰èƒ½è®¡ç®—åˆ†æ¯ã€‚ å¯¹äºç¦»æ•£å˜é‡æ¥è¯´ï¼Œåˆ™æ˜¯æ±‚å‡ºè¿™ä¸€ä¸ªä¸€æ¨¡ä¸€æ ·çš„æ ·æœ¬åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°çš„æ¬¡æ•°ã€‚ å¦‚æœè¿‡å»æ²¡æœ‰å‡ºç°è¿‡è¿™ä¸€æ ·æœ¬ï¼Œæˆ‘ä»¬æ€»ä¸èƒ½æŠŠ0ä½œä¸ºå®ƒçš„æ¦‚ç‡ï¼Œè¿™æ˜¯ä¸åˆç†çš„ï¼ˆä¸€æ¥æœ‰å¯èƒ½æ˜¯æ ·æœ¬æ•°é‡è¿‡å°‘ï¼ŒäºŒæ¥äººå®¶æ˜¯åˆ†æ¯å•Šï¼Œæ€ä¹ˆèƒ½æ˜¯0ï¼‰ï¼Œæ‰€ä»¥é‡‡ç”¨å¹³æ»‘ï¼ˆSmoothingï¼‰çš„æŠ€æœ¯ï¼Œåœ¨åˆ†å­åˆ†æ¯åŒæ—¶åŠ å…¥ä¸€ä¸ªä¸æ ·æœ¬æ•°æœ‰å…³çš„å¹³æ»‘é¡¹ã€‚å…·ä½“æŠ€æœ¯åœ¨æ­¤ä¸åšè¯¦ç»†ä»‹ç»ã€‚ ç„¶è€Œæ­£å¸¸æƒ…å†µä¸‹ï¼Œå®ƒå¹¶ä¸åœ¨æˆ‘ä»¬çš„è€ƒè™‘èŒƒå›´å†…ï¼š å› ä¸ºï¼Œæ¯ä¸€ä¸ªç±»çš„è®¡ç®—æ¦‚ç‡çš„åˆ†æ¯éƒ½æ˜¯è¿™ä¸€é¡¹ã€‚æ—¢ç„¶æˆ‘ä»¬æœ€ç»ˆçš„ç›®æ ‡æ˜¯æ¯”è¾ƒåéªŒæ¦‚ç‡çš„å¤§å°ï¼ˆæˆ–è€…ä¸é£é™©çŸ©é˜µå…³è”åçš„å¤§å°ï¼Œwhateverï¼‰ï¼Œè¿™ä¸€é¡¹ä½œä¸ºç›¸åŒçš„ç³»æ•°å¹¶ä¸ä¼šäº§ç”Ÿå½±å“ï¼šï¼‰ ç›®æ ‡å‡½æ•°åœ¨è¿™é‡Œå› ä¸ºæˆ‘ä»¬å¹¶ä¸æ˜¯é‡‡å–è¿­ä»£ä¼˜åŒ–ï¼Œè€Œæ˜¯é€šè¿‡å‡è®¾æ¨¡å‹ç›´æ¥ä¼°è®¡å¾—å‡ºå‚æ•°ï¼Œæ‰€ä»¥ä¸éœ€è¦ç›®æ ‡å‡½æ•°å¯å¯¼ã€‚ é‡‡ç”¨0-1æŸå¤±å‡½æ•°å°±å¯ä»¥ï¼Œå³åˆ†ç±»é”™è¯¯ï¼Œç»“æœå°±åŠ ä¸€ï¼Œåˆ†ç±»æ­£ç¡®ç»“æœå°±ä¸å˜åŒ–çš„å‡½æ•°ã€‚ åœ¨è´å¶æ–¯ä¸­åˆ†ç±»ä¸­ï¼Œè¿˜æœ‰ä¸€ä¸ªå¸¸è§çš„è¯„ä»·æ ‡å‡†ï¼ˆmetricsï¼‰ï¼šæ··æ·†çŸ©é˜µå’Œé£é™©çŸ©é˜µï¼Œå…·ä½“è§ä¸Šä¸€ç¯‡æœºå™¨å­¦ä¹ æ¦‚å¿µçš„ååŠæ®µã€‚ æœ´ç´ è´å¶æ–¯æœ´ç´ è´å¶æ–¯ï¼ˆNaive Bayesï¼‰æ¨¡å‹æ˜¯è´å¶æ–¯æ¨¡å‹çš„ä¸€ä¸ªå˜ç§ï¼Œæ˜¯ç®€åŒ–è´å¶æ–¯å‚æ•°çš„ä¸€ç§æ¨¡å‹ã€‚ åœ¨æœ´ç´ è´å¶æ–¯ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºå„ä¸ªç‰¹å¾ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ï¼Œäº’ç›¸ä¸ä¼šå½±å“ï¼Œå³ï¼š $P(X_i|w_j)=P(X^1_i,X^2_i,X^3_i,â€¦X_i^p|w_j)=P(X_i^1|w_j)P(X_i^2|w_j)P(X_i^3|w_j)â€¦P(X_i^p|w_j)$ $=\\prod_{k=1}^pP(X_i^k|w_j)$ å°†è¿™ä¸€å‡è®¾åº”ç”¨åœ¨é«˜æ–¯æ¨¡å‹ä¸­ï¼Œè´å¶æ–¯-é«˜æ–¯æ¨¡å‹çš„$\\Sigma$å‚æ•°å°±é€€åŒ–ä¸ºå¯¹è§’çŸ©é˜µï¼Œå› ä¸ºå®ƒæœ¬è´¨æ˜¯åæ–¹å·®çŸ©é˜µï¼Œå¦‚ä»Šå„ä¸ªç‰¹å¾ä¹‹é—´çš„åæ–¹å·®ä¸º0ï¼Œæ¯ä¸ªç‰¹å¾æœä»ç‹¬ç«‹çš„é«˜æ–¯åˆ†å¸ƒã€‚ æ‰€ä»¥è®¡ç®—å…¬å¼ä¹Ÿå˜å¾—ç®€å•ï¼Œåªéœ€è¦å•ç‹¬è®¡ç®—æ¯ä¸€ç»´åº¦çš„é«˜æ–¯åˆ†å¸ƒæ¦‚ç‡å†ç›¸ä¹˜å°±å¯ä»¥è®¡ç®—ã€‚ æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è‡³ä»Šä¹Ÿæ˜¯ä¸€ä¸ªç®€å•çš„æµè¡Œåˆ†ç±»å™¨ï¼Œä¸è¿‡åœ¨å¾ˆå¤šæ—¶å€™ï¼Œæ ·æœ¬çš„å±æ€§å¾€å¾€æ˜¯ç›¸å…³çš„ï¼Œè¿™ç§æƒ…å½¢ä¸‹ä½¿ç”¨æœ´ç´ è´å¶æ–¯æ¨¡å‹å°±ä¸å¤ªå¥½ã€‚ ä»£ç å®ç°å¥½äº†ï¼Œè¯´äº†è¿™ä¹ˆå¤šç»ˆäºè¦ä¸Šä»£ç äº†ï½ è¿™é‡Œå®ç°äº†é«˜æ–¯è´å¶æ–¯å¤šåˆ†ç±»å™¨ï¼Œç»§æ‰¿è‡ªSupervisedModelåŸºç±»ï¼ˆè¯¦è§æœ¬äººçš„repoï¼‰ï¼Œä¸»è¦æ–¹æ³•å®ç°äº†fit,predict,evaluateï¼Œä»£ç ä¸­åŒ…å«ä¸€å®šçš„æ³¨é‡Šï¼Œå¦‚æœ‰ç–‘é—®å¯ä»¥åœ¨è¯„è®ºåŒºç•™è¨€ã€‚ import numpy as np from supervised._base import SupervisedModel class Bayes(SupervisedModel): \"\"\"Bayes model, multi-class (or binary) classifier. Bayes models include Gaussian, Multinomial, Bernoulli, however here I only implemented Gaussian. \"\"\" def __init__(self): self._prior_dict = None self._mean_dict = None self._cov_dict = None self._cov_all = None self._p = None def fit(self, x: np.ndarray, label: np.ndarray, **kwargs) -> np.float: assert x.shape[0] == label.shape[0] n, p = x.shape if self._mean_dict is None or self._cov_dict is None \\ or self._prior_dict is None or self._p != p: self._prior_dict = {} self._mean_dict = {} self._cov_dict = {} self._p = p # Calculate mean and co-variance matrix for each class all_class = np.unique(label) for c in all_class: group = x[label == c] mean, cov = self.__param_gaussian(group) self._prior_dict[c] = group.shape[0] / n self._mean_dict[c] = mean self._cov_dict[c] = cov # Calculate the whole co-variance matrix _, cov = self.__param_gaussian(x) self._cov_all = cov # Calculate loss on x _, loss = self.evaluate(x, label) return loss def predict(self, x: np.ndarray, **kwargs) -> np.ndarray: assert self._cov_dict is not None and self._mean_dict is not None assert self._cov_all is not None assert self._p == x.shape[1] # Default: non-linear classifier linear = False if 'linear' in kwargs: assert isinstance(kwargs['linear'], bool) linear = kwargs['linear'] # Calculate posterior propability for each class # All class share a same co-variance matrix if linear == True prob, label_list = [], [] for c, mean in self._mean_dict.items(): if linear: cov = self._cov_all else: cov = self._cov_dict[c] prior = self._prior_dict[c] current_prob = self.__posterior_gaussian(x, prior, mean, cov) prob.append(current_prob) label_list.append(c) # Get index of class having maximum probability for each x pred_val = np.argmax(prob, axis=0) label_list = np.array(label_list) pred_label = label_list[pred_val] return pred_label def evaluate(self, x: np.ndarray, label: np.ndarray, **kwargs) -> tuple: pred_label = self.predict(x, **kwargs) # Calculate 0-1 loss loss = np.count_nonzero(pred_label - label) # Use loss to calculate precision precision = 1 - loss / x.shape[0] return precision, loss @staticmethod def __param_gaussian(x: np.ndarray) -> tuple: \"\"\"Estimate mean and variance.\"\"\" mean = x.mean(axis=0) diff = x - mean cov = np.matmul(diff.T, diff) / x.shape[0] return mean, cov @staticmethod def __posterior_gaussian(x: np.ndarray, prior: np.float, mean: np.ndarray, cov: np.ndarray) -> np.ndarray: \"\"\"Calculate posterior probability P(wi | x).\"\"\" # Calculate likelihood probability: # P(xj | wi) ~ 1 / sqrt(det(cov)) # * exp(-0.5 * (xj - mean)^T * cov^(-1) * (xi - mean)) diff = x - mean coef = np.power(np.linalg.det(cov), -0.5) inv = np.linalg.pinv(cov) # Get exponent for xj (0 &lt; j &lt; n) exponents = np.apply_along_axis( lambda row: np.float(np.matmul(row, inv).dot(row)), 1, diff) likelihood = coef * np.exp(-0.5 * exponents) # Posterior = prior * likelihood / evidence (omitted) posterior = prior * likelihood return posterior æ‹“å±•ï¼šåˆ†ç±»é¢å½¢çŠ¶ä¸€èˆ¬è€Œè¨€ï¼Œè´å¶æ–¯åˆ†ç±»å™¨å¹¶ä¸æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ã€‚ é«˜æ–¯æ¨¡å‹ä¸åŒç±»ä¹‹é—´çš„åˆ†ç±»é¢æ˜¯é«˜æ–¯é¢ä¹‹é—´çš„ç›¸äº¤é¢ï¼Œå’Œæ¯ä¸ªç±»çš„æ¨¡å‹å‚æ•°æœ‰å…³ã€‚ ç”¨äºŒç»´ç‰¹å¾ã€å¤šåˆ†ç±»çš„é«˜æ–¯åˆ†ç±»é¢çš„å›¾åƒè¯´æ˜ä¼šæ›´æ¸…æ™°ï¼ˆæ¦‚ç‡å¯†åº¦è¡¨ç°ä¸ºå›¾åƒä¸­çš„é«˜åº¦zå€¼ï¼Œä¸åŒçš„å³°è¡¨ç¤ºä¸åŒç±»çš„ä¸­å¿ƒæ¦‚ç‡å¯†åº¦ï¼‰ï¼š é™åˆ¶äº†äºŒç»´ç‰¹å¾ä¸äºŒåˆ†ç±»çš„é«˜æ–¯åˆ†å¸ƒæ¨¡å‹ä¹‹åï¼Œåˆ†ç±»é¢å…¶å®æœ‰ä¸€äº›æœ‰è¶£çš„è§„å¾‹ï¼Œè¿™æ˜¯ç”±é«˜æ–¯åˆ†å¸ƒçš„å½¢çŠ¶é€ æˆçš„ã€‚ è¿™é‡Œä»¥äºŒåˆ†ç±»ã€äºŒç»´ç‰¹å¾çš„é«˜æ–¯åˆ†ç±»æ¨¡å‹ä¸ºä¾‹è¯´æ˜è¿™ä¸€ç‚¹ï¼Œä¸‹å›¾å±•ç¤ºäº†ä¸åŒçš„å‚æ•°ï¼ˆ$\\mu,\\Sigma$ï¼‰å¸¦æ¥åˆ†ç±»é¢çš„ä¸åŒï¼š å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒä¸‰ç»´å›¾ï¼š é‚£ä¹ˆï¼Œé«˜æ–¯æ¨¡å‹çš„å‚æ•°åˆæ˜¯å¦‚ä½•å½±å“åˆ†ç±»é¢å½¢çŠ¶çš„å‘¢ï¼Ÿ å¯ä»¥è¯æ˜æœ‰ä»¥ä¸‹ç»“è®ºï¼ˆè¯æ˜è§é™„å½•ï¼‰ï¼š ç±»çš„$\\mu$å‚æ•°ä¸ä¼šå½±å“åˆ†ç±»é¢çš„æ€§è´¨ï¼ˆçº¿æ€§/éçº¿æ€§ï¼‰ï¼Œåªä¼šæ”¹å˜ç±»åœ¨é«˜ç»´ç©ºé—´çš„ä¸­å¿ƒä½ç½®ã€‚ å¦‚æœæ‰€æœ‰ç‰¹å¾å‡æ˜¯ç‹¬ç«‹åˆ†å¸ƒï¼Œä¸”æ‰€æœ‰ç±»å…±äº«åæ–¹å·®çŸ©é˜µï¼Œå³ï¼š$\\Sigma_j=\\sigma^2I$ï¼Œé‚£ä¹ˆåˆ†ç±»é¢æ˜¯çº¿æ€§çš„ï¼Œä¸”ä¸¤ä¸ªç±»ä¹‹é—´çš„åˆ†ç±»ç›´çº¿å‚ç›´ç±»ä¸­å¿ƒä¹‹é—´çš„è¿çº¿ã€‚ å¦‚æœæ‰€æœ‰ç‰¹å¾å‡å…±äº«åæ–¹å·®çŸ©é˜µï¼Œå³ï¼š$\\Sigma_j=\\Sigma=cov(X)$ï¼Œé‚£ä¹ˆåˆ†ç±»é¢ä¹Ÿæ˜¯çº¿æ€§çš„ï¼Œä½†æ˜¯ç›´çº¿ä¼šå­˜åœ¨ä¸€å®šçš„å€¾æ–œã€‚ å¦‚æœä¸æ»¡è¶³è¿™ä¸¤ä¸ªæ¡ä»¶ä¹‹é—´çš„ä»»æ„æƒ…å†µï¼Œé‚£ä¹ˆåˆ†ç±»é¢æ˜¯åœ†é”¥æ›²çº¿ï¼ˆæŠ›ç‰©çº¿ã€åŒæ›²çº¿ã€åœ†â€¦â€¦ï¼‰ã€‚ ç‰¹ç‚¹ å¯¹å¶å°”çš„æ•°æ®å™ªå£°é²æ£’æ€§å¥½ï¼Œå› ä¸ºä½¿ç”¨äº†å‡è®¾æ¨¡å‹ï¼Œç›¸å½“äºæ¨¡å‹çš„ä¿¡æ¯ä¸å®Œå…¨æ¥è‡ªæ•°æ®ã€‚ ä½†æ˜¯ä¹Ÿå› ä¸ºæ¨¡å‹è‡ªå¸¦å‡è®¾ï¼Œåœ¨ä¸æ»¡è¶³å‡è®¾æƒ…å½¢çš„æ•°æ®ä¸Šæ‹Ÿåˆæ•ˆæœä¸å¥½ã€‚ é™„å½•ï¼šå¤šç»´é«˜æ–¯å‚æ•°ä¼°è®¡æ¨å¯¼ï¼ˆDeriving the Maximum Likelihood Estimatorsï¼‰æ¥æºï¼šhttps://stats.stackexchange.com/questions/351549/maximum-likelihood-estimators-multivariate-gaussian æˆ–è€…æŸ¥çœ‹æ–‡æ¡£ç‰ˆæœ¬ï¼šhttps://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter13.pdf é«˜æ–¯åˆ†å¸ƒå‚æ•°ä¸åˆ†ç±»é¢å½¢çŠ¶è¯æ˜æ¥æºï¼šhttps://www.byclb.com/TR/Tutorials/neural_networks/ch4_1.htm ç”±äºè¯æ˜è®¨è®ºè¿‡é•¿ï¼Œç¯‡å¹…æ‰€é™ï¼Œåœ¨æ­¤ä¸è´´å‡ºè¯¦ç»†è¯æ˜å†…å®¹ã€‚","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-01ï¼ˆä¸‹ï¼‰ï¼šæœºå™¨å­¦ä¹ æ¦‚å¿µ","slug":"Machine-Learning-01-Overview-2","date":"2019-06-20T16:00:00.000Z","updated":"2019-07-08T15:21:16.407Z","comments":true,"path":"Machine-Learning-01-Overview-2/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-01-Overview-2/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¸‹åŠéƒ¨åˆ†ï¼Œå†…å®¹åŒ…å«äº†æœºå™¨å­¦ä¹ çš„æ¦‚å¿µè§£é‡Šã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkå’Œprã€‚ å¼•å­ç´§æ¥ä¸ŠåŠç¯‡æ–‡ç« çš„ç®—æ³•ä»‹ç»ï¼Œè¿™é‡Œä¸»è¦ä¼šä»‹ç»ä¸€äº›åŸºæœ¬æ¦‚å¿µã€‚ é¢„å¤„ç†ç‰¹å¾ç¼©æ”¾ç‰¹å¾ç¼©æ”¾ï¼ˆFeature Scalingï¼‰æ˜¯ä¸€é¡¹é¢„å¤„ç†æŠ€æœ¯ï¼Œå®ƒå°†æ‰€æœ‰çš„è¾“å…¥æŒ‰ç…§ç»Ÿä¸€çš„æ ‡å‡†è¿›è¡Œå¤„ç†ï¼š æœ€å¤§æœ€å°ç¼©æ”¾ï¼ˆMin-Max Normalizationï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªç‰¹å¾çš„å„ä¸ªå€¼æŒ‰ç…§å¤§å°ç¼©æ”¾åˆ°$[0,1]$çš„åŒºé—´ä¸­ã€‚ å‡å€¼ç¼©æ”¾ï¼ˆMean Normalizationï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªç‰¹å¾çš„å„ä¸ªå€¼æŒ‰ç…§å¤§å°ç¼©æ”¾åˆ°$[-1, 1]$åŒºé—´ä¸­ã€‚ æ ‡å‡†åŒ–ï¼ˆStandardizationï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªç‰¹å¾ç¼©æ”¾æˆå¹³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„å˜é‡ã€‚ å•ä½åŒ–ï¼ˆScaling to Unit Lengthï¼‰ï¼šæŠŠæ¯ä¸€ä¸ªæ ·æœ¬çš„é•¿åº¦ï¼ˆå³å‘é‡çš„ç¬¬äºŒèŒƒæ•°ï¼‰ç¼©æ”¾ä¸º1ã€‚ è¯„ä¼°æ³›åŒ– ã€æ–¹å·®ã€åå·®å’Œå™ªå£°é¦–å…ˆï¼Œæ³›åŒ–ï¼ˆGeneralizationï¼‰æ˜¯æŒ‡æ¨¡å‹åœ¨ç»è¿‡ä¸€å®šçš„æ•°æ®è®­ç»ƒä¹‹åå¯¹ç°å®æ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹èƒ½å¤Ÿæœ€å°åŒ–æµ‹è¯•è¯¯å·®ï¼ˆtesting errorï¼‰ï¼Œè€Œè®­ç»ƒæ•°æ®é›†ä¸Šçš„è¯¯å·®ä¸æµ‹è¯•æ•°æ®é›†ä¸Šçš„è¯¯å·®å°±æ˜¯æ³›åŒ–è¯¯å·®ï¼ˆGeneralization Errorï¼‰ã€‚ è€Œæ³›åŒ–è¯¯å·®åˆ†ä¸ºæ–¹å·®ï¼ˆVarianceï¼‰ä¸åå·®ï¼ˆBiasï¼‰ï¼Œé€šè¿‡è¿™ä¸¤ä¸ªæ–¹é¢å¯ä»¥æè¿°æ¨¡å‹ä¸ç°å®æ¨¡å‹çš„è¯¯å·®ï¼š Biasæ˜¯æ¨¡å‹é¢„æµ‹ä¸çœŸå®ç»“æœçš„å·®è·ï¼Œå¯ä»¥ç›´è§‚ç†è§£ä¸ºè®­ç»ƒè¯¯å·®ï¼ˆtraining errorï¼‰ï¼Œè¡¨ç°äº†æ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ï¼› Varianceåˆ™æ˜¯â€œï¼ˆå¤§å°ç›¸åŒçš„ï¼‰ä¸åŒè®­ç»ƒæ•°æ®é›†è®­ç»ƒå‡ºçš„æ¨¡å‹â€çš„è®­ç»ƒè¯¯å·®ä¹‹é—´çš„å·®å¼‚ï¼Œè¡¨ç°äº†æ•°æ®æ‰°åŠ¨çš„å½±å“ã€‚ é€šå¸¸æ¥è¯´ï¼Œæ¨¡å‹è¶Šå¤æ‚ï¼ˆç»„æˆæ¨¡å‹çš„å‚æ•°è¶Šå¤šï¼‰ï¼Œæ–¹å·®è¶Šå¤§ï¼Œåå·®è¶Šå°ï¼Œè¿™æ˜¯å› ä¸ºæ¨¡å‹çš„æè¿°èƒ½åŠ›è¶Šå¼ºï¼›æ¨¡å‹è¶Šç®€å•ï¼Œåå·®ä¹Ÿå®¹æ˜“å¤§ï¼Œå¾ˆå¯èƒ½æ— æ³•æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚ é€šå¸¸æ¨¡å‹å¤æ‚ç¨‹åº¦ä¸æ–¹å·®/åå·®çš„å…³ç³»ï¼š åœ¨å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œéšç€æ¨¡å‹å˜å¾—å¤æ‚ï¼Œè®­ç»ƒè¯¯å·®/åå·®å˜å°ï¼Œè€Œæ–¹å·®ï¼ˆåœ¨å›¾ä¸­å¯ä»¥çœ‹ä½œæµ‹è¯•è¯¯å·®ä¸è®­ç»ƒè¯¯å·®ä¹‹é—´çš„å·®å€¼ï¼‰å˜å¤§ï¼Œè®­ç»ƒè¯¯å·®åœ¨ä¸­é—´æœ‰ä¸€ä¸ªè¾ƒä½å€¼ã€‚ ç”±æ­¤å¯å‘æˆ‘ä»¬å¯»æ‰¾ä¸€ä¸ªå¤æ‚åº¦çš„å¹³è¡¡ç‚¹ï¼Œä½¿å¾—æ¨¡å‹å…·æœ‰è¾ƒä½çš„biaså’Œvarianceï¼›è‡³äºnoiseåˆ™æ˜¯æ— æ³•æ”¹å˜çš„ã€‚ æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¦‚å¿µå«åšå™ªå£°ï¼ˆnoiseï¼‰ï¼šå™ªå£°åœ¨å½“å‰ä»»åŠ¡ä¸Šä»»ä½•å­¦ä¹ ç®—æ³•æ‰€èƒ½è¾¾åˆ°çš„æœŸæœ›æ³›åŒ–è¯¯å·®çš„ä¸‹ç•Œï¼Œå³åˆ»ç”»äº†å­¦ä¹ é—®é¢˜æœ¬èº«çš„éš¾åº¦ã€‚ æ¨¡å‹çš„è¯¯å·®ä¸»è¦æ¥è‡ªä¸‰éƒ¨åˆ†çš„æ€»å’Œã€‚ è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ æ¬ æ‹Ÿåˆä¸»è¦æè¿°çš„æ˜¯æ¨¡å‹å¤æ‚åº¦è¿‡ä½ï¼Œéš¾ä»¥æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œæ­¤æ—¶åå·®è¿‡å¤§ï¼ˆä¸Šå›¾å·¦ä¾§éƒ¨åˆ†ï¼‰ è¿‡æ‹Ÿåˆæ˜¯æŒ‡æ¨¡å‹è¿‡äºå¤æ‚ï¼Œè™½ç„¶åœ¨è®­ç»ƒæ•°æ®ä¸Šèƒ½å¤Ÿè¾ƒå¥½æ‹Ÿåˆï¼Œä½†æ˜¯åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯¯å·®æå¤§ï¼Œæ­¤æ—¶åå·®è¾ƒå°è€Œè¯¯å·®è¾ƒå¤§ï¼ˆä¸Šå›¾å³ä¾§éƒ¨åˆ†ï¼‰ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæµ‹è¯•è¯¯å·®è¾ƒå¤§ä¸èƒ½è¯´æ˜æ˜¯è¿‡æ‹Ÿåˆè¿˜æ˜¯æ¬ æ‹Ÿåˆï¼›éœ€è¦çœ‹è®­ç»ƒè¯¯å·®çš„å¤§å°ä»¥åŒºåˆ†ã€‚ åˆ†ç±»æ··æ·†çŸ©é˜µä¸é£é™©çŸ©é˜µæ··æ·†çŸ©é˜µä¸€å¼ å›¾è¯´æ˜æ··æ·†çŸ©é˜µï¼š æ··æ·†çŸ©é˜µç”¨äºé¢„æµ‹ä¸å®é™…çš„å·®è·ï¼Œå¯¹ä¸€ä¸ªNå…ƒåˆ†ç±»å™¨è€Œè¨€æ˜¯ä¸€ä¸ªN*Nçš„çŸ©é˜µï¼Œ$M[i][j]$è¡¨ç¤ºäº†é¢„æµ‹ç±»ä¸º$i$ï¼ŒçœŸå®ç±»ä¸º$j$çš„æ ·æœ¬æ•°ã€‚æ˜¾ç„¶ï¼Œæ­£ç¡®çš„åˆ†ç±»è½åœ¨çŸ©é˜µçš„ä¸»å¯¹è§’çº¿ä¸Šï¼Œå³æ‰€æœ‰çš„$M[i][i]$å…ƒç´ ã€‚è€Œå…¶ä»–é¡¹è¡¨ç¤ºäº†åˆ†ç±»é”™è¯¯çš„ä¸ªæ•°ã€‚ å½“ç„¶ä¹Ÿæœ‰ å¯¹äºäºŒåˆ†ç±»è€Œè¨€ï¼Œæˆ‘ä»¬ä¼šæŠŠæŸä¸€ä¸ªç±»å«åšæ­£ç±»ï¼Œå¦ä¸€ä¸ªç±»å«åšè´Ÿç±»ï¼Œé¢„è®¡æŸä¸ªç±»ä¸ºæ­£ç±»å«åšé˜³æ€§ï¼Œåä¹‹å«é˜´æ€§ï¼Œæ‰€ä»¥åˆäº§ç”Ÿäº†å¦‚ä¸‹æ¦‚å¿µï¼š é¢„æµ‹å’ŒçœŸå®å‡ä¸ºæ­£ç±»çš„å«åšçœŸé˜³æ€§ï¼ˆTPï¼ŒTrue Positiveï¼‰ é¢„æµ‹ä¸çœŸå®å‡ä¸ºè´Ÿç±»çš„å«åšçœŸé˜´æ€§ï¼ˆTFï¼ŒTrue Negativeï¼‰ é¢„æµ‹ä¸ºæ­£ç±»è€ŒçœŸå®ä¸ºè´Ÿç±»çš„å«åšå‡é˜³æ€§ï¼ˆFPï¼ŒFalse Positiveï¼‰ é¢„æµ‹ä¸ºè´Ÿç±»è€ŒçœŸå®ä¸ºæ­£ç±»çš„å«åšå‡é˜´æ€§ï¼ˆFNï¼ŒFalse Negativeï¼‰ ç¨åŠ æ‹“å±•ï¼Œå½“åº”ç”¨åœ¨å¤šåˆ†ç±»ä¸Šï¼Œå°±æ˜¯æŠŠåˆ†ç±»é”™è¯¯ç»Ÿç§°ä¸ºè´Ÿç±»ï¼Œåˆ†ç±»æ­£ç¡®çš„å½“åšæ­£ç±»ã€‚ ç”±æ­¤å‡ºå‘ï¼Œæˆ‘ä»¬å¾—åˆ°æ–°çš„æ¦‚å¿µä½œä¸ºè¯„ä»·æŒ‡æ ‡ï¼š å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰ï¼š$Accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$ ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼š$Precision=\\frac{TP}{TP+FP}$ å¬å›ç‡ï¼ˆRecallï¼‰ï¼š$Recall=\\frac{TP}{TP+FN}$ è¿™äº›æ¦‚å¿µå®¹æ˜“ææ··ï¼Œå¦å¤–ä¸æœç´¢å¼•æ“çš„è¯„ä¼°ä¹Ÿæœ‰ä¸€å®šå…³è”ã€‚ é‚£ä¹ˆè¿™ä¸‰ä¸ªåˆ†ç±»æ ‡å‡†åˆ†åˆ«æœ‰ä»€ä¹ˆç‰¹ç‚¹å’Œé€‚ç”¨åœºæ™¯ï¼Ÿ æˆ‘ä»¬ä»¥æ£€æµ‹ç–¾ç—…çš„åˆ†ç±»å™¨ä¸ºä¾‹è¯´æ˜ï¼š Accuracyä¸åˆ†ç±»ç›®æ ‡æ— å…³ï¼Œå®é™…åªçœ‹åˆ†å¯¹äº†æ²¡æœ‰ï¼›åœ¨ç±»åˆ«ä¸å‡è¡¡çš„é—®é¢˜ä¸Šè¯„ä¼°ç²’åº¦å¤ªå¤§ï¼Œä¸å¦‚åä¸¤ç§æ‰‹æ®µæœ‰æ•ˆã€‚å› æ­¤ï¼Œåœ¨æ²¡æœ‰ç‰¹å®šè¦æ±‚æŸä¸ªç±»çš„å‡†ç¡®ç‡è€Œæ˜¯å…³æ³¨æ•´ä½“å‡†ç¡®ç‡çš„æ—¶å€™ï¼Œä½¿ç”¨è¿™ä¸€æŒ‡æ ‡ã€‚ Precisionæ˜¯æŒ‡åˆ†ç±»å™¨æ‰€æŒ‘å‡ºçš„æŸä¸ªç±»ä¸­ï¼ŒçœŸæ­£æ˜¯æˆ‘ä»¬å¸Œæœ›çš„é‚£ä¸€ç±»çš„æ¦‚ç‡ã€‚ä½¿ç”¨è¿™ä¸ªä¸ºæŒ‡æ ‡å°±æ˜¯æœŸå¾…åˆ†ç±»å™¨é™ä½æŠŠæ²¡ç—…çš„äººå½“ä½œæœ‰ç—…çš„æ¦‚ç‡ã€‚ Recallæ˜¯æŒ‡æ²¡æœ‰è¢«è¯†åˆ«å‡ºæ˜¯æˆ‘ä»¬æƒ³è¦çš„é‚£ä¸€ç±»çš„æ¦‚ç‡ã€‚ç®€å•æ¥è¯´å°±æ˜¯ä½¿ç”¨è¿™ä¸ªæŒ‡æ ‡å°±æ˜¯æœŸå¾…åˆ†ç±»å™¨ä¸è¦é”™æ”¾è¿‡æœ‰ç—…çš„äººã€‚ é£é™©çŸ©é˜µç”Ÿæ´»ç»éªŒä¸­ï¼ŒåŒæ ·æ˜¯åˆ†ç±»é”™è¯¯ï¼Œæˆ‘ä»¬å¯¹äºä¸åŒé”™è¯¯åˆ†ç±»çš„å®¹å¿åº¦å¾€å¾€æ˜¯ä¸åŒçš„ï¼Œæ¯”å¦‚ï¼š åƒåœ¾é‚®ä»¶åˆ†ç±»é—®é¢˜ä¸­ï¼Œç›¸æ¯”é‡è¦é‚®ä»¶è¢«é”™è¯¯åˆ†ç±»ä¸ºåƒåœ¾é‚®ä»¶è€Œè¿›å…¥åƒåœ¾ç®±ï¼Œæˆ‘ä»¬æ›´æƒ…æ„¿å¤šæ”¶åˆ°ä¸€äº›è¢«å½“ä½œæ­£å¸¸é‚®ä»¶çš„åƒåœ¾é‚®ä»¶ã€‚ åœ¨è¿™é‡Œå¦‚æœæ­£ç±»æ˜¯åƒåœ¾é‚®ä»¶ï¼Œé‚£ä¹ˆæˆ‘ä»¬å…³æ³¨Precisionå¤šäºRecallï¼›åè¿‡æ¥å¦‚æœæ­£å¸¸é‚®ä»¶æ˜¯æ­£ç±»ï¼Œé‚£ä¹ˆæˆ‘ä»¬æ›´åŠ å…³æ³¨Recallã€‚ å½“åˆ¤å†³æŸä¸ªç»†èƒæ˜¯æ­£å¸¸ç»†èƒè¿˜æ˜¯ç™Œç»†èƒçš„æ—¶å€™ï¼Œæ˜¾ç„¶æŠŠä¸€ä¸ªæ­£å¸¸ç»†èƒé”™åˆ¤ä¸ºç™Œç»†èƒçš„é£é™©è¦æ¯”æŠŠä¸€ä¸ªç™Œç»†èƒé”™åˆ¤ä¸ºæ­£å¸¸ç»†èƒçš„é£é™©å¤§å¾ˆå¤šï¼Œåè€…çš„é”™è¯¯æ˜¯è‡´å‘½çš„ã€‚ å¦‚æœæˆ‘ä»¬çš„æ­£ç±»æ˜¯ç™Œç»†èƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å…³æ³¨Recallå¤šäºPrecisionï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¸Œæœ›æ”¾è¿‡æ¯ä¸€ä¸ªæ­£ç±»ã€‚ åœ¨è¿™äº›æƒ…å½¢ä¸‹ï¼ŒåŒæ ·éƒ½æ˜¯åˆ†ç±»é”™è¯¯ï¼ŒæŸä¸€ç§åˆ†ç±»é”™è¯¯çš„å½±å“æ›´ä¸¥é‡ï¼Œæ‰€ä»¥å¹¶ä¸æ˜¯æœ€å°é”™è¯¯ç‡ï¼ˆMinimum Probability Errorï¼‰è€Œæ˜¯æœ€å°é£é™©è¯¯å·®ï¼ˆMinimum Riskï¼‰æ‰èƒ½å¤Ÿè¡¨ç¤ºæˆ‘ä»¬çš„æœŸå¾…ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬ä¼šæŠŠåˆ†ç±»é”™è¯¯æ·»åŠ ä¸€ä¸ªæƒé‡ï¼Œä½¿ç”¨æƒé‡æ¥æ”¹å˜è¯„åˆ¤æ ‡å‡†ã€‚ é£é™©ï¼ˆRiskï¼‰ï¼Œå¯ä»¥ç†è§£ä¸ºå¯¹æŸç§é”™è¯¯åˆ†ç±»æƒ…å½¢ä¸‹é€ æˆåæœçš„ä¸¥é‡ç¨‹åº¦ï¼Œå½¢çŠ¶å’Œæ··æ·†çŸ©é˜µä¸€è‡´ï¼Œæ˜¯äººä¸ºæ·»åŠ çš„åŠå®šé‡çŸ©é˜µã€‚ æˆ‘ä»¬å°†é£é™©çŸ©é˜µä¸æ··æ·†çŸ©é˜µå¯¹åº”ä½ç½®å…ƒç´ ç›¸ä¹˜å¾—åˆ°çš„æ€»å’Œå°±æ˜¯æ–°çš„ç›®æ ‡å‡½æ•°å€¼ï¼Œæˆ‘ä»¬çš„åˆ†ç±»ç»“æœåº”å½“ä½¿å¾—è¿™ä¸€ç›®æ ‡å‡½æ•°å€¼è¾¾åˆ°æœ€å°ã€‚ è¿™ä¸€æ”¹å˜å°†å¦‚ä½•å½±å“æˆ‘ä»¬çš„åˆ†ç±»ç­–ç•¥ï¼Ÿ å¯¹ä¸€ä¸ªæ ·æœ¬$X_i$ï¼š å¯¹æ¯ä¸€ä¸ªç±»jï¼Œæˆ‘ä»¬è®¡ç®—å‡º$X_i$å±äºjç±»çš„æ¦‚ç‡åˆ†åˆ«ä¸º$P(w_j|X_i)$ï¼Œå¹¶è®¡ç®—jç±»çš„è¯¯åˆ†ç±»é£é™©ä¹‹å’Œï¼š$\\Sigma_{i!=j}M[j][i]$ å°†ç±»çš„è¯¯åˆ†ç±»é£é™©ä¸æ¦‚ç‡ç›¸ä¹˜ï¼Œä¹˜ç§¯å°±æ˜¯jç±»è¯¯åˆ†ç±»çš„æ¦‚ç‡é£é™© å°†æ¯ä¸€ä¸ªç±»çš„è¯¯åˆ†ç±»æ¦‚ç‡é£é™©æ±‚å‡ºï¼Œæ‰¾åˆ°æ¦‚ç‡é£é™©æœ€å°çš„é‚£ä¸€ä¸ªåˆ†ç±»ä½œä¸ºå½“å‰çš„åˆ†ç±» æŒ‰ç…§è¿™ä¸€æ–¹æ³•åˆ†ç±»è®¡ç®—å¾—åˆ°çš„è¯¯åˆ†ç±»æ¦‚ç‡é£é™©æ˜¯æœ€å°çš„ã€‚ ä»äºŒåˆ†ç±»åˆ°å¤šåˆ†ç±»å¸¸è§çš„åˆ†ç±»å™¨å¦‚æ”¯æŒå‘é‡æœºã€æ„ŸçŸ¥æœºåªèƒ½åšåˆ°äºŒåˆ†ç±»ï¼Œé‚£ä¹ˆå¤šåˆ†ç±»é—®é¢˜åº”è¯¥å¦‚ä½•è§£å†³ï¼Ÿ ä¸»è¦æœ‰ä»¥ä¸‹ä¸¤ç§æ€è·¯ï¼š Ont-versus-Oneï¼šä¸€å¯¹ä¸€å¯¹æ¯ä¸€ç»„ä¸åŒçš„ç±»$j_1,j_2$ï¼Œæˆ‘ä»¬æ„é€ ä¸€ä¸ªäºŒåˆ†ç±»å™¨ï¼› ç„¶åï¼Œå¯¹æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œè®¡ç®—æ‰€æœ‰åˆ†ç±»å™¨ï¼Œå¯¹æ¯ä¸€ä¸ªç±»è¿›è¡ŒæŠ•ç¥¨ã€‚ One-versus-Restï¼šä¸€å¯¹å…¶ä½™å¯¹æ¯ä¸€ä¸ªç±»$j$ï¼Œæ„é€ ä¸€ä¸ªäºŒåˆ†ç±»å™¨ï¼ŒåŒºåˆ†çš„ç±»æ˜¯ç¬¬jç±»å’Œæ‰€æœ‰çš„å…¶ä»–ç±»ï¼› ç„¶åï¼Œå¯¹æ¯ä¸€ä¸ªæ ·æœ¬ï¼Œè®¡ç®—æ‰€æœ‰åˆ†ç±»å™¨ï¼Œæ­¤æ—¶å¦‚æœåªæœ‰ä¸€ä¸ªåˆ†ç±»å™¨é¢„æµ‹ä¸ºæ­£ç±»ï¼Œé‚£ä¹ˆå°±å°†å…¶åˆ†ç±»ä¸ºæ­£ç±»ï¼›å¦åˆ™ï¼Œåœ¨é¢„æµ‹æ­£ç±»çš„ç±»ä¸­æŒ‘é€‰ç½®ä¿¡åº¦æœ€å¤§åˆ†ç±»å™¨å¯¹åº”çš„ç±»ã€‚ äºŒè€…çš„æ¯”è¾ƒOvOåªéœ€è¦ä¸¤ä¸ªç±»çš„æ ·æœ¬ï¼Œä½†æ˜¯æ¯ä¸ªåˆ†ç±»å™¨éœ€è¦è®­ç»ƒ$k(k-1)/2$ä¸ªåˆ†ç±»å™¨ï¼› OvRéœ€è¦kä¸ªåˆ†ç±»å™¨ï¼Œä½†æ˜¯æ¯ä¸ªåˆ†ç±»å™¨éœ€è¦è®­ç»ƒå…¨éƒ¨æ ·æœ¬ã€‚ ç»¼åˆæ¥çœ‹ï¼ŒOvOè®­ç»ƒçš„æ—¶é—´å¼€é”€è¾ƒå°ï¼ŒOvRçš„å­˜å‚¨å¼€é”€è¾ƒå°ã€‚ Multi-versus-Multiï¼šå¤šå¯¹å¤šæ¯æ¬¡é€‰å–ç‰¹å®šçš„å¤šä¸ªç±»ä½œä¸ºæ­£ç±»ï¼Œç‰¹å®šçš„å¤šä¸ªç±»ä½œä¸ºè´Ÿç±»è¿›è¡Œåˆ†ç±»ï¼Œä»è€Œç¡®å®šæ‰€å±çš„ç±»åŒºé—´ã€‚ è¿™é‡Œé€‰å–çš„ç±»ä¸èƒ½éšæ„é€‰å–ï¼Œä¸»è¦æœ‰çº é”™è¾“å‡ºç æŠ€æœ¯ï¼ˆError-Correcting Output Codesï¼ŒECOCï¼‰ï¼Œåœ¨æ­¤ä¸åšå±•å¼€ ï¼Œæœ‰å…´è¶£å¯ä»¥å‚è€ƒï¼šhttps://hyper.ai/wiki/4350 è¿™ä¸ªæ¨å¹¿å¯¹å…¶å®ƒäºŒåˆ†ç±»åˆ†ç±»å™¨ä¹Ÿé€‚ç”¨ã€‚ ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ç±»åˆ«ä¸å¹³è¡¡ï¼ˆclass imbalanceï¼‰ï¼Œåˆç§°ä¸ºæ•°æ®åæ–œï¼ˆclass skewï¼‰ã€‚ ä»¥äºŒåˆ†ç±»é—®é¢˜ä¸ºä¾‹ï¼Œè¯¥é—®é¢˜ä¸€èˆ¬æŒ‡çš„æ˜¯è®­ç»ƒé›†ä¸­æ­£è´Ÿæ ·æœ¬æ•°æ¯”ä¾‹ç›¸å·®è¿‡å¤§ï¼Œä¸€èˆ¬ä¼šé€ æˆï¼š ç±»åˆ«å°‘çš„è¯¯åˆ¤æƒ©ç½šè¿‡ä½ï¼Œå¯¼è‡´æœ‰æ‰€åè¢’ï¼Œå½“æ ·æœ¬ä¸ç¡®å®šæ—¶å€¾å‘äºæŠŠæ ·æœ¬åˆ†ç±»ä¸ºå¤šæ•°ç±»ã€‚ æ ·æœ¬æ•°é‡åˆ†å¸ƒå¾ˆä¸å¹³è¡¡æ—¶ï¼Œç‰¹å¾çš„åˆ†å¸ƒåŒæ ·ä¼šä¸å¹³è¡¡ã€‚ ä¼ ç»Ÿçš„è¯„ä»·æŒ‡æ ‡å˜å¾—ä¸å¯é ï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€‚ è€Œåœ¨å¤šåˆ†ç±»é—®é¢˜ä¸­ï¼Œå°½ç®¡åŸå§‹è®­ç»ƒé›†ä¸­å¯èƒ½ä¸åŒç±»åˆ«è®­ç»ƒæ ·æœ¬æ•°ç›®ç›¸å½“ï¼Œé€šè¿‡OvRã€MvMè¿›è¡Œæ‹†åˆ†æ—¶ä¹Ÿæœ‰å¯èƒ½ä¼šé€ æˆä¸Šè¿°æƒ…å†µï¼Œæ‰€ä»¥ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜äºŸå¾…è§£å†³ã€‚ å¸¸è§çš„è§£å†³æ–¹æ¡ˆæœ‰ï¼š å¯¹è¾ƒå¤šçš„é‚£ä¸ªç±»åˆ«è¿›è¡Œæ¬ é‡‡æ ·(under-sampling)ï¼Œèˆå¼ƒä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½¿å…¶ä¸è¾ƒå°‘ç±»åˆ«çš„æ•°æ®ç›¸å½“ã€‚ å¯¹è¾ƒå°‘çš„ç±»åˆ«è¿›è¡Œè¿‡é‡‡æ ·(over-sampling)ï¼Œé‡å¤ä½¿ç”¨ä¸€éƒ¨åˆ†æ•°æ®ï¼Œä½¿å…¶ä¸è¾ƒå¤šç±»åˆ«çš„æ•°æ®ç›¸å½“ã€‚ é˜ˆå€¼è°ƒæ•´ï¼ˆthreshold movingï¼‰ï¼Œå°†åŸæœ¬é»˜è®¤ä¸º0.5çš„é˜ˆå€¼è°ƒæ•´åˆ° è¾ƒå°‘ç±»åˆ«/ï¼ˆè¾ƒå°‘ç±»åˆ«+è¾ƒå¤šç±»åˆ«ï¼‰å³å¯ã€‚ è®­ç»ƒäº¤å‰éªŒè¯äº¤å‰éªŒè¯ï¼ˆCross Validationï¼‰æ˜¯ä¸€ç§é¿å…è¿‡æ‹Ÿåˆçš„è®­ç»ƒæŠ€å·§ã€‚ å…·ä½“æ€è·¯åœ¨äºå°†è®­ç»ƒåˆ‡åˆ†ï¼Œæ¯ä¸€æ¬¡ç”¨ä¸åŒçš„æ•°æ®é›†æ¥è®­ç»ƒï¼Œä¼˜åŒ–å¹³å‡çš„è¯¯å·®ï¼Œä»è€Œé™ä½ä¸åŒæ•°æ®é›†å¸¦æ¥æ¨¡å‹æ€§èƒ½çš„å˜åŒ–ï¼Œè¾¾åˆ°é™ä½æ–¹å·®çš„ç›®çš„ã€‚ ä¸»è¦æœ‰ä¸¤ç§æ–¹æ³•ï¼š KæŠ˜éªŒè¯ï¼ˆK-Foldï¼‰ï¼šæŒ‡å°†æ•°æ®åˆ‡åˆ†ä¸ºKä»½ï¼Œæ¯ä¸€ä»½è½®æµä½œä¸ºéªŒè¯é›†ï¼ˆValidation Setï¼‰ï¼Œå…¶ä»–æ•°æ®ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œè®­ç»ƒKè½®æ¬¡è·å¾—è®­ç»ƒè¯¯å·®ã€‚ ç•™ä¸€éªŒè¯ï¼ˆLeave-One-Outï¼‰ï¼šæ˜¯K=nçš„KæŠ˜éªŒè¯ï¼Œé€šè¿‡æ¯æ¬¡å–ä¸€ä¸ªæ ·æœ¬ä½œä¸ºéªŒè¯é›†è¿›è¡Œäº¤å‰éªŒè¯è®­ç»ƒã€‚ æ¢¯åº¦ä¸‹é™æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰æ˜¯åœ¨é€šå¸¸æ¨¡å‹ä¸­é€šç”¨çš„è¿­ä»£å‹å‚æ•°ä¼°è®¡æ–¹æ³•ã€‚ æˆ‘ä»¬å¯ä»¥è®¤ä¸ºï¼Œç›®æ ‡å‡½æ•°æ˜¯ä¸€ä¸ªè‡ªå˜é‡ä¸ºæ¨¡å‹å‚æ•°çš„å‡½æ•°ï¼Œè€Œæˆ‘ä»¬å¸Œæœ›è¾¾åˆ°å®ƒçš„æœ€å¤§/æœ€å°å€¼ã€‚ æˆ‘ä»¬çŸ¥é“ï¼Œä¸€ä¸ªå‡½æ•°åœ¨æœ€å¤§æˆ–è€…æœ€å°å€¼çš„ä½ç½®ï¼Œå®ƒçš„ä¸€é˜¶æ¢¯åº¦ä¸ºå…¨0çš„å‘é‡ã€‚è‡³äºå®ƒç©¶ç«Ÿæ˜¯æœ€å¤§å€¼è¿˜æ˜¯æœ€å°å€¼ï¼Œå¾—çœ‹å…¶äºŒé˜¶å¯¼æ•°ï¼Œæˆ–è€…è¿›è¡Œæµ‹è¯•å±€éƒ¨å˜åŒ–æ¥éªŒè¯ã€‚ å½“ç„¶ï¼Œé€šå¸¸æˆ‘ä»¬ä¼šå¸Œæœ›ç›®æ ‡å‡½æ•°æ˜¯çº¯å‡¸/çº¯å‡¹çš„ï¼Œå› ä¸ºè¿™æ ·å®ƒçš„é©»ç‚¹ï¼ˆæå¤§æå°å€¼ç‚¹ï¼‰åªæœ‰ä¸€ä¸ªï¼Œä¸€æ—¦æ‰¾åˆ°æå€¼ç‚¹å°±èƒ½å¤Ÿç¡®å®šå®ƒæ˜¯æœ€ä¼˜çš„ã€‚åœ¨è¿™ä¸€ç†è®ºçš„é©±åŠ¨ä¸‹ï¼Œè¯ç”Ÿäº†å‡¸ä¼˜åŒ–è¿™ä¸€å­¦ç§‘ï¼Œç›®æ ‡å°±æ˜¯æŠŠå„ç§éå‡¸é—®é¢˜è½¬åŒ–æˆå‡¸çš„é—®é¢˜ã€‚ å› æ­¤æˆ‘ä»¬ä¼šå¯¹å®ƒè¿›è¡Œæ±‚å¯¼ï¼Œå¯»æ‰¾ä¸€é˜¶å¯¼æ•°ä¸º0çš„ç‚¹å¯¹åº”çš„è‡ªå˜é‡ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹å‚æ•°çš„å€¼ã€‚ æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åˆ©ç”¨ç­‰å¼çš„æ¢¯åº¦ä¸º0æ±‚è§£å‡ºå‚æ•°ï¼Œä¹Ÿå¯ä»¥é‡‡ç”¨è¿­ä»£æ±‚è§£çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•ã€‚ å‰è€…çœ‹èµ·æ¥ä¸æ˜¯æ›´ç›´æ¥è€Œä¸”ç²¾ç¡®å˜›ï¼Ÿä½†æ˜¯äº‹å®ä¸Šæˆ‘ä»¬å¤§å¤šé‡‡ç”¨çš„æ˜¯åè€…ã€‚ç†ç”±å°±æ˜¯ï¼Œç¬¬ä¸€ä¸ªæ–¹æ³•çš„å®è´¨æ˜¯è®¡ç®—æ–¹ç¨‹ç»„çš„è§£ï¼Œæ¶‰åŠæ±‚é€†çŸ©é˜µçš„è¿‡ç¨‹ï¼Œä½†æ˜¯ä¸€æ¥è®¡ç®—é‡å¤§ï¼ŒäºŒæ¥éš¾ä»¥ä¿è¯çŸ©é˜µéå¥‡å¼‚æˆ–è€…éç—…æ€çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—è¿‡ç¨‹å¯¹æ–¹ç¨‹ç»„å€¼çš„æ‰°åŠ¨éå¸¸æ•æ„Ÿï¼Œå™ªå£°å¸¦æ¥çš„è¯¯å·®è¾ƒå¤§å¯¼è‡´ç»“æœåç¦»ç†è®ºè§£ã€‚ é‚£ä¹ˆï¼Œåè€…æ˜¯å¦‚ä½•æ“ä½œçš„ï¼Ÿ åœ¨æ¯æ¬¡è®­ç»ƒæ—¶ï¼Œå‡å»æ¢¯åº¦å€¼å’Œå­¦ä¹ ç‡çš„ä¹˜ç§¯ã€‚å¯¹äºä¸€ä¸ªå±€éƒ¨å‡¸çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨å‡å»æ¢¯åº¦ä¹‹åæˆ‘ä»¬çš„å‚æ•°åæ ‡ä¼šå‘æå€¼ç‚¹ï¼ˆæœ€ä½ç‚¹ï¼‰é è¿‘ï¼Œä¸”æ¢¯åº¦ç»å¯¹å€¼è¶Šå¤§ï¼Œä¸‹é™è¶Šå¿«ã€‚ ç†è®ºä¾æ®ï¼šæ¢¯åº¦çš„åæ–¹å‘å°±æ˜¯å‡½æ•°å±€éƒ¨å€¼ä¸‹é™æœ€å¿«çš„æ–¹å‘ã€‚ ä¸ºäº†å¿«é€Ÿæ”¶æ•›ã€é¿å…éœ‡è¡çš„ç›®çš„ï¼Œä¹Ÿå‡ºç°äº†å¾ˆå¤šå­¦ä¹ ç‡ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚è‡ªé€‚åº”æ€§ä¼˜åŒ–ï¼ˆAdamï¼‰ã€Adagradå’Œéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ã€Momentumç­‰ç­–ç•¥ï¼Œè¿™ä¸€å—æš‚æ—¶ä¸åšä»‹ç»ã€‚ æ‰¹é‡æ¢¯åº¦ä¸‹é™/éšæœºæ¢¯åº¦ä¸‹é™è¿™æ˜¯æ¢¯åº¦ä¸‹é™çš„ä¸¤ç§æ“ä½œæ–¹å¼ã€‚ éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descentï¼‰æ˜¯æŒ‡ï¼Œå¯¹æ¯ä¸€ä¸ªè®­ç»ƒçš„æ ·æœ¬éƒ½è®¡ç®—ä¸€æ¬¡æ¢¯åº¦å¹¶ä¸”ç”¨æ¢¯åº¦æ‰§è¡Œæ›´æ–°å‚æ•°çš„æ“ä½œã€‚è¿™ç§æ–¹æ³•çš„å¥½å¤„æ˜¯æ›´æ–°æ¬¡æ•°å¿«ï¼Œä¸”å­˜åœ¨ä¸€å®šçš„éšæœºæ€§ä¸ä¼šé™·å…¥å±€éƒ¨æå°å€¼ï¼›ä½†æ˜¯ä¹Ÿå› ä¸ºéšæœºæ€§å¼ºï¼Œå¾€å¾€æ¢¯åº¦çš„æ³¢åŠ¨å¤§ï¼ŒæŸä¸€ä¸¤ä¸ªæ ·æœ¬å¸¦æ¥çš„å‚æ•°å˜åŒ–å¤ªå¤§ï¼Œæ›´æ–°ä¸ç¨³å®šï¼Œç”šè‡³å¯¼è‡´ä¸æ”¶æ•› ã€‚ æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆBatch Gradient Descentï¼‰æ˜¯æŒ‡ï¼Œæ¯æ¬¡å¯¹æ‰€æœ‰è®­ç»ƒæ ·æœ¬è¿›è¡Œè®¡ç®—æ¢¯åº¦å¹¶ä¸”åªç”¨æ‰€æœ‰æ¢¯åº¦çš„å¹³å‡å€¼è¿›è¡Œä¸€æ¬¡æ›´æ–°ã€‚è¿™ç§æ–¹æ³•çš„å¥½å¤„è‡ªç„¶å°±æ˜¯ç¨³å®šæ›´æ–°ï¼›ä½†æ˜¯å…¶æ›´æ–°å¤ªæ…¢ï¼Œåœ¨ä¸€å®šçš„æ—¶é—´é‡Œéš¾ä»¥è¾¾åˆ°æ”¶æ•›ï¼Œè€Œä¸”ä¹Ÿå®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°å€¼ï¼Œæœ€ç»ˆåœ¨è¾ƒå°çš„æ¢¯åº¦ä¸‹åœæ­¢æ›´æ–°ã€‚ ä¸€èˆ¬æ¥è¯´ç°æœ‰çš„æŠ€å·§åœ¨äºæŠ˜è¡·ä¸¤ç§æ–¹æ¡ˆï¼Œè¿›è¡Œå°æ‰¹é‡çš„æ¢¯åº¦ä¸‹é™ï¼Œå¹¶ä¸”æ‰“ä¹±æ ·æœ¬ä»¥è·å–éšæœºæ€§ã€‚ è¿™æ ·åšçš„å¥½å¤„åœ¨äºï¼š åˆ©ç”¨äº†éšæœºæ¢¯åº¦ä¸‹é™çš„éšæœºæ€§ï¼Œä¸€èˆ¬ä¸ä¼šé™·å…¥å±€éƒ¨æå°å€¼ã€‚ æ›´æ–°é€Ÿåº¦é€‚ä¸­ï¼Œä¿æŒè¾ƒå¥½çš„ç¨³å®šæ€§ä¸ä¼šéœ‡è¡ï¼ŒåŒæ—¶ä¹Ÿèƒ½å¤Ÿè¾ƒå¿«è¾¾åˆ°æ”¶æ•›ã€‚ æœ€é‡è¦çš„æ˜¯ï¼Œæ–¹ä¾¿åº•å±‚GPUä¼˜åŒ–ã€‚å› ä¸ºæ¢¯åº¦è®¡ç®—çš„åº•å±‚æ“ä½œæ˜¯çŸ©é˜µè¿ç®—ï¼Œè€ŒGPUç”±äºå¤šæ ¸è®¡ç®—èƒ½å¤Ÿå¹¶è¡Œåœ°è®¡ç®—æŸä¸€è¡Œçš„è®¡ç®—ç»“æœï¼Œä»è€ŒåŠ é€Ÿæ¢¯åº¦æ›´æ–°è¿‡ç¨‹ã€‚æ‰€ä»¥ä¸€èˆ¬è€Œè¨€ï¼Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™çš„æ•ˆç‡æ¯”éšæœºæ¢¯åº¦ä¸‹é™æ›´é«˜ã€‚","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"æœºå™¨å­¦ä¸åŠ¨äº†-01ï¼ˆä¸Šï¼‰ï¼šæœºå™¨å­¦ä¹ ç»¼è¿°","slug":"Machine-Learning-01-Overview","date":"2019-06-20T16:00:00.000Z","updated":"2019-07-02T18:08:24.259Z","comments":true,"path":"Machine-Learning-01-Overview/","link":"","permalink":"http://riroaki.github.io/Machine-Learning-01-Overview/","excerpt":"","text":"æœ¬æ–‡æ˜¯â€æœºå™¨å­¦ä¸åŠ¨äº†â€ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« çš„ä¸ŠåŠéƒ¨åˆ†ï¼Œå†…å®¹åŒ…å«äº†æœºå™¨å­¦ä¹ çš„ç†è®ºç»¼è¿°ã€ç®—æ³•åˆ†ç±»ã€‚ å…¨ç³»åˆ—æ¨èç»“åˆä¸ªäººå®ç°çš„ä»£ç é£Ÿç”¨ï¼šhttps://github.com/Riroaki/LemonML/ æ¬¢è¿starã€forkå’Œprã€‚ å¼•å­å¦‚ä»Šæ·±åº¦å­¦ä¹ ã€æ•°æ®æŒ–æ˜ã€æœºå™¨å­¦ä¹ è¿™äº›æ¦‚å¿µå·²ç»ğŸ”¥åˆ°æˆä¸ºæ»¡å¤§è¡—éƒ½æ˜¯çš„æ¦‚å¿µï¼Œç”±äºå…¶é—¨æ§›ä½ï¼ˆè°ƒåŒ…ï¼‰å’ŒæŸäº›fancyçš„åŠŸèƒ½ï¼ŒåŠ ä¸Šåª’ä½“çš„å®£ä¼ å’Œé«˜è–ªçš„è¯±æƒ‘ï¼Œæ— è®ºè®¡ç®—æœºä¸“ä¸šè¿˜æ˜¯éè®¡ç®—æœºä¸“ä¸šå‡ºèº«çš„äººä»¬éƒ½çƒ­è¡·äºåœ¨å…¶ä¸­å¯»æ‰¾æœºä¼šï¼Œæˆ‘è¿™ä¸ªè½¯å·¥çš„èœğŸ”ä¹Ÿä¸ä¾‹å¤–ã€‚å½“ç„¶ï¼Œç›®å‰æ­£å¤„äºæ–°æ‰‹æœŸã€‚ è¿™ä¸€ä¸ªç³»åˆ—ä¸»è¦è®°å½•äº†æˆ‘åœ¨ZJUä¸Šæ•°æ®æŒ–æ˜è¯¾å­¦ä¹ å’Œæ¢³ç†çš„æœºå™¨å­¦ä¹ çš„çŸ¥è¯†ï¼Œå¹¶ä¸”åŒ…å«ä¸€äº›é¢å¤–çš„è¡¥å……çŸ¥è¯†ã€‚å…·ä½“å†…å®¹åŒ…æ‹¬äº†æ•°å­¦ç†è®ºå’Œä»£ç å®ç°ï¼Œå¸Œæœ›èƒ½å¤Ÿç»™å…¥é—¨è€…ï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±ï¼‰æä¾›ä¸€ä¸ªå‚è€ƒã€‚ ç”±äºæœ¬äººæ‡’ç™Œæ™šæœŸï¼Œåšå®¢å°†ä¸å®šæœŸæ›´æ–°ã€‚ è¯»è€…å¦‚æœæœ‰é—®é¢˜æˆ–è€…ç•™è¨€å¯ä»¥ç›´æ¥åœ¨ç›¸å…³çš„åšæ–‡ä¸‹é¢ç•™è¨€ï¼Œå¯ä»¥å…±åŒæ¢è®¨è§£å†³ã€‚ å½“ç„¶ä¹Ÿå¯ä»¥é‚®ä»¶è”ç³»æœ¬äººï¼šlilq1285@163.comï¼Œæ¬¢è¿ç†æ€§è®¨è®ºã€‚ æœ¬ç³»åˆ—å†…å®¹å±äºä¸ªäººåŸåˆ›ï¼Œè½¬è½½è¯·å£°æ˜å‡ºå¤„ï¼Œå•†ä¸šè½¬è½½è¯·è”ç³»æœ¬äººï¼Œé‚®ç®±åŒä¸Šã€‚ æœºå™¨å­¦ä¹ æ€»è§ˆæœºå™¨å­¦ä¹ å‘æºäºç»Ÿè®¡å­¦ï¼Œä¸»è¦çš„ç›®æ ‡æ˜¯ç”¨æ•°å­¦å’Œç¨‹åºè¯­è¨€æè¿°äº‹ç‰©çš„è§„å¾‹ï¼Œä»è€Œä¸ºé¢„æµ‹ã€å†³ç­–æä¾›å‚è€ƒã€‚ ä»¥å…¨å±€çš„è§†è§’æ¥çœ‹æœºå™¨å­¦ä¹ è¿™ä¸€é¢†åŸŸçš„ç®—æ³•ï¼Œä¸»è¦åˆ†ä¸ºæœ‰ç›‘ç£ï¼ˆSupervisedï¼‰å­¦ä¹ å’Œæ— ç›‘ç£ï¼ˆUnsupervisedï¼‰å­¦ä¹ ä¸¤ç±»ï¼Œæ­¤å¤–è¿˜æœ‰åŠç›‘ç£ï¼ˆHalf-supervisedï¼‰å­¦ä¹ ã€å¼ºåŒ–ï¼ˆReinforcementï¼‰å­¦ä¹ ï¼š æœ‰ç›‘ç£å­¦ä¹ ä¸»è¦ä»»åŠ¡ å›å½’ï¼ˆRegressionï¼‰é€šå¸¸ç›®æ ‡æ˜¯å¾—åˆ°è¿ç»­çš„æ›²çº¿ï¼Œè¾“å‡ºæ˜¯è¿ç»­çš„å€¼ åˆ†ç±»ï¼ˆClassificationï¼‰é€šå¸¸ç›®æ ‡æ˜¯å¾—åˆ°å†³ç­–çš„è¾¹ç•Œï¼Œè¾“å‡ºçš„æ˜¯ç¦»æ•£çš„ç±»åˆ« å¸¸è§ç®—æ³• Linear Regressionï¼šçº¿æ€§å›å½’ï¼Œä»¥çº¿æ€§æ–¹å¼ç»„åˆç‰¹å¾æ‹Ÿåˆè¿ç»­æ›²çº¿ Bayesï¼šè´å¶æ–¯åˆ†ç±»ï¼Œé€šè¿‡æ¦‚ç‡æ¨¡å‹è®¡ç®—æ ·æœ¬å±äºå„ä¸ªåˆ†ç±»çš„åéªŒæ¦‚ç‡ï¼Œè¿›è¡Œåˆ†ç±» Logistic Regressionï¼šé€»è¾‘å›å½’ï¼Œåœ¨çº¿æ€§å›å½’åŸºç¡€ä¸Šå¢åŠ æ¿€æ´»å‡½æ•°ä»¥è¿›è¡Œåˆ†ç±» Support Vector Machineï¼šæ”¯æŒå‘é‡æœºï¼Œé€‰å–å†³ç­–é¢è¾ƒè¿‘çš„ç‚¹ç”¨æ¥è®¡ç®—å†³ç­–é¢çš„å‚æ•° K Nearest Neighborï¼šKè¿‘é‚»ï¼Œå¯»æ‰¾è·ç¦»è¾ƒè¿‘çš„Kä¸ªæ ·æœ¬çš„æ ‡ç­¾å–ä¼—æ•°ä½œä¸ºæ ·æœ¬å½’ç±» Perceptronï¼šæ„ŸçŸ¥æœºï¼ŒäºŒåˆ†ç±»ç®—æ³•ï¼Œæœ€ç®€å•çš„ç¥ç»ç½‘ç»œ Decision Treeï¼šå†³ç­–æ ‘ï¼Œå¯ä»¥çœ‹ä½œä»æ ·æœ¬æ•°æ®ä¸­å­¦ä¹ if-elseè¯­å¥çš„ç»„åˆï¼Œæ¯ä¸€ä¸ªåˆ¤æ–­éƒ½æ˜¯æ•°çš„ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ç°åˆ†ç±» Linear Discriminant Analysisï¼šçº¿æ€§åˆ¤åˆ«åˆ†æï¼Œé€šè¿‡æ‰¾åˆ°ç‰¹å¾çš„çº¿æ€§ç»„åˆä»¥ç”¨äºé™ç»´ï¼Œä¹Ÿæ˜¯ä¸€ç§åˆ†ç±»ç®—æ³• ç®—æ³•çš„åˆ†ç±» å¦‚æœä»ç®—æ³•è§£å†³çš„é—®é¢˜åˆ†ç±»ï¼Œå¯ä»¥åˆ†ä¸ºå›å½’å’Œåˆ†ç±»ä¸¤å¤§ç±»ç®—æ³•ï¼š å…¶ä¸­ï¼Œçº¿æ€§å›å½’ä¸ºå›å½’ç±»çš„ç®—æ³•ï¼Œå…¶ä½™ç®—æ³•å‡ä¸»è¦ç”¨äºåˆ†ç±»ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æœ‰å›å½’çš„ä½œç”¨ã€‚å› ä¸ºè¿™äº›åˆ†ç±»ç®—æ³•å¤§å¤šæ˜¯åœ¨è¿ç»­çš„è¾“å‡ºå¤–è¿›è¡Œå¤„ç†è·å¾—ç±»åˆ«ï¼Œå¦‚é€»è¾‘å›å½’ã€æ„ŸçŸ¥æœºã€æ”¯æŒå‘é‡æœºç­‰ï¼Œå¦‚æœç”¨åœ¨å›å½’ä¸Šåˆ™è¾“å‡ºçš„æ˜¯åˆ†ç±»å‰è®¡ç®—çš„ç»“æœã€‚ å¦‚æœä»å†³ç­–é¢çš„è§’åº¦æ¥çœ‹ï¼Œä¸Šè¿°çš„åˆ†ç±»ç®—æ³•å¯ä»¥åˆ†ä¸ºçº¿æ€§åˆ†ç±»ç®—æ³•å’Œéçº¿æ€§åˆ†ç±»ç®—æ³•ï¼š çº¿æ€§åˆ†ç±»ç®—æ³•ï¼šåˆ†ç±»é¢ä¸ºçº¿æ€§/è¾“å‡ºå‡½æ•°ä¸ºçº¿æ€§å½¢å¼ï¼ˆæœ¬è´¨ç›¸åŒï¼Œé‡‡ç”¨ä¸åŒçš„ç›®æ ‡å‡½æ•°å¾—åˆ°çš„æ¨¡å‹ï¼‰ åŒ…æ‹¬ï¼šé€»è¾‘å›å½’ã€æ”¯æŒå‘é‡æœºã€æ„ŸçŸ¥æœºã€çº¿æ€§åˆ¤åˆ«åˆ†æ éçº¿æ€§ç®—æ³•ï¼šåˆ†ç±»é¢ä¸ºéçº¿æ€§/è¾“å‡ºå‡½æ•°çš„å½¢å¼ä¸ºéçº¿æ€§ åŒ…æ‹¬ï¼šè´å¶æ–¯ã€Kè¿‘é‚»ã€å†³ç­–æ ‘ å¦‚æœä»ç®—æ³•çš„å®é™…å«ä¹‰è§’åº¦çœ‹ï¼Œä¸Šè¿°çš„åˆ†ç±»ç®—æ³•å¯ä»¥åˆ†ä¸ºç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹ï¼š ç”Ÿæˆæ¨¡å‹ï¼šæŒ‰ç…§æ¡ä»¶æ¦‚ç‡å»ºç«‹æ¨¡å‹ï¼ŒåŸºäºé«˜æ–¯åˆ†å¸ƒç­‰å‡è®¾ï¼Œå­¦ä¹ æ¨¡å‹çš„å‚æ•°ç”¨äºåˆ†ç±» åŒ…æ‹¬ï¼šè´å¶æ–¯æ¨¡å‹ã€çº¿æ€§åˆ¤åˆ«åˆ†æ åˆ¤åˆ«æ¨¡å‹ï¼šå‡ºäºæœ€å¤§åŒ–åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼Œè¿›è¡Œè®­ç»ƒ åŒ…æ‹¬ï¼šå¤§éƒ¨åˆ†å…¶ä»–åˆ†ç±»ç®—æ³• åœ¨åŸºæœ¬ç®—æ³•çš„åŸºç¡€ä¸Šï¼Œç°ä»£æœºå™¨å­¦ä¹ å¸¸è§çš„è¿˜æœ‰é›†æˆï¼ˆEnsembleï¼‰å­¦ä¹ ï¼Œå…¶æ ¸å¿ƒæ˜¯â€ä¸‰ä¸ªè‡­å±åŒ ï¼Œé¡¶ä¸ªè¯¸è‘›äº®â€ï¼Œå¹¶ä¸è‡´åŠ›äºäº§ç”Ÿæœ€å¼ºçš„å•ä¸ªåˆ†ç±»å™¨ï¼Œè€Œæ˜¯é€šè¿‡æŠŠè®­ç»ƒä¸åŒçš„è¾ƒå¼±åˆ†ç±»å™¨ï¼Œå¹¶è¿›è¡Œé›†åˆå†³ç­–ä»¥è·å¾—æœ€å¥½çš„åˆ†ç±»æ•ˆæœã€‚ é›†æˆå­¦ä¹  Bagging/Bootstrap Aggregatingï¼šé€šè¿‡éšæœºåˆ‡åˆ†æ•°æ®é›†ï¼Œå¹¶è¡Œè®­ç»ƒç›¸åŒæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„åˆ†ç±»æ•ˆæœã€‚ éšæœºæ£®æ—ï¼ˆRandom Forestï¼‰ç®—æ³•æ­£æ˜¯åŸºäºbaggingç®—æ³•å®ç°ã€‚ Boostingï¼šé€šè¿‡è®­ç»ƒä¸€ç³»åˆ—å¼±åˆ†ç±»å™¨å¹¶ç»„åˆè·å¾—å¼ºåˆ†ç±»å™¨ã€‚ Stackingï¼šè®­ç»ƒä¸€ä¸ªç»„åˆä¸åŒæ¨¡å‹çš„é«˜å±‚æ¨¡å‹è¿›è¡Œåˆ†ç±»ï¼ˆä¸Šé¢ä¸¤ç§ç®—æ³•å¯¹åº•å±‚æ¨¡å‹çš„ç»„åˆæ–¹å¼æ˜¯ç¡®å®šçš„ï¼‰ã€‚ æ— ç›‘ç£å­¦ä¹ ä¸»è¦ä»»åŠ¡ é™ç»´ï¼ˆDimensionality Reductionï¼‰æŒ‡çš„æ˜¯å°†æ ·æœ¬ç©ºé—´ä»é«˜ç»´ç‰¹å¾æŠ•å½±åˆ°è¾ƒä½ç»´åº¦çš„ç‰¹å¾ä»è€Œå®ç°æé«˜è®¡ç®—æ•ˆç‡çš„ä½œç”¨ã€‚ èšç±»ï¼ˆClusteringï¼‰æŒ‡çš„æ˜¯å°†æ— æ ‡ç­¾çš„æ ·æœ¬æŒ‰ç…§æ ·æœ¬ä¹‹é—´çš„è·ç¦»ä¿¡æ¯ç­‰ï¼Œå°†ç›¸è¿‘çš„æ ·æœ¬å½’ä¸ºä¸€ä¸ªç°‡çš„ç®—æ³•ï¼Œå¯ä»¥ç†è§£ä¸ºæ²¡æœ‰æ ·æœ¬æ ‡ç­¾çš„åˆ†ç±»ç®—æ³•ã€‚ å¸¸è§ç®—æ³• Principle Component Analysisï¼šä¸»æˆåˆ†åˆ†æï¼Œé€šè¿‡æå–åæ–¹å·®çŸ©é˜µä¸­çš„ç‰¹å¾å‘é‡ä½œä¸ºæ–°ç‰¹å¾å®ç°é™ç»´ã€‚ ä¸çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLDAï¼‰ç›¸ä¼¼çš„ç®—æ³•ã€‚ K Meansï¼šKå‡å€¼ç®—æ³•ï¼Œé€šè¿‡æŠ½å–ç›¸è¿‘ç‚¹ç°‡çš„é‡å¿ƒä½œä¸ºç°‡çš„ä»£è¡¨æ¥å®ç°èšç±»ã€‚ K Medoidsï¼šKä¸­å¿ƒç‚¹ç®—æ³•ï¼Œå’ŒK Meansç®—æ³•ç›¸è¿‘ï¼Œä¸åŒçš„æ˜¯é€‰å–ç°‡ä¸­æœ€æ¥è¿‘é‡å¿ƒçš„ç‚¹ä½œä¸ºç°‡çš„ä»£è¡¨ã€‚ Spectral Clusteringï¼šè°±èšç±»ï¼Œé€šè¿‡é™ç»´æ–¹æ³•å’ŒK Meansç®—æ³•å®ç°èšç±»ã€‚ Gaussian Mixture Modelï¼šé«˜æ–¯æ··åˆæ¨¡å‹ï¼Œæ˜¯åŸºäºé«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ï¼Œé€šè¿‡ç‚¹ç°‡çš„åˆ†å¸ƒä¼°è®¡å‚æ•°ä»¥å®ç°èšç±»ã€‚ K Meansç®—æ³•å¯ä»¥è§†ä¸ºGMMçš„ä¸€ç§ç‰¹æ®Šå½¢å¼ã€‚ Matrix Factorizationï¼šçŸ©é˜µåˆ†è§£ï¼Œæ˜¯ä¸€ç±»é™ç»´ç®—æ³•ï¼ŒåŒ…æ‹¬å¥‡å¼‚å€¼åˆ†è§£ã€çŸ©é˜µéè´Ÿåˆ†è§£å’Œç¨€ç–ç¼–ç ç­‰ç®—æ³•ã€‚ ç®—æ³•çš„åˆ†ç±» å¦‚æœæŒ‰ç…§ä¸»è¦ä»»åŠ¡ï¼Œå¯ä»¥å°†ç®—æ³•åˆ†ä¸ºé™ç»´ç®—æ³•å’Œèšç±»ç®—æ³•ï¼š é™ç»´ç®—æ³•ï¼šä¸»è¦åŒ…æ‹¬ä¸»æˆåˆ†åˆ†æã€çŸ©é˜µåˆ†è§£ èšç±»ç®—æ³•ï¼šä¸»è¦åŒ…æ‹¬Kå‡å€¼ã€Kä¸­å¿ƒç‚¹ã€è°±èšç±»ã€é«˜æ–¯æ··åˆæ¨¡å‹ åŠç›‘ç£å­¦ä¹ åˆ©ç”¨å°‘é‡æ ‡æ³¨æ ·æœ¬å’Œå¤§é‡æœªæ ‡æ³¨æ ·æœ¬è¿›è¡Œæœºå™¨å­¦ä¹ çš„ç®—æ³•ã€‚ ç”±äºæœ¬äººå¹¶ä¸äº†è§£è¿™ä¸€å—ï¼Œæ‰€ä»¥æ­¤å¤„å†…å®¹ä¸ä½œè¯¦ç»†ä»‹ç»ï¼Œæœ‰å…´è¶£è€…è¯·è‡ªè¡Œè°·æ­Œã€‚ å¼ºåŒ–å­¦ä¹ æ²¡æœ‰ç‰¹å®šçš„ç›®æ ‡ï¼Œå¼ºè°ƒç¯å¢ƒçš„åé¦ˆä½œç”¨ï¼Œé€šè¿‡åº”å¯¹ç¯å¢ƒè°ƒæ•´ç­–ç•¥çš„ç®—æ³•ã€‚ ç”±äºæœ¬äººå¹¶ä¸äº†è§£è¿™ä¸€å—ï¼Œæ‰€ä»¥æ­¤å¤„å†…å®¹ä¸ä½œè¯¦ç»†ä»‹ç»ï¼Œæœ‰å…´è¶£è€…è¯·è‡ªè¡Œè°·æ­Œã€‚ æ·±åº¦å­¦ä¹ è¿™ä¸€å—æ˜¯è¿‘åå¹´æ–°çš„æ–¹å‘ï¼Œä¹Ÿæ˜¯ç›®å‰æœºå™¨å­¦ä¹ æœ€ç«çš„åˆ†æ”¯ï¼Œä½†æ˜¯é¢„è®¡ä¸ä¼šåœ¨è¿‘æœŸå†…å®¹ä¸­å‡ºç°ã€‚ ç®€è¨€ä¹‹ï¼Œæ·±åº¦å­¦ä¹ å°±æ˜¯åŸºäºç¥ç»ç½‘ç»œçš„ç®—æ³•ï¼Œé€šè¿‡ç»„åˆçº¿æ€§çš„ç¥ç»å…ƒå’Œéçº¿æ€§çš„æ¿€æ´»å±‚ï¼Œä»¥åŠæ­å»ºä¸åŒç»“æ„çš„ç½‘ç»œï¼Œæ¥å®ç°å›å½’æˆ–è€…é¢„æµ‹ã€èšç±»ç­‰å·¥ä½œã€‚ å…¶â€ç¥ç»ç½‘ç»œâ€å½¢æ€çš„çµæ„Ÿå¾—ç›Šäºç”Ÿç‰©å¤§è„‘çš„ç¥ç»å…ƒè¿æ¥ç»“æ„ï¼Œè®©äººè”æƒ³åˆ°â€æœºå™¨çš„å¤§è„‘ğŸ§ â€ï¼ŒåŠ ä¸Šè¯¸å¦‚alphaGoç­‰ç­‰ä¸€äº›æ–°å¥‡çš„æˆå°±å¸¦æ¥çš„ç‹‚çƒ­ä½¿å¾—ä¼—äººä¸ºä¹‹ç–¯ç‹‚ï¼Œè®¸å¤šè¥é”€å·å’Œåª’ä½“ç”šè‡³è„‘æ´å¤§å¼€ï¼Œå¤§è‚†é¼“å¹â€äººå·¥æ™ºèƒ½æœ‰å®³è®ºâ€ã€‚ ä½†ç›®å‰è€Œè¨€ï¼Œå¯è§£é‡Šæ€§å·®ã€ç¼ºä¹è¾ƒç»Ÿä¸€çš„æ•°å­¦ç†è®ºæè¿°æ˜¯å…¶ç¡¬ä¼¤ã€‚è€Œä¸”ä¹Ÿæ²¡æœ‰å‡ºç°å¼ºäººå·¥æ™ºèƒ½çš„è¿¹è±¡ï¼Œç›®å‰çš„ç¥ç»ç½‘ç»œï¼Œæœ¬è´¨åªæ˜¯ä¸€ç§å¤æ‚çš„ç»Ÿè®¡æ¨¡å‹ã€‚ éšç€ç ”ç©¶é™·å…¥ç“¶é¢ˆï¼Œè¿™åœºèµ„æœ¬ä¸èˆ†è®ºçš„ç‹‚æ¬¢å·²ç»åœ¨é€æ¸å†·å´ï¼Œæœªæ¥ç©¶ç«Ÿå¦‚ä½•å‘å±•ä¹Ÿæœªå¯çŸ¥ï¼šï¼‰ æœºå™¨å­¦ä¹ æ–¹æ³•è®ºæœºå™¨å­¦ä¹ çš„æœ¬è´¨åœ¨äºä»æ•°æ®æˆ–è€…å‡è®¾ä¸­å»ºç«‹æ¨¡å‹ã€å­¦ä¹ å‚æ•°ï¼Œå»æ‹Ÿåˆä¸€ä¸ªæœªçŸ¥çš„å‡½æ•°ã€‚ æ ¹æ®è®ºæ–‡ã€ŠA Few Useful Things to Know about Machine Learningã€‹ï¼Œæœºå™¨å­¦ä¹ çš„è¿‡ç¨‹å¯ä»¥è¡¨ç¤ºä¸ºï¼š $LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION$ ä¹Ÿå°±æ˜¯è¯´ï¼Œæœºå™¨å­¦ä¹ ä¸»è¦åˆ†ä¸ºä¸‰ä¸ªè¿‡ç¨‹ï¼š è¡¨ç¤ºï¼ˆRepresentationï¼‰ï¼šä½¿ç”¨è®¡ç®—æœºèƒ½å¤Ÿæ‰§è¡Œçš„è¯­è¨€æè¿°ç®—æ³•ã€‚è¿™ä¸ªé˜¶æ®µç¡®å®šäº†æ¨¡å‹çš„ç±»å‹ï¼Œæ‰€ä»¥å†³å®šäº†æ‹Ÿåˆ/åˆ†ç±»å‡½æ•°çš„å‡è®¾ç©ºé—´ï¼ˆHypothesis Spaceï¼‰â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨è¿™ä¸€æ­¥ï¼Œæ¨¡å‹çš„å‚æ•°ä¸ªæ•°å’Œæ¨¡å‹çš„è®¡ç®—æ–¹å¼å·²ç»ç¡®å®šï¼Œæ¯”å¦‚çº¿æ€§æ¨¡å‹çš„$y=WX+B$ï¼Œé‚£ä¹ˆæ¨¡å‹æ— æ³•æ¨¡æ‹Ÿéçº¿æ€§çš„åˆ†ç±»/å›å½’ï¼Œè¿™æ˜¯é€‰å–çš„æ¨¡å‹å¯¼è‡´çš„ã€‚è€Œå…·ä½“æ˜¯å¦‚ä½•çº¿æ€§çš„å‡½æ•°ï¼Œéœ€è¦åœ¨æ¥ä¸‹æ¥çš„è¿‡ç¨‹ä¸­ç¡®å®šã€‚ è¯„ä¼°ï¼ˆEvaluationï¼‰ï¼šç”¨äºè¯„ä¼°æ¨¡å‹çš„å¥½åã€‚æ ¹æ®ä»»åŠ¡çš„ä¸åŒï¼ˆå›å½’ã€åˆ†ç±»ï¼‰ç¡®å®šäº†ä¸åŒçš„ç§ç±»ï¼ŒåŒæ—¶è¿™ä¸ªè¯„ä¼°æ–¹æ³•åº”å½“æ˜¯èƒ½å¤Ÿæ–¹ä¾¿åœ°æ‰¾åˆ°å¯¹åº”çš„ä¼˜åŒ–å‡½æ•°çš„ï¼ˆæ›´æ˜ç¡®ä¸€ç‚¹ï¼Œè¯„ä¼°çš„å‡½æ•°åº”è¯¥æ˜¯å¯å¯¼çš„ï¼‰ã€‚æˆ‘ä»¬è®­ç»ƒçš„ç›®æ ‡å°±æ˜¯æœ€å°åŒ–ç›®æ ‡å‡½æ•°ï¼ˆè¯¯å·®å‹ï¼‰æˆ–è€…æœ€å¤§åŒ–ç›®æ ‡å‡½æ•°ï¼ˆç²¾åº¦å‹ï¼‰ã€‚ ä¼˜åŒ–ï¼ˆOptimizationï¼‰ï¼šè¯„ä¼°å‡½æ•°å°±åƒè€ƒè¯•ï¼Œæœ‰äº†è€ƒè¯•æˆ‘ä»¬å°±å¯ä»¥çŸ¥é“è‡ªå·±çš„è–„å¼±ç¯èŠ‚ï¼Œä»è€Œç¡®å®šåŠªåŠ›çš„æ–¹å‘ã€‚è€Œæœ‰äº†è¯„ä¼°å‡½æ•°ï¼Œå°±æœ‰ä¸€ä¸ªå¯¹åº”çš„ä¼˜åŒ–å‡½æ•°ç”¨äºè°ƒæ•´æ¨¡å‹çš„å‚æ•°ã€‚ é€šå¸¸æˆ‘ä»¬é‡‡ç”¨åŸºäºæ¢¯åº¦çš„æ–¹æ³•ï¼Œå…·ä½“ä¼šåœ¨ä¸‹é¢æ¢¯åº¦ä¸‹é™è¿™ä¸€æ¦‚å¿µä¸­è§£é‡Šã€‚ è®ºæ–‡ä¸­åˆ—å‡ºäº†ä¸€ä¸ªå…³äºè¿™ä¸‰ä¸ªéƒ¨åˆ†çš„è¡¨æ ¼ï¼Œåœ¨è¿™é‡Œè´´å‡ºæ¥ï¼š ä»è¡¨æ ¼ä¹Ÿå¯ä»¥çœ‹å‡ºæ¥ï¼Œå¯¹æŸä¸€ç§ç®—æ³•ï¼Œå¹¶éæ‰€æœ‰çš„è¯„ä¼°å‡½æ•°éƒ½èƒ½å¤Ÿä½¿ç”¨ï¼Œæœ‰äº›ç®—æ³•æ˜¯ç»‘å®šäº†è¯„ä¼°å‡½æ•°çš„ã€‚ åŒæ—¶ï¼Œè¯„ä¼°å‡½æ•°ä¸ä¼˜åŒ–å‡½æ•°å­˜åœ¨å¯¹åº”å…³ç³»ï¼Œé€‰æ‹©æŸä¸€ç±»è¯„ä¼°å‡½æ•°æ—¶ï¼Œå¯¹åº”çš„ä¼˜åŒ–ç­–ç•¥ä¹Ÿå°±å†³å®šäº†ã€‚ ï¼ˆæ¥ä¸‹ç¯‡ï¼šæœºå™¨å­¦ä¹ æ¦‚å¿µï¼‰","categories":[{"name":"æœºå™¨å­¦ä¸åŠ¨äº†","slug":"æœºå™¨å­¦ä¸åŠ¨äº†","permalink":"http://riroaki.github.io/categories/æœºå™¨å­¦ä¸åŠ¨äº†/"}],"tags":[{"name":"Data Mining","slug":"Data-Mining","permalink":"http://riroaki.github.io/tags/Data-Mining/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://riroaki.github.io/tags/Machine-Learning/"}]},{"title":"Restart","slug":"Restart","date":"2019-05-28T01:52:55.000Z","updated":"2019-06-02T14:33:47.956Z","comments":true,"path":"Restart/","link":"","permalink":"http://riroaki.github.io/Restart/","excerpt":"","text":"ä»Šå¤©æŠŠåšå®¢æ–‡ç« å…¨éƒ½æ¸…ç©ºäº†ã€‚ ä¸»è¦æ˜¯ä¹‹å‰çš„æ–‡ç« å¤ªä¹±ï¼Œç¼ºä¹æ•´ç†ï¼›åŠ ä¸Šè¿‘æœŸå­¦äº†å¾ˆå¤šä¸œè¥¿ä¹‹åï¼Œå›å¤´çœ‹è¿‡å»çš„å†…å®¹è§‰å¾—æœ‰äº›æµ…è–„ï¼Œå†³å¿ƒä»å¤´å¼€å§‹å†™ã€‚ ä»Šåä¼šåœ¨è¿™é‡Œå†™ä¸€äº›æœºå™¨å­¦ä¹ ï¼Œä»¥åŠæ•°æ®å¤„ç†çš„ä¸œè¥¿ã€‚ å½“ç„¶è¿˜æœ‰ä¸€äº›å·¥ç¨‹å‘çš„å†…å®¹ï¼Œæ€»ä¹‹æˆ‘ä¼šæ›´åŠ æ·±æ€ç†Ÿè™‘åœ°æ¨é€æ–‡ç« ã€‚ ï¼ˆæ˜¯ä¸æ˜¯ä¹Ÿè€ƒè™‘ä¸€ä¸‹æ¢ä¸»é¢˜å‘¢â€¦â€¦å“ˆå“ˆè¿˜æ˜¯ç®—äº†ä¼°è®¡åˆè¦æŒ‘å¾ˆä¹…ï¼‰","categories":[],"tags":[{"name":"Hello, world!","slug":"Hello-world","permalink":"http://riroaki.github.io/tags/Hello-world/"}]}]}